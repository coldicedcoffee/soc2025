id,mentor,title,co_mentor_info,specific_category,description,mentee_max,prereuisites,banner_image,banner_image_link,timeline,checkpoints,general_category
1,Aakriti Chandra 22b0908,Speech emotion recognition,Aryaman Angurana(22b1043),Machine Learning,"https://github.com/x4nth055/emotion-recognition-using-speech  
Work invovled in the project:
1. Gathering and preprocessing a diverse dataset of speech samples with labeled emotions.
2. Extracting relevant features from the speech signals, such as pitch, intensity, and spectral features.
3. Training machine learning models, such as SVMs and Neural Networks, on the labeled dataset.
4. Tuning hyperparameters to optimize model performance through techniques like cross-validation.
5. Evaluating performance using accuracy.
6. Iteratively refining the model architecture and feature selection process based on evaluation results.
7. Testing the model on unseen data to assess its generalization capability.
8. Fine-tuning the model based on feedback and insights from testing.
9. Documenting the entire process, including data collection, preprocessing, model training, and evaluation.
10. Continuously learning and updating the model to adapt to new speech patterns and emotions.
Learning outcomes:
1.Understanding of the fundamentals of machine learning.
2.Learning regression and classification models like RNN, random forest classifier etc.
3. Strengthing ML concepts and implementing it on real life situation
",10,Basics of python and loads of enthusiasm,projects/emotion detection.png,https://drive.google.com/file/d/1SLtjCfJjqtfdHvx95b6a1_YkPKz5N_gM/view?usp=sharing,"Week 1 : Basic python skill development and python libraries like numpy, pandas and matplotlib
Week 2: Implementation of regression model from scratch
Week 3: Neural Networks theory and implementation
Week 4: RNN theory and implementation using pkl dataset
Week 5-7 : final project
Week 8: Project documentation + buffer","Checkpoint 1: Learning of python libraries numpy, pandas and matplotlib.
Checkpoint 2: Implementation of neural networks and regression models from scratch and using it against a dataset
Checkpoint 3:Building strong foundation of other additional libraries tensorflow, librosa and scikit- learn
Checkpoint 4: Ideation and basic structure designing of final project
Checkpoint 5: Code implementation and accuracy refinement",ML
2,Aansh Samyani 22B0424,A Guided Tour to PyTorch,"Aansh Samyani (22B0424), Suyash Gahankari (22B0426)",Deep Learning,"Over the course of our journey, we'll explore how to build powerful neural network models from scratch, right here in PyTorch. Through hands-on exercises and guided tutorials, you'll gain a solid understanding of fundamental deep learning concepts and learn how to apply them to real-world problems. Whether you're a beginner or an experienced programmer, this adventure will equip you with the knowledge and skills needed to create and train your own deep learning models with PyTorch.

Throughout the project, you'll have the opportunity to delve into various neural network architectures and learn how to implement them using PyTorch's intuitive interface. From simple feedforward networks to more complex convolutional and recurrent neural networks, you'll discover how to design and train models for a wide range of tasks, from image classification to natural language processing. Along the way, we'll also explore advanced topics such as transfer learning, optimization techniques, and model deployment strategies, empowering you to tackle real-world challenges in deep learning with confidence. Join us on this exciting adventure as we unlock the secrets of deep learning with PyTorch and unleash the potential of artificial intelligence!",10,Basics of Python/C++/C,projects/downloadpytorch.png,https://drive.google.com/file/d/1czbegDzcCV8tg11T1-2OoLRCu2c-rxuB/view?usp=sharing,"Week 1 - Introduction to PyTorch and Deep Learning
                Learning about PyTorch Tensors and Libraries
                Implementing Basic Regression and Classification tasks

Week 2 - Application of Computer Vision
                What are Convolutions, building CNNs
                Image Classification using CNNs

Week 3 - Building different CNN Architectures ( U - Net, Res-Net etc.)
                Image Segmentation using CNNs
                Labelling specific image parts

Week 4 - Broader Application of Computer Vision
                Using Pretrained Object Detection Models
                Instance Segmentation for building Object Detection Models

Week 5 - Unsupervised and Representation Learning
                Building Variational Autoencoders
                Building Generative Adversarial Networks

Week 6 - Digital Image Processing
                Applying Style Transfer on Images
                Applying masks and digital filters

Week 7 - Building basic Domain Adaptation Models
                Building Self-Supervised Learning Models for Image Classification and 
                Segmentation
                                 ","Checkpoint 1 - Building basic networks for Regression and Classification tasks
Checkpoint 2 - Building CNNs for Image Classification and Segmentation
Checkpoint 3 - Building Object-Detection Models, VAE and GANs
Checkpoint 4 - Applying Style Transfer and Digital Image Filtering to Images
Checkpoint 5 - Building Self-Supervised Learning Models",ML
3,Aastha Sahoo 22B0453,FormFusion: Empowering Seamless Form Connections with Autonomous Intelligence using DeltaV,Samruddhi Shinde (22B1539),Natural Language Processing,"FormFusion(One stop for all insti reports and forms) simplifies online form filling by connecting form creators with users, streamlining the submission process. Our platform incorporates features like smart helpers and efficient routing to make filling out forms effortless. Leveraging Fetch.ai technology enhances the overall user experience, ensuring smooth functionality.

https://docs.google.com/document/d/1lh1IGcZheaNx3lbQpxGZq5lXSQV-F2adprsTarOf5Fs/edit?usp=sharing",6-8,"Python (must)
Experience in NLP (not a hard pre-requisite)
Loads of Enthusiasm",projects/FormFusion.png,https://drive.google.com/file/d/1nrozDhUZWk0qMev8G2FPO4OPAtO6rWKj/view?usp=sharing,"Week 1: Familiarizing yourself with fetch.ai 
Week 2-3: Making first uAgent and project kickoff (involves defining objectives and roles), deciding the flow 
Week 4-5: Implementing form definition, submission, and data routing functionalities
Week 6: Testing the agents and preparing for deployment.
Week 7-8: Deploying the platform, conducting final testing, and optimizing performance for production","Checkpoint 1 - First uAgent based on the assigned topic
Checkpoint 2 - Rough flow of data (flowcharts and algorithms)
Checkpoint 3 - Server side uAgent
Checkpoint 4 - Client side uAgent
Checkpoint 5 - Deployment",ML
4,Abhishek Kumar 22B2210,Image Captioning Using Attention Mechanism,"Soham Joshi (22B2495), Abhishek Kumar (22B2210)",Image Processing,"The project is based on image captioning using CNN encoder and LSTM decoder. This project was done by my co-mentor in WiDS. Unfortunately, the output predicted in that project was not quite good. Hence, we have decided to incorporate the attention mechanism in the encoder and decoders.
Shared below is the WiDS project link my co-mentor has completed:
https://github.com/Soham-joshi04/Image-Captioning/blob/main/Image_Captioning.ipynb",10,Python and Basic Familiarity with Machine Learning,projects/SOC_Banner.png,https://drive.google.com/file/d/1Y4l6FbXu53EHVoyEsKiYyygL27rWX2Ha/view?usp=sharing,"Week 1: Learning Neural Networks 
Week 2: Exploring Convolutional Neural Networks 
Week 3: Exploring Sequential Models (RNN, LSTM)
Week 4: Learning Basics of Natural Language Processing
Week 5: Understanding Attention Mechanism & Encoder-Decoder Architecture
Week 6 & Week 7: Building Model","Checkpoint-1: Basic Classification Task using Neural Networks
Checkpoint-2: Classification of Images using CNN
Checkpoint-3: Stock Prediction using Sequential Models (Hands on with Sequential Model)
Checkpoint-4: Sentiment Analysis using NLP
Checkpoint-5: Final Model",ML
5,Adit Srivastava 22b1269,Applications of RL: Natural Language Processing,Jay Mehta(22b1281),Deep Learning,"Reinforcement Learning is an emerging branch of Machine Learning which has pretty innovative applications in the real world. Reinforcement Learning is a type of Machine Learning which deals with on-flight control to maximise certain reward. It's a blend of traditional Machine Learning methods and Optimal Control. Reinforcement Learning is about training an agent, our model, to interact with an environment, know about its state and then performed the best possible actions to maximise our long-term reward. The best part about RL is that it assumes no specific mathematical model for the environment and learns everything about it by exploring.
Combining the recent surge of RL with the rising popularity of NLP. Our project aims to use RL techniques to improve NLP agents in whatever task they’re performing(ex: text summarisation, dialogue chatbots, generative agents, etc.)

Buckle up for some intense math (patience needed for understanding RL at first) and coding ofcourse :)

",8-10,"Basic Python, Probability and Statistics theory.",projects/default.png,https://drive.google.com/file/d/1PbzW8CtrHwUkf2FyLylXDTd538W1f_fd/view?usp=drivesdk,"Week 1-3:
Intro to RL theory (lecture series by David silver)
https://youtube.com/playlist?list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-&si=KdMzM_6CZ27avidH

Week 4:
The halfway point, here you will apply everything you’ve learnt before this to make an AI agent solve games like taxi, cart pole, lunar lander from Open AI gym.
https://gymnasium.farama.org/

Week 5:
Introduction to basic NLP concepts

Week 6-7: 
Introduction to deep learning and Deep RL algorithms such as DQN, PPO, A2C etc.
This is what you will be using for the final project.

Week 8-9:
Applying RL for tasks in NLP
(Final Project)
","1-Learning the introductory concepts of RL and a brush up on probability theory(week 1)
2-Using RL to solve the n-armed bandit problem(week 2)
3-Solving games from Open AI gym using RL techniques(week 4)
4-Introduction to NLP and Deep learning(week 6)
5- Applying RL for NLP tasks like Text summarisation, generation and dialogue systems.
(Week 9)",ML
6,Aditya Agrawal 22B0955,Queen's Gambit,"Aryan Katiyar(22B1205),Kunal Chaudhari(22B1060)",Machine Learning,"The goal of the project is to get a flavour of game theory and understand how our favourite chess engines work. Project delves into understanding the mathematics behind games and how computers approach games which seem impossible for a machine to predict. We understand how machines outmatch the creativity of a human mind by cold hard calculations. Theoretically, computers are not yet so powerful to solve chess and that's the part where humans come in. Your mission, should you choose to accept it is to develop an algorithm which balances accuracy of moves played and the time taken to play them. At its exposition, you the mentees will put your engines to the test against each other.",8-12,"No hard prerequisites, but basics of python and the love of games goes a very long way. Mentees should be enthusiastic and willing to learn. Original thoughts and compositions enable us humans to surpass machines :)",projects/default.png,https://drive.google.com/drive/folders/1ET2Ss8rWcYCGrckZqKtUL0qH71XksHHG?usp=sharing,"Week 1: Introduction to numpy, vectorization in numpy
Week 2: Understanding dominant strategy in various games and how to come up with the dominant strategy
Week 3: Using alpha-beta prunning and min-max player to implement tic-tac- toe  and Notakto
Week 4: Nash equilibrium and various other types of equilibriums.
Week 5: Start building the chess engine without time constraints using previously taught concepts.
Week 6: Introduce time constraints to the chess engine and develop heuristics to make moves
Week 7: Competition of the chess engines made by mentees","Milestone 1: Finding dominant strategy for various 2 player games 
Milestone 2: Implementing Notakto
Milestone 3: Understanding how to find various equilibrium in normal form games
Milestone 4: Chess engine performes well against the mentors build Chess engine
Milestone 5: Chess engine running under given time constraints",ML
7,Aditya Busa 22B1024,Competitive Programming,"Ujjawal Kumar Singh (22B1065) , Ayush Raj Kaushik (22B0410)",Competitive Programming,"Competitive Programming is quite opposite to traditional learnings, instead of scarcity of resources, here we are overwhelmed with the amount of resources

Too many sources, what to read ? where to start ? how much to be done ? These become the basic questions for any newbie which results in wasting a lot of time and hardly there is any uplift in level. Considering the importance of both algorithms, speed and proficiency and mathematics we have curated one of the best set of cp questions. The knowledge obtained from this will help you in navigating the uncharted waters of Competitive Programming like a veteran !

But make no mistake – success here demands effort. Mastery requires consistent practice and improvement. Don't be discouraged by initial setbacks; persistence is key. Our structured curriculum covers diverse topics, each accompanied by a variety of practice questions. While it may seem daunting, our support and guidance will see you through.

We will try our best to get you addicted to CP , So what are you waiting for hop on this journey with us !!",8-10,"CS101 Knowledge is more than enough but specifically speaking, knowing these below are good to go ahead with the project.

1 . Basic understanding of programming fundamentals (variables, loops, conditionals, functions, data structures, etc.).
2. Proficiency in at least one programming language (e.g., C++, Java, Python).
3. Familiarity with fundamental algorithms and data structures (e.g., arrays, linked lists, sorting algorithms).",projects/final.png,https://drive.google.com/file/d/17uXyricOQi9YXFLFNZ4ftk67srVXheTn/view?usp=sharing,"Week 1: How CP is different from DSA using Templates , C++ STL data structures like sets, maps, and sorting algorithms, with corresponding structures explored for other languages. Progress to more advanced algorithms such as stacks, queues, and the two-pointer method. 

Week 2: Dive deeper into problem-solving by tackling challenges that require the application of previously learned data structures. Introduce the concepts of Greedy and Dynamic Programming (DP) algorithms, along with basic Number Theory principles.

Week 3: Explore more complex DP and Greedy problems, encouraging mentees to identify suitable algorithms for each question themselves. Touch upon basic graph concepts like depth-first search (DFS), breadth-first search (BFS), and graph representation.

Week 4: Depending on mentees' progress, review concepts covered so far or delve into harder problems within the same topics. Mid-session bonus contests will focus solely on revisiting previous topics.

Week 5: Introduce mentees to advanced topics such as Dijkstra's Algorithm, and implementing DP and Greedy Algorithms in trees. Introduce Segment Trees and Fenwick Trees, allowing time for mentees to understand and code their own implementations.

Week 6: Present moderately challenging problems involving bit-wise manipulation, Segment Trees and Fenwick Trees, focusing on comfortable implementation. Introduce mentees to flow algorithms, understanding that this topic may present a steep learning curve.

Week 7: Address mentees' weaknesses and challenges, encouraging them to study editorials and review others' code to enhance their problem-solving skills. Aim for mentees to solve approximately 100 problems across various platforms, spanning easy, medium, and hard difficulty levels by the end of the program.","checkpoint 1: Completion of basic strategies and algorithms needed to start cp
checkpoint 2: Almost all Data Structures and their implementation 
checkpoint 3: Implementation of all sorts of greedy and DP algorithms
checkpoint 4: basic graph algos with deep understanding on their implementation
checkpoint 5: Extra topics on bit-wise manipulation, Fenwick trees and Segment trees",CP
8,Aditya Narayan Prasad 210020007,Algorithm Visualizer,"Rohit Kumar, (210020108)",Web Development,"Introduction:
Algorithm Visualizer is an interactive web application designed to help users understand and visualize various sorting and pathfinding algorithms. The project aims to create an educational tool that makes complex algorithms more accessible and engaging through interactive visualizations. Mentees participating in this project will have the opportunity to enhance their skills in web development, data structures, algorithms, and user interface design.

Work Involved:
1. Development of UI Components: Mentees will work on designing and implementing user interface components using React.js. This includes creating interactive elements for algorithm selection, data visualization, and user controls.
2. Implementation of Algorithms: Mentees will implement sorting algorithms such as Bubble Sort, Merge Sort, and quicksort, along with pathfinding algorithms like Dijkstra's Algorithm and A* Algorithm. They will integrate these algorithms with the UI to allow users to visualize their execution step-by-step.
3. User Experience Enhancement: Mentees will focus on improving the user experience by adding features such as algorithm speed adjustment, visualization pause/resume, tooltips, and help sections. They will also optimize the application for better performance.
5. Testing and Documentation: Mentees will conduct thorough testing of implemented features to ensure correctness and reliability. They will also document the codebase and functionalities for future reference and maintenance.

Learning Opportunities:
- Web Development: Mentees will gain hands-on experience in building web applications using React.js, a popular JavaScript library for building user interfaces.
- Data Structures and Algorithms: Mentees will deepen their understanding of common sorting and pathfinding algorithms, as well as various data structures, through implementation and visualization.
- Project Management: Mentees will collaborate with mentors and fellow mentees, manage tasks, and adhere to project timelines, gaining valuable project management skills.

   - [Algorithm Visualizer](https://algorithm-visualizer.net/) - Inspiration for the project, provides interactive visualizations of algorithms.
   - [VisuAlgo](https://visualgo.net/en) - Another platform offering interactive visualizations of various algorithms and data structures.

GitHub Repos/Demonstrations:
- [Algorithm Visualizer GitHub Repository](https://github.com/algorithm-visualizer/algorithm-visualizer): Provides access to the source code of the Algorithm Visualizer project for reference and learning purposes.
- [React Sorting Visualizer](https://github.com/clementmihailescu/Sorting-Visualizer): A React.js project that visualizes sorting algorithms, offering insights into implementation and UI design.
",7,"Basic web dev, Great chatgpt and google skills. We won't be particularly teaching DSA and React so mentee should have basic knowledge and willingness to do the work, make mistake and learn. ",projects/default.png,"Drive folder - https://drive.google.com/drive/folders/1Dp7oBkQU0qPUNd7C-l31D-xEoPLCfKgQ?usp=drive_link , photo link - https://drive.google.com/file/d/1fJIhWKWwjQNY5Bq87JmZyb1oMPsW6B7d/view?usp=drive_link (there are some other photos in the folder too, you can maybe use those too)","Week-wise Timeline:

Week 1-2: Project Setup and Basic UI Design
- Set up development environment with React.js.
- Design basic UI layout including navigation and visualization area.
- Define data structure for algorithms and visualization.
- Implement basic UI elements for data structure visualization.
- Integrate linear search and binary search algorithms with basic UI.

Week 3-4: Sorting Algorithms Visualization
- Implement visualization components for sorting algorithms (e.g., Bubble Sort, Merge Sort).
- Integrate sorting algorithms with UI for user interaction.
- Implement controls for user input such as array size and visualization speed.
- Test sorting algorithms thoroughly and ensure correctness.
- Document implemented features.

Week 5-6: Pathfinding Algorithms and Map Visualization
- Design and implement map UI component with tiles and start/end points.
- Implement visualization components for pathfinding algorithms (e.g., Dijkstra's Algorithm, A* Algorithm).
- Integrate pathfinding algorithms with map UI for user interaction.
- Implement controls for defining start/end points and barriers.
- Test pathfinding algorithms thoroughly and ensure correctness.


Week 7 User Experience Enhancements
- Enhance UI for better user experience and aesthetics.
- Implement features such as algorithm speed adjustment and visualization controls.
- Add tooltips and help sections for guiding users.
- Perform user testing and gather feedback for improvements.
- Address any bugs or issues identified during testing.


Week 8: Deployment and Finalization
- Prepare application for deployment on a web server.
- Set up continuous integration/continuous deployment (CI/CD) pipeline if applicable.
- Perform final testing on deployed application.
- Write documentation for usage and maintenance of application.
- Present/demo finalized project to mentors and peers.","Checkpoint 1: Project Setup and Basic UI Design (Week 1)

Tasks:
1. Set up the development environment with React.js.
2. Design the basic UI layout including navigation, algorithm selection, and visualization area.
3. Define the data structure for representing algorithms and data visualization.
4. Implement basic UI elements for visualizing data structures like trees, graphs, linked lists.
5. Integrate linear search and binary search algorithms with basic UI for visualization.

Deliverables:
- Initial project setup with React.js environment.
- Basic UI design mockups including data structure visualization.
- Data structure design for algorithms and visualization.
- Implementation of linear search and binary search algorithms with basic visualization.

Checkpoint 2: Sorting Algorithms Visualization (Week 3)

Tasks:
1. Implement visualization components for common sorting algorithms (e.g., Bubble Sort, Merge Sort) using the previously defined data structures.
2. Integrate sorting algorithms with the UI for user interaction.
3. Implement controls for user input such as array size and speed of visualization.
4. Test sorting algorithms thoroughly and ensure correct functionality.
5. Document code and functionality for future reference.

Deliverables:
- Implemented sorting algorithms with advanced visualization components.
- Integrated sorting algorithms with user interface controls.
- Tested and verified sorting algorithms' correctness.
- Documentation of implemented features.

Checkpoint 3: Pathfinding Algorithms and Map Visualization (Week 5)

Tasks:
1. Design and implement a map UI component with tiles, walls, and start/end points for pathfinding visualization.
2. Implement visualization components for pathfinding algorithms (e.g., Dijkstra's Algorithm, A* Algorithm) using the map UI.
3. Integrate pathfinding algorithms with the map UI for user interaction.
4. Implement controls for defining start and end points, as well as barriers.
5. Test pathfinding algorithms thoroughly and ensure correct functionality.

Deliverables:
- Implemented map UI component with pathfinding visualization.
- Integrated pathfinding algorithms with map UI controls.
- Tested and verified pathfinding algorithms' correctness.
- Documentation of implemented features.

Checkpoint 4: User Experience Enhancements and Optimization (Week 7)

Tasks:
1. Enhance user interface for better user experience and aesthetics, including tooltips and help sections.
2. Implement features such as algorithm speed adjustment and visualization pause/resume for both sorting and pathfinding.
3. Optimize assets and code for improved performance.
4. Perform user testing and gather feedback for improvements.
5. Address any bugs or issues identified during testing.

Deliverables:
- Improved user interface with enhanced features.
- Implemented user feedback and bug fixes.
- Optimized code for better performance.

Checkpoint 5: Deployment and Finalization (Week 8)

Tasks:
1. Prepare the application for deployment on a web server.
2. Set up continuous integration/continuous deployment (CI/CD) pipeline if applicable.
3. Perform final testing on the deployed application.
4. Write documentation for usage and maintenance of the application.

Deliverables:
- Deployed web application accessible online.
- Finalized documentation for the application.
- Completion report summarizing the project journey, challenges, and learnings.

Pathfinding can be an optional feature depending on the project's scope and the availability of time due to our busy schedule",Development
9,Aditya Narayan Prasad 210020007,"Exploring AI Agentic workflows, OpenDevin and ComicGPT 2.0",Shivesh Gupta,GenAI,"In this project, we will delve into the fascinating world of AI agents, focusing on understanding their workflows, frameworks, and practical applications. Our journey will involve both research and hands-on experimentation. We’ll explore existing AI agent frameworks, analyze their construction, and apply them to real-world scenarios. 
Here's a great website to explore ai-agents - https://e2b.dev/ai-agents.",7,"Knowledge about llms, Langchain and such tools. As this tech/field is new, excitement is more than suffice.",projects/Screenshot 2024-04-07 235122.png,https://drive.google.com/file/d/1xZrhB4GFQ6fL-nbEtiCL82JMfee7pE8K/view?usp=sharing,"Familiarization and Research (Week 1):
o	Explore AI agent frameworks (e.g., AgentGPT, AutoGPT, BabyAGI).
o	Investigate how these frameworks are designed and function.
o	Document key findings.
Framework Application (Week 2-3):
o	Set up a development environment with a chosen framework.
o	Create a basic AI agent application (e.g., chatbot).
o	Collaborate with team members to gain practical experience.
Project Ideation (Week 4):
o	Brainstorm creative project ideas.
o	Select a project aligned with team interests and skills.
Devin Workflow Exploration (Week 5-6):
o	Dive into the Devin workflow based on the OpenDevin GitHub repository.
o	Understand how Devin navigates software engineering complexities.
o	Share insights with the team.
//////// OR /////////////
ComicGPT Workflow (Week 5-6):
o	Design a comic creator workflow using AI agents.
o	Combine language models (LLMs) for storylines and Stable Diffusion for visual panels.
o	Ensure consistent theme, style, and character design.
","1.	Familiarization and Research (Week 1)
 	Objective: Understand AI agent frameworks and their workflows.
	Tasks: 
        -	Explore existing AI agent frameworks (e.g., AgentGPT, AutoGPT, BabyAGI).
        -	Research how these frameworks are constructed and how they function.
        -       Document findings and share with the team.
2.	Framework Application (Week 2-3)
	Objective: Apply AI agent frameworks practically.
	Tasks: 
       -	Set up a development environment with the chosen framework (e.g., AutoGPT).
       - 	Create a simple project (e.g., chatbot) using the framework.
       -	Collaborate with mentees to build a basic AI agent application.
       -	Document challenges and solutions encountered during implementation.
3.	Project Ideation (Week 4)
	Objective: Brainstorm creative project ideas.
	Tasks: 
       -	Gather team input on potential projects.
       -	Ideate unique use cases for AI agents (e.g., comic creation, storytelling).
       -	Select one project idea that aligns with team interests and skills.
4.	ComicGPT Workflow (Week 5-6)
	Objective: Develop a comic creator workflow using AI agents.
	Tasks: 
       -	Design the overall workflow: 
       - 	Language Model (LLM): Generate storylines and dialogues.
       - 	Stable Diffusion: Create comic panels from text descriptions.
       -	Ensure consistent theme, style, and character design.
       -       Implement and test the workflow.
       -	Collaborate with mentees to create sample comics.  
/////////           OR                   //////////////////
4. Devin Workflow Exploration (Week 5-6)
    Objective: Understand the Devin workflow based on the OpenDevin GitHub repository.
    Tasks:
    -    Study the OpenDevin project and its components.
    -    Analyze how Devin navigates software engineering complexities.
    -    Identify strengths and areas for improvement.
    -     Share insights with the team.
5.	Project Review and Refinement (Week 7-8)
	Objective: Evaluate the project and make improvements.
	Tasks: 
       -	Review the completed ComicGPT/openDevin project.
        -	Gather feedback from the team and potential users.
        -	Address any issues or enhancements.
       -	Prepare documentation and presentation materials. 
",Others
10,Aditya Sancheti 22b3004,Fashion Recommendation System,"Mahek Hinhoriya(22b3031), Rishi Daga(22b3003)",Deep Learning,"Have you ever wondered how Google Lens magically identifies objects in your photos or how Myntra suggests similar fashion items based on your uploaded images? 
Dive into the world of image processing and learn to make useful project that has wide scaled implementation

The Fashion Recommender System aims to provide product recommendations to users based on their uploaded images of garments or shoes. Leveraging deep learning  techniques, the system learns to associate visual features from the user’s input with relevant items in its dataset. 

Certainly! In addition to coding and model implementation, we’ll also focus on deploying the system. Our goal is to make it accessible and usable for real-world scenarios.",11,"Python Libraries  - Numpy, Pandas. 
Basic Understanding of Machine Learning and Deep Learning is a plus point.
and LOTS OF Enthusiasm !!",projects/Screenshot 2024-04-08 at 10.52.33?PM.png,https://drive.google.com/file/d/1JnD3NanplEWNm-YWWU2RD5Dza4AQ7UT_/view?usp=sharing,"Week 1: Introduction to pandas, numpy, matplotlib, and classification algorithms. Week 2: Exploring Image Processing. Week 3-4: Delving into Deep Learning. Week 5: Developing a Mini Project. Week 6-7: Understanding Transfer Learning and deployment techniques. Week 8-9: Creating a Final Project.","Checkpoint 1: Mastery of pandas, numpy, matplotlib, and basic classification algorithms.
Checkpoint 2: Proficiency in fundamental image processing techniques using OpenCV or PIL.
Checkpoint 3 Successful implementation and evaluation of deep learning models for image-related tasks.
Checkpoint 4: Completion of a mini project demonstrating integration of learned concepts.
Checkpoint 5: Understanding and application of transfer learning techniques and deployment strategies for deep learning models.",ML
11,Afnan Abdul Gafoor 22b2505,MNIST Digit Classification with Neural Networks,,Deep Learning,"Project Description:

The ""MNIST Digit Classification with Neural Networks"" project aims to develop a deep learning model to accurately classify handwritten digits from the MNIST dataset using neural networks. This project offers an excellent opportunity for you to dive into the field of deep learning, specifically in image classification tasks.

Work and Learning Involved:

1. Understanding Neural Networks: You will learn about the fundamentals of neural networks, including different types of layers (e.g., dense layers), activation functions (e.g., ReLU), loss functions (e.g., categorical cross-entropy), and optimization algorithms (e.g., Adam).

2. Data Preprocessing: You will preprocess the MNIST dataset, including normalization and reshaping of input images.

3. Model Building: You will construct a neural network model using frameworks such as TensorFlow or Keras. Experiment with various architectures, including the number of layers, number of neurons per layer, and activation functions.

4. Training and Evaluation: Train the model on the training data and evaluate its performance on the test data. You will learn about metrics such as accuracy, precision, recall, and F1-score for model evaluation.

5. Hyperparameter Tuning: Explore techniques for hyperparameter tuning to optimize the model's performance.


Resources:
As this project is among the most common choices for beginners starting with deep learning, resources are abundant across the internet. The project draws inspiration from Course 2, Week 1-2 of the Machine Learning Specialization by Andrew Ng.",8-12,Enthusiasm,projects/default.png,https://drive.google.com/file/d/1qGNDWGRL7lqBw4ILsDjxmVPj6py7reRU/view?usp=share_link,"Tentative Week-wise Timeline:

Week 1-3: Learn Necessary Python Tools and Libraries
Week 3-6: Model Building
Week 6-7: Fine-Tuning and Optimization
Week 7-8: Documentation and Submission","Checkpoint-1: Data Preparation and Preprocessing
- Prepare and preprocess the MNIST dataset to ensure it is suitable for training the neural network.

Checkpoint-2: Model Architecture Design
- Design and create the neural network architecture, experimenting with various configurations to optimize performance.

Checkpoint-3: Model Training and Evaluation
- Train the neural network model using the prepared dataset and evaluate its performance on unseen data to measure its effectiveness.

Checkpoint-4: Hyperparameter Tuning
- Fine-tune the model's hyperparameters to optimize its performance and enhance its accuracy in classifying handwritten digits.

Checkpoint-5: Documentation and Presentation
- Document the project thoroughly, including methodologies, results, and challenges faced.",ML
12,Akash Banger 210010007,IntelliExtract: Dynamic PDF Table Parsing Using OCR and LLMs,Sakshi shinde (210110102),Deep Learning,"IntelliExtract aims to revolutionize how we interact with unstructured data in PDF documents by leveraging Optical Character Recognition (OCR) technology, dynamic programming, and the capabilities of Large Language Models (LLMs) to accurately parse and convert table data into a structured CSV format. 

This project will involve:
Utilizing OCR to detect text and its spatial organization within a PDF.
Arranging detected text into a text grid that mirrors the table's layout.
Employing LLMs to interpret the grid, generate a CSV output, and correct any OCR-induced errors.
Crafting a robust pipeline that integrates these components into a workflow.

Learning and Reading Material:
OCR and EasyOCR: Familiarise with OCR technology and specifically EasyOCR documentation (https://pypi.org/project/easyocr/)
Dynamic Programming: Refresh knowledge on dynamic programming, focusing on applications in text and image processing (https://www.geeksforgeeks.org/dynamic-programming/)
LLMs for Data Structuring: Explore OpenAI's documentation on GPT models, focusing on text understanding and generation.(https://platform.openai.com/docs/introduction)
",5,"Basic understanding of Python programming.
Familiarity with OCR technology and machine learning concepts.
No specific prior experience in dynamic programming or LLMs is required, but a willingness to learn is essential.

Expectations and Good-to-Have Skills
Strong analytical and problem-solving skills.
Experience with Python libraries like pandas, NumPy, and PyTorch or TensorFlow.
Basic knowledge of LaTeX or markdown formatting is a plus, for understanding text arrangement.",projects/project_banner.jpg,https://drive.google.com/file/d/1jZjCs22e5mpwjMRchVcHRYxTn2wxE8mB/view?usp=sharing,"Week 1-2: Foundation and Setup
Setup development environment.
Introduction to OCR with EasyOCR.
Initial trials of text extraction from PDFs.
Week 3-4: Text Grid Arrangement
Explore and implement dynamic programming techniques for arranging OCR text into a grid.
Develop algorithms for text alignment and spacing adjustments.
Week 5-6: Integration with LLM
Introduction to LLMs and prompt engineering.
Develop the interface between the text grid and LLM for CSV generation and error correction.
Week 7: Refinement and Testing
Optimize algorithms for efficiency.
Extensive testing with diverse PDF documents to refine the process.
Week 8: Final Integration and Documentation
Ensure the operation of the pipeline.
Document the project, code, and usage instructions.","Checkpoint 1: Successful extraction of text and bounding boxes from PDFs using OCR.
Checkpoint 2: Implementation of dynamic programming for accurate text grid arrangement.
Checkpoint 3: Initial integration with LLM for generating CSV from the text grid.
Checkpoint 4: Optimization and error correction enhancements.
Checkpoint 5: Complete system integration, testing, and documentation.",ML
13,Akshat Kumar 22B4513,GPT Mastery: A Comprehensive Guide To Crafting Your Own ChatGPT,No ,Machine Learning,"The project aims to develop a personal chatbot using natural language processing techniques, specifically focusing on building a simplified version of OpenAI's GPT (Generative Pre-trained Transformer) model from scratch. Through a series of structured steps, participants will learn the fundamentals of neural networks, backpropagation, language modeling, and advanced techniques like WaveNet for generating human-like responses in a conversational setting.

Github Link - https://github.com/karpathy/ng-video-lecture

I'm planning to teach everything from basic Neural Networks to advanced transformers in order to build a simplified ChatGPT.

This is an intermediate level project suitable for those who have a basic background in Machine Learning. The course start by learning and implementing Neural Networks from scratch.",Around 10 - 15 ,"Prerequisites For this project :-
1.) Basic Python 
2.) Basic Understanding of Machine Learning concepts ",projects/Artificial Intelligence - Made with PosterMyWall (1).jpg,https://drive.google.com/file/d/1f_eEm0T_X-jK4qymZE27MkgsE-vdvvNu/view?usp=sharing,"1st Week: Introduction to Neural Networks and Backpropagation
2nd Week:  Introduction to Language Modeling
3rd Week:  Activations & Gradients, BatchNorm 
4th Week:  Becoming a Backprop Ninja 
5th Week:  Building a WaveNet
6th Week:  Building GPT from Scratch 
7th Week:  Building the GPT Tokenizer","1. Basic Neural Networks & Backpropagation: Participants start with micrograd, learning how forward and backward propagation work, crucial for deep learning.

2. Language Modeling Introduction: Using makemore, participants understand generating coherent text sequences, building upon neural network basics.

3. Activations, Gradients & BatchNorm: Dive deeper into neural network mechanics, focusing on activation functions, gradient descent optimization, and batch normalization for improved model performance.

4. Advanced Backpropagation Techniques: Participants refine understanding of backpropagation, exploring optimization strategies for training deep neural networks efficiently.

5. Implementing WaveNet & GPT: Build WaveNet for high-quality audio generation and construct a simplified version of GPT, emphasizing transformer architecture and self-attention mechanism. Additionally, develop a GPT Tokenizer module for seamless interaction with the chatbot.",ML
14,Alwin Johnosn 22B2455,HarmonAI,none,Machine Learning,"building an AI tool capable of analysing songs and generating guitar tab sheet that replicate the original music while accommodating varying difficulty levels. 
The project will leverage Magenta, an open-source research project by Google, which is closely related to the project and will be used to extract features of the song etc.
If time permits also work with magenta to create an auto backing track for the guitar tabs it generates. 
Mentees will learn how to utilise open source projects like magenta and machine learning using tensorflow. They will also learn basics of music theory, and ensuring that the notes it generates are playable and adjusting the difficulty level is a new concept with not many resources available, so they will learn problem solving and algorithm developing skills (we will start with only 1 string at a time to make it simple), if it all goes good it can be deployed and will also require front end development. mentees can go through the youtube video by google explaining magenta and their repo- https://github.com/magenta/magenta/tree/main. They can also learn basic music theory and some interesting videos showing the possibilities of AI and music -
https://www.youtube.com/watch?v=ZRnbbtqxBEc",8,"Basic python 
good-to-have skills - playing a musical instrument and interest in music ",projects/default.png,https://drive.google.com/drive/folders/1V8fFktpghU_1wS8ES9NOrUnwyvT8J2DT?usp=sharing,"week 1- intro to project and developments environments (jupyter and google collab) and using magenta to extract features from songs
week 2- leaning how to process and feed sounds as data 
week 3- preparing dataset of songs and corresponding tabs and extracting features 
week 4- training different models (mostly types of RNN) with the data
week 5- developing an algorithm to generate the music from tabs and compare it with original (can be done earlier also)
week 6- testing different models and experimenting with features to get best output
week 7- developing algorithm to ensure playable tabs and difficulty levels depending on time 
week 8- refinement and further testing with the playability restriction 


","Checkpoint 1- data preparation and feature extraction using magenta 
checkpoint 2- training different RNN models with datasets
checkpoint 3- generating music from tabs and processing sounds as data 
checkpoint 4- developing algorithm to ensure playability and difficulty
checkpoint 5- comparing songs and tab generated version and refine to make it similar",ML
15,Aman Khande 210100009,Meta-learning for Few-shot Learning,"Rishikesh Pandey, 210100105",Deep Learning,"This project introduces learners to advanced machine learning techniques, focusing on learning from limited examples. By leveraging Python and TensorFlow/PyTorch libraries, we'll delve into Model-Agnostic Meta-Learning (MAML). This approach allows machines to adapt to new tasks with minimal data, similar to human-like learning. Applications include medical diagnosis with scarce patient data and personalized recommendations. The project aims to equip participants with deep learning fundamentals, paving the way to develop meta-learning algorithms for efficient learning from sparse datasets.

",4-6,Prerequisite: Basic proficiency in Python and familiarity with machine learning fundamentals.,projects/Few shot.jpeg,https://drive.google.com/file/d/16IsNihxKNggmM3ICDllqQH7bFNdW6S6B/view?usp=sharing,"
Week 1	Introduction to Few-Shot Learning and Meta-Learning
Week 2	Understanding Metric-Learning Algorithms (Matching Networks, Prototypical Networks)
Week 3	Delve into Gradient-Based Meta-Learning (Model-Agnostic Meta-Learning)
Week 4	Deep Dive into MAML Algorithm and Implementation
Week 5	Buffer
Week 6	Exploring Prototypical Networks and Matching Networks
Week 7	Understanding Relation Networks and Advanced Meta-Learning Techniques
Week 8	Introduction to Few-Shot Object Detection and YOLOMAML Algorithm","Checkpoint-1: Understanding Few-Shot Learning and Meta-Learning Algorithms.
Checkpoint-2: Implementing Meta-Learning Algorithms.
Checkpoint-3: Advanced Meta-Learning Techniques and Evaluation Metrics.
Checkpoint-4: Few-Shot Object Detection with YOLOMAML.",ML
16,Aman Moon 22B1216,General Alpha Zero,Dileep Devarajan (22B2136),Machine Learning,"This project is all about creating a smart game-playing computer program. It's inspired by a famous research paper from DeepMind called ""Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"". The idea is to teach the program to play games by itself and get better over time.

To make this happen, we're using a modified version of the Monte Carlo Tree Search (MCTS) algorithm. This helps the program explore different ways the game could play out and learn from them.

The key to success here is a cycle of self-play and learning. The program plays games against itself, learns from those games, and then adjusts its strategies accordingly. This loop continues, with the program improving over time until it reaches saturation.

https://arxiv.org/abs/1712.01815",5,Basic Python Knowledge,projects/r50Q_f1A04Vu613CKTIMBuYEkdUVR2E2e7vpy ... 6C1xWbU7xQIRSTybY=w400-h225-n-nu.webp,https://drive.google.com/file/d/1X7_vTDG4hVj5Z2gmmp5uJMbiojz3wZ_R/view?usp=sharing,"Week 1: Learn the basics of machine learning and deep learning.
Week 2: Study the MCTS algorithm and also the CNN, and ResNet implementation in PyTorch.
Week 3: Review research papers related to the project.
Week 4-8: Implement and train the algorithm.","Checkpoint 1: Implement game rules.
Checkpoint 2: Implement ResNet model with the game state as input and the probability of the next move (policy), along with the winning probability, as output.
Checkpoint 3: Integrate the MCTS algorithm, replacing random simulation at the last node with the ResNet-generated prediction.
Checkpoint 4: Implement the self-play algorithm.
Checkpoint 5: Train the model.",ML
17,Amit Tiwari 22b3006,When 'LLM' meets 'Web-Dev'!,"Ashwani Dubey(22b3024), Sathwik Shetty(22b2209)",Natural Language Processing,"Customizing GPT with Different LLMs: Diving deep into understanding the architecture and capabilities of different LLMs such as GPT, BERT, and RoBERTa. It's fascinating to explore how these models are trained, their strengths and weaknesses, and how they can be fine-tuned for specific tasks or domains.

Integrating NLP Techniques: Beyond just leveraging pre-trained LLMs, incorporating additional NLP techniques like Named Entity Recognition (NER), sentiment analysis, and summarization. Understanding how these techniques work and how they can augment the capabilities of our model is crucial for our project's success.

Deployment with React Frontend: Once our customized model is ready, the focus will shift to deploying it in a user-friendly manner. Integrating it with a React frontend will offer users a seamless way to interact with the model through a web interface, enhancing accessibility and usability.

Learning Resources:

Tutorials and Documentation: The documentation provided by Hugging Face's Transformers library invaluable for leveraging pre-trained language models and fine-tuning them for our specific needs. Additionally, I refer to TensorFlow and PyTorch official documentation for implementing NLP techniques and building models from scratch.

Research Papers: Keep up with the latest advancements in NLP by reading papers from conferences like ACL, NeurIPS, and EMNLP. These papers offer valuable insights into cutting-edge techniques and approaches in the field.",11,"Python skills
Basic web development skills
A general understanding of machine learning will be appreciated.
And most important a lot of enthusiasm to learn ",projects/WhatsApp Image 2024-04-08 at 23.28.30_ffdeef07.jpg,https://drive.google.com/file/d/1CTwRbOjmOkzUgo-QF42WMSjPiXhzXB6d/view?usp=sharing,"Week 1-2 (May 6th - May 19th):

Python basics: Variables, data types, control structures, and functions.
ML basics: Supervised and unsupervised learning, regression, and classification.
Deep learning basics: Neural networks, activation functions, and basic architectures.
Week 3-4 (May 20th - June 2nd):

NLP fundamentals: Word embeddings, sequence modeling, and language models.
LLMs exploration: GPT, BERT, and RoBERTa architecture and applications.
Initial planning for the final project.
Week 5-6 (June 3rd - June 16th):

Advanced NLP techniques: Named Entity Recognition (NER), sentiment analysis, and text summarization.
Fine-tuning LLMs: Customization for specific tasks or domains.
Designing the integration of NLP techniques with LLMs.
Week 7-8 (June 17th - June 30th):

Implementation of integrated system.
Testing, validation, and optimization.
Documentation preparation and final project submission.
Week 9-10 (July 1st - July 10th):

Finalizing React.js frontend.
Conducting extensive testing and debugging.
Submitting the final project by July 15th deadline.","Checkpoint-1: Research and Selection of Language Models

Explore different LLMs such as GPT, BERT, RoBERTa, etc.
Evaluate their architectures, strengths, and weaknesses.
Select the most suitable LLMs for the project based on requirements.
Checkpoint-2: Fine-tuning and Customization of LLMs

Fine-tune the selected LLMs for specific tasks or domains.
Experiment with different hyperparameters and training techniques.
Validate the performance of customized LLMs through thorough evaluation.
Checkpoint-3: Integration of NLP Techniques

Incorporate additional NLP techniques such as Named Entity Recognition (NER), sentiment analysis, summarization, etc.
Implement these techniques in conjunction with the customized LLMs.
Ensure seamless integration and compatibility between different NLP components.
Checkpoint-4: Development of React Frontend

Design and develop a user-friendly React frontend for interacting with the customized language models.
Implement features for inputting text, displaying model predictions, and handling user interactions.
Ensure responsiveness, accessibility, and aesthetic appeal of the frontend interface.
Checkpoint-5: Deployment and Testing

Deploy the entire system, including customized LLMs and React frontend, to a production environment.
Conduct extensive testing to ensure the functionality, performance, and reliability of the deployed system.
Gather feedback from users and stakeholders, and iterate on the system based on their input.",ML
18,Ananya Chinmaya 210070008,IPL Score Predictor Using Deep Learning,Anubha Vyasamudri (210100019),Deep Learning,"This project offers a hands-on opportunity to apply machine learning concepts to real-world sports scenarios.
In this project, we'll dive into the world of cricket analytics using deep learning techniques. You would get to explore historical match data to understand the factors influencing team performance. From team compositions and player statistics to match venues, you would analyze it all to build a model which will act as a score predictor, with given inputs.

Some Resources we will follow are:
1) https://youtube.com/playlist?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&si=RuqTJVfhc9d98pzc
2) https://youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&si=tecW1kirvYDfsdJG ",8-10,No hard prerequisites other than enthusiasm. Although some prior knowledge on Python would be beneficial.,projects/emptystadium.jpg,https://drive.google.com/file/d/11ICTi8Ar10qVRa1z4LVkuOsQTG_DQ8ni/view?usp=sharing,"Week 1-2: Learning Python Basics and familiarizing oneself with common libraries like numpy and pandas
Week 3-4: Watch tutorials on the basics of machine learning and deep learning (theory)
Week 5-6: Familiarizing oneself with machine learning libraries on python such as PyTorch/SKLearn/TensorFlow
Week 7-8: Use preferred library to implement a basic deep learning model on the IPL Dataset to build a score predictor","Checkpoint 1: Learning Basic Python and libraries such as Numpy and Pandas
Checkpoint 2: Learning basic Deep Learning and Machine Learning concepts in theory
Checkpoint 3: Learning to use Machine Learning libraries such as Pytorch/Tensorflow
Checkpoint 4: Implementing knowledge to build a model on given dataset
Checkpoint 5: Fine-tuning model and adding personal touches such as UI",ML
19,Ananya Rao 22B0980,Sketch your videos!,,Image Processing,"The goal of this project is to develop a model which can convert real environment videos(those recorded with camera) to sketch videos(see red bull ad for reference). This will involve learning about feature extraction from images, capturing the outline of the visual scene and much more. To know more, google.",8-10,"Enthusiasm and desire to develop your own models 
Expectations from applicant's proposal - Why do you want to do this project when you could sleep during the summers instead? ",projects/default.png,https://drive.google.com/file/d/1W36GXlpz6ftoRg4J2k9o3O5TnutbDMi1/view,"Week 0-1 | Brush up on basic python and git 
Week 2-3 | Basics of image processing,  get familiar with open CV
Week 4-5 | Towards the final goal - learn project specific topics(feature extraction, edge detection, contours)
Week 6-7 | Develop and train the model","Checkpoint-1: Basic python implementation
Checkpoint-2: Simple openCV project for familiarity
Checkpoint-3: Sketchify an image
Checkpoint-4: Final project",ML
20,Ankit kumar Maurya  22b1266,Q-BOT,"SACHIN AWASTHI (22B1264),TAKSHIT AGGARWAL(22B1236),G.NIVEDHA(22B1815)",Machine Learning,"Create  algorithmic trading bot that leverages machine learning techniques, specifically Random Forest, in conjunction with proven trading strategies like Range Trading, Simple Moving Average (SMA), Golden Cross, and Multi-Data Strategy. The bot aims to optimize day-to-day (intraday) trading activities by continuously adapting its strategies throughout the trading session, thereby maximizing trade turnover and minimizing transaction costs, ultimately leading to significant profits for both individual traders and organizations.
REFRENCE-https://doi.org/10.1051/itmconf/20214003041",9-11,N/A but ML knowledge will be appreciated ,projects/qu_bot.jpg,https://drive.google.com/file/d/1rRrP-4vK2AMCbrPEc0S6vJyGHAes3p8q/view?usp=sharing,"Week 1 - Introduction to trading terms and strategies 

Week 2 -  learning basics of a language ( C++ or Python)

Week 3 - Learning Random Forest and few Genetic Algorithms 

Week 4 - Learning Support vector Machine Regression and Random forests and Gradient boosted decision trees

Week 5- Collecting Dataset and applying it to various models and visualizing it

Week 6 - Integration of Financial Strategies with our bot

Week 7 - Final model submission and documentation","1.Data Acquisition and Preprocessing:

Collect real-time market data from reliable sources, such as financial data APIs.
Preprocess the data to ensure consistency and accuracy, including cleaning, normalization, and feature engineering.
Prepare datasets for training the Random Forest model and for implementing trading strategies.
2.Machine Learning Model Development:
Train a Random Forest model on historical market data to predict price movements and identify trading opportunities.

3.Implement proven trading strategies such as Range Trading, Simple Moving Average (SMA), Golden Cross, and Multi-Data Strategy.
Integrate the Random Forest predictions with the trading strategies to make informed buy/sell decisions.

4.Real-time Adaptation and Optimization:
Develop algorithms to continuously monitor market conditions and adapt trading strategies in real-time.

5.Performance Monitoring and Evaluation:
Implement a comprehensive monitoring system to track the bot's performance, including trade turnover, profitability, and transaction costs.
Analyze key performance indicators (KPIs) and evaluate the effectiveness of the trading bot against predefined benchmarks.
",ML
21,Ansh Kapoor  22b2476,CodeClash: The Battle of Algorithms,Arnav Jain (22b2527),Competitive Programming,"Welcome to CodeClash: The Battle of Algorithms! This project is designed to provide you with an exciting opportunity to participate in competitive programming contests. Each weekend, we'll host contests where you can showcase your programming skills, tackle challenging problems, and learn and grow alongside your peers.

Learning Journey:

Contest Participation: During this project, you'll have the chance to solve a series of programming problems covering various algorithms and data structures. It's a great way to put your skills to the test and see how you fare in a competitive environment.

Problem Solving: As you tackle the contest problems, you'll encounter a wide range of challenges that will test your problem-solving abilities. You'll learn to analyze problems, devise efficient algorithms, and implement solutions.

Learning from Experience: Whether you succeed or encounter difficulties, each contest will provide valuable insights and opportunities for growth. Take the time to reflect on your approach, understand your mistakes, and strive to improve with each contest.

Community Engagement: Engage with your fellow mentees and mentors throughout the project. Share your approaches, discuss strategies, and support each other in your quest to solve the contest problems.

Resources for Your Journey:

We'll provide all the necessary resources, including links to tutorials, practice platforms, and recommended reading materials, to support you throughout your project.

Practice Platforms: Practice regularly on online coding platforms like Codeforces, LeetCode, and HackerRank. These platforms offer a wealth of practice problems across various difficulty levels, allowing you to hone your skills and prepare for the project.",8-10,"Basic understanding of programming fundamentals.
Familiarity with C++
Comfort with basic mathematical concepts.
No prior experience in competitive programming is required; beginners are welcome!",projects/default.png,https://drive.google.com/file/d/1UUqYHj9SU4gVEwIC8cmdzt3BxX-0ei5o/view?usp=drivesdk,"Week 1: Fundamentals of Programming ,  STL Libraries
Week 2: Searching and Sorting
Week 3: Recursion
Week 4: Advanced Sorting , Stack , Queues
Week 5: Introduction to OOPS , Linked List
Week 6: Trees , BST
Week 7: Graphs
Week 8: Dynamic Programming","Checkpoint 1: Weeks 1-2
Complete Fundamentals of Programming and STL Libraries.
Understand Searching and Sorting algorithms.
Begin applying these concepts to simple problems.

Checkpoint 2: Weeks 3-4
Master Recursion and understand its applications.
Learn Advanced Sorting techniques, Stack, and Queues.
Practice solving problems that require recursion and stack/queue implementations.

Checkpoint 3: Weeks 5-6
Introduction to Object-Oriented Programming (OOPS) concepts.
Master Linked List data structure and its operations.
Solve problems related to Linked List and OOPS concepts.

Checkpoint 4: Weeks 7-8
Learn about Trees and Binary Search Trees (BST).
Understand Graph data structure and its operations.
Solve problems related to Trees, BST, and Graphs.

Checkpoint 5: Week 8 (Final)
Learn Dynamic Programming concepts and techniques.
Apply Dynamic Programming to solve complex problems.",CP
22,Antriksh Punia  22b1031 ,Image super resolution ,"Thomas Biju cheeramveli(22b1073),Rijul Bhat(22b0971), Chaitanya Garg (22b0979), Antriksh Punia(22b1031)",Machine Learning,"This project involves thoroughly understanding the basics of machine learning. We plan to focus not only on the implementation part but also the mathematics that goes behind it.

By the end of the project we hope all our mentees would be comfortable with python libraries like numpy and pytorch. Also we hope that they would know what goes on under the hood of a network.

Super resolution involves enhancing the resolution of an image often upto 4 times or more. Applications are immense from improving image quality to increasing the accuracy of computer vision algorithms.

Mentees would be introduced to the concept of adversarial networks that cater to the task of image super resolution and compare them with strongly connected convolution neural networks.

Further mentees would have to select a research paper to work upon, this cultivates critical thinking, exposes mentees to diverse topics, fosters independence, and exposes them to the world of research",15,None but a good grip over python and it's libraries would greatly help throughout the project ,projects/default.png,https://drive.google.com/drive/folders/11cLA2JZxWmB2d2oavejvh4iW2ywcEbEa,"Week 1: learning basics of python, familiarise yourself with numpy and other python Libraries 
Week 2: implementing logistic, linear regression and PCA using numpy 
Week 3: Understanding pytorch and using it to implement a simple feed forward neural network(option assignment: make the neural network using numpy only)
Week 4: Implementing convolution neural network (CNN) along with focus on thoroughly understanding its backpropogation step
Week 5: clearing backlogs and beginning to study the basics of image super resolution.
Week 6: Finalizing a research paper to implement and a dataset to go along with it 
Week 7-8: implementing the research paper.","Checkpoint 1: Implementing PCA and regression using Numpy
Checkpoint 2: Making Neural Network using pytorch
Checkpoint 3: Making CNN for digit recognition using MNSIT dataset
Checkpoint 4: Deciding the Research paper and Dataset for final submission (Requires going through multiple research papers)
Checkpoint 5: Final Implementation of the Research Paper",ML
23,Anumalasetty Varshith 22b0907,Code Canvas - The Text Editor,"Dheeraj Kurukunda (22b0935), Nandan Manjunath Immadisetty (22b0920)",DevOps,"Ever marvelled at the advanced features found in modern text editors like VS Code? 
Want to know how these functionalities are implemented under the hood? In this project, we delve into the fascinating world of software development by starting with the basics: Data Structures and Algorithms.
Each introduction of a new data structure will be paired with interactive hands-on exercises, allowing mentees to enhance our text editor, Code-Canvas, with exciting new features..

Check this videos for an idea about project: https://youtu.be/kkqbh2DEHIQ?feature=shared, 
https://youtu.be/0kNXhFIEd_w?feature=shared",8,"Proficiency in C/C++, Basic idea on OOPs, Willingness to go through large code base",projects/Banner.png,https://drive.google.com/file/d/1_uuTz4hORx_GIYHPndn1CkQ3VNW3GLBU/view?usp=sharing,"Week 1 - Brush up on C++ classes, Github and others
Week 2 - Getting familiar with Vectors, Queues, Stacks, Maps
Week 3 - Learning KMP algorithm, Trie, and suffix trees
Week 4 - Implementing Autocomplete in Code Canvas (Our own text editor)
Week 5 - Autocorrection of words using Edit distance
Week 6 - Heap and Huffman coding, zip file creation
Week 7,8 - Complete Remaining work, Documentation and Presentation","Checkpoint-1: Familiar with using Data structures of C++
Checkpoint-2: Autocomplete in Code Canvas
Checkpoint-3: Autocorrection
Checkpoint-4: Zip file Creation
Checkpoint-5: Exploring Approximation algorithms based on their comfort level",Others
24,Anupam Rawat 22b3982,scam_'92_v2.0,Amitesh Shekhar (22b0014),Machine Learning,"The project seeks to develop an advanced model for predicting stock market trends and potential prices in the near future by leveraging state-of-the-art architectures such as Long Short-Term Memory (LSTM), Generative Adversarial Networks (GANs), and Gated Recurrent Units (GRUs). 
The objective is to utilize historical market data to train these models, thus capturing complex patterns and dependencies in stock price movements. By incorporating LSTM, GANs, and GRUs, the model aims to enhance its ability to learn from sequential and time series data, and generate more accurate predictions. 
This is a link of a research paper, you can refer to for more clarity and understanding - https://thescipub.com/pdf/jcssp.2021.188.196.pdf
You can refer to the below research paper for GANs - https://www.researchgate.net/publication/319869547_Generative_Adversarial_Networks_Introduction_and_Outlook 
For LSTM part, you can refer to the below research paper - https://arxiv.org/pdf/1909.09586.pdf",5-6,"Pre-Requisites for the mentees include:

Basic coding skills with a  familiarity with programming concepts is required. Understanding and enjoyment of the CS 101 course is a hard pre requisite. Must have worked with Python. 
Along with that, although it is not mandatory but a beginner-level Machine Learning knowledge is appreciated.
Apart from this an interest in stock markets, and enthusiasm in a field of Machine Learning is must. The applicant must be perseverant and willing to complete the project.",projects/Stock_Market_Banner.jpg,https://drive.google.com/file/d/1gqZzLLOzlBJdsK9hnH3PhiazEhgolq1y/view?usp=sharing,"Week 0: (Introduction to Stock Market Basics and Programming Fundamentals:) Explore the basics of stock market and brush up your programming fundamentals (especially OOPs fundamentals)

Week 1: (Python Programming and Data Processing:) Brush up your python programming skills. Learn more about pandas and numpy library. Explore Data Processing techniques and filtering out stocks with excessive noise.

Week 2 and 3: (Machine Learning Theory and RNNs and LSTMs:) Learn Machine Learning Theory. Suggested resources - Machine Learning Specialization (by Andrew NG) and Research Papers (eg arxiv). Explore more about RNNs and LSTMs.

Week 4: (Implement LSTM-based Stock Market Prediction Model:) Apply the knowledge gained to implement an LSTM-based stock market prediction model using Python and TensorFlow or PyTorch.

----------------------------------------MID TERM REPORT SUBMISSION---------------------------------------------------

Week 5:(Advanced Architectures - GRUs, GANs, and Beyond:)  Learn about GRUs, GANs and their architectures (optional: explore more state-of-the art architectures who have their potential applications in this field. Extra effort and enthusiasm is always appreciated). Explore research papers and online resources to understand the workings and potential applications of these architectures.

Week 6 and 7: (Implement GAN and GRU Models for Prediction) Implement a GAN model and GRU model to predict the trend and improvise it and optimize it.

Week 8: (Optional Sentiment Analysis and Final Project Report:) (Optionally, explore sentiment analysis techniques to incorporate public sentiment about stocks into the prediction model using Natural Language Processing (NLP).)
Finalize the project, prepare the final report documenting the methodology, results, and any additional insights or improvements made during the project

---------------------------------------------FINAL REPORT SUBMISSION---------------------------------------------------

# Keep track of project progress and milestones to ensure timely completion of tasks.
# Document code, experiments, and results systematically for easier review and future reference.","Checkpoint-1: Learning the Machine Learning theory and its potential applications
Checkpoint-2: Implement the LSTM prediction model for the same
Checkpoint-3: Learn about the state-of-the art models and architectures for implementing the GAN and GRU model.
Checkpoint-4: Implement the GAN and GRU architecture for prediction.
Checkpoint-5: Finalise the project, fine tune your models for more accurate prediciton",ML
25,Apurv Keer 210260007,Simulations in Physics,Mridul Goel (210260033),Computational Physics,"The project is about various simulation techniques in physics. We will use these techniques to make simulations of various physical systems in Fortran programming language. The Physics Department runs a course by the name of Advanced Simulation Techniques in Physics, in which we look at various numerical techniques and implement them in Fortran. This project is inspired by that course (the assignments in the course are in this link - https://drive.google.com/drive/folders/1wuJrL60zTREZkQSCQA11ihxGBAUZVC5r?usp=sharing ). In this project, the mentees will learn to code in Fortran. They will learn various numerical techniques for solving ODEs and systems of equations. Then they will use those techniques to simulate various physical systems, like solving the Poisson equation, visualizing the hydrogen atom, making a Lorentz attractor, etc. Last year, there was a project under SOC by the name of Hands on Computational Physics in which I did these things using python. Here is the link: https://github.com/ApurvKeer/SOC-Computational-Physics.git . Here we will use these topics, but we will make them simpler to simulate using Fortran.",5,Basic coding skills in C++. CS101 knowledge will suffice.,projects/SOC Sim in Phy Poster.png,https://drive.google.com/file/d/1FXjfZ23CBIrsCzSKpQYevtAOGolZDwvJ/view?usp=sharing,"Week 1: Setting up Fortran
Week 2: Getting used to Fortran syntax
Week 3: Learning to solve system of linear equations numerically.
Week 4: Solving the Poisson equation for various charge distributions. 
Week 5: Learning to solve ODEs using Euler and RK methods and using them to solve systems of non-linear equations.
Week 6/7/8: Open ended project OR simulating more complex systems like  Hydrogen atom orbitals and Tight Binding method for 1D lattices (Depending on how mentees respond to initial week process as in if they are capable to do a project on their own).","Checkpoint 1: After setting up Fortran and running basic code.
Checkpoint 2: After the Poisson Equation Project.
Checkpoint 3: After the non-linear equation project and the basic idea for an open-ended project.
Checkpoint 4: Checkup progress on project.
Checkpoint 5: Final project submission.",Others
26,Arnav 22b0664,Facial Recognition and Emotion Analysis in Video Streams,"Pranav Gupta(22B0661), Swapnil Banthia(22B2142)",Image Processing,"The project ""Facial Recognition and Emotion Analysis in Video Streams"" aims to develop a real-time system capable of detecting faces, recognizing individuals, and analyzing their emotional expressions within video streams. Utilizing techniques such as face detection algorithms, facial recognition models, and deep learning-based emotion analysis, the system will identify individuals in the video feed and classify their emotions into predefined categories such as happiness, sadness, or anger. Integration of efficient real-time processing methods and visualization techniques will enable the system to provide immediate feedback on the identities and emotional states of individuals within the video stream",10-15,"None, just basic python and enthusiasm to learn!!!!",projects/delte.jpg,https://drive.google.com/file/d/1sfXA6YMQy2eJj3KsoKfvdpTKBvMXHnVz/view?usp=sharing,"Week 1-2: Getting Started and Mastering the Basics

Week 1: Let's kick things off by setting up your coding environment. You'll need to install Python, Jupyter Notebook, and essential libraries like pandas, numpy, and pytorch. Get comfortable with the basics of these tools.
Week 2: Now that you've got the setup down, it's time to dive deeper. Spend this week exploring pandas, numpy, and pytorch more extensively. Learn how to manipulate data, perform array operations, and grasp fundamental machine learning concepts.

Week 3-4: Exploring Face Detection Techniques

Week 3: This week, we'll focus on understanding how computers can recognize faces in images. We'll delve into classical methods such as the Viola-Jones algorithm and the Histogram of Oriented Gradients (HOG). You'll have the opportunity to implement simplified versions of these algorithms to gain insight into their functionality.
Week 4: Moving forward, we'll explore modern face detection techniques. Learn about advanced approaches like Single Shot MultiBox Detector (SSD) and Faster R-CNN, which are based on deep learning. By the end of the week, you'll have built a basic face detection model using one of these state-of-the-art methods.

Week 5-6: Mastering Facial Recognition Methods

Week 5: Our focus now shifts to recognizing faces. We'll start with traditional methods such as eigenface and fisherface. You'll implement these algorithms and understand their strengths and weaknesses.
Week 6: Delve into modern facial recognition techniques like FaceNet. Learn about advanced concepts such as Siamese networks and triplet loss. By the end of the week, you'll have developed a basic version of FaceNet for facial recognition.

Week 7-8: Understanding Emotion Analysis in Facial Expressions

Week 7: This week is dedicated to studying techniques for analyzing emotions in facial expressions. Learn about feature extraction methods like Local Binary Patterns (LBP) and Histogram of Oriented Gradients (HOG) for emotion recognition.
Week 8: Dive deeper into deep learning architectures for emotion analysis. Study Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) for emotion classification. By the end of the week, you'll have implemented a basic emotion analysis model using deep learning.

Week 9-10: Integration and Project Completion

Week 9: It's time to integrate what you've learned so far - facial detection, facial recognition, and emotion analysis. Develop a pipeline that takes an input image, detects faces, recognizes individuals, and predicts their emotions.
Week 10: Finalize your project by thoroughly testing the integrated system, handling edge cases, and optimizing the code for performance. Document your project and prepare any necessary presentations or report","1: Learn libraries needed for ML (pandas, numpy, pytorch) 

2: Study face detection features like Viola-Jones algorithm, HOG etc

3. Understand modern facial recognition methods like eigenface, fisherface and modern approaches like FaceNet

4. Learn about emotion analysis techniques in facial expressions, including feature extraction and classification using deep learning architectures.

5. Integrate everything learnt so far, facial detection, facial recognition, and emotional analysis.
",ML
27,Arnav Jain 22B2527,CodeClash: The Battle of Algorithms,Ansh Kapoor (22B2476),Competitive Programming,"Welcome to CodeClash: The Battle of Algorithms! This project is designed to provide you with an exciting opportunity to participate in competitive programming contests. Each weekend, we'll host contests where you can showcase your programming skills, tackle challenging problems, and learn and grow alongside your peers.

Learning Journey:

Contest Participation: During this project, you'll have the chance to solve a series of programming problems covering various algorithms and data structures. It's a great way to put your skills to the test and see how you fare in a competitive environment.

Problem Solving: As you tackle the contest problems, you'll encounter a wide range of challenges that will test your problem-solving abilities. You'll learn to analyze problems, devise efficient algorithms, and implement solutions.

Learning from Experience: Whether you succeed or encounter difficulties, each contest will provide valuable insights and opportunities for growth. Take the time to reflect on your approach, understand your mistakes, and strive to improve with each contest.

Community Engagement: Engage with your fellow mentees and mentors throughout the project. Share your approaches, discuss strategies, and support each other in your quest to solve the contest problems.

Resources for Your Journey:

We'll provide all the necessary resources, including links to tutorials, practice platforms, and recommended reading materials, to support you throughout your project.

Practice Platforms: Practice regularly on online coding platforms like Codeforces, LeetCode, and HackerRank. These platforms offer a wealth of practice problems across various difficulty levels, allowing you to hone your skills and prepare for the project.",8-10,"Basic understanding of programming fundamentals.
Familiarity with C++
Comfort with basic mathematical concepts.
No prior experience in competitive programming is required; beginners are welcome!",projects/default.png,https://drive.google.com/file/d/1UUqYHj9SU4gVEwIC8cmdzt3BxX-0ei5o/view?usp=drivesdk,"Week 1: Fundamentals of Programming ,  STL Libraries
Week 2: Searching and Sorting
Week 3: Recursion
Week 4: Advanced Sorting , Stack , Queues
Week 5: Introduction to OOPS , Linked List
Week 6: Trees , BST
Week 7: Graphs
Week 8: Dynamic Programming","Checkpoint 1: Weeks 1-2
Complete Fundamentals of Programming and STL Libraries.
Understand Searching and Sorting algorithms.
Begin applying these concepts to simple problems.

Checkpoint 2: Weeks 3-4
Master Recursion and understand its applications.
Learn Advanced Sorting techniques, Stack, and Queues.
Practice solving problems that require recursion and stack/queue implementations.

Checkpoint 3: Weeks 5-6
Introduction to Object-Oriented Programming (OOPS) concepts.
Master Linked List data structure and its operations.
Solve problems related to Linked List and OOPS concepts.

Checkpoint 4: Weeks 7-8
Learn about Trees and Binary Search Trees (BST).
Understand Graph data structure and its operations.
Solve problems related to Trees, BST, and Graphs.

Checkpoint 5: Week 8 (Final)
Learn Dynamic Programming concepts and techniques.
Apply Dynamic Programming to solve complex problems.",CP
28,Arohan Hazarika 22B3948,"Game On, Ad Up: RL for Intelligent Agents",Siddhartha Rajeev (22B1825),Reinforcement Learning,"The project will be a good start for newbies in the domain of Reinforcement Learning and people with prior experience will have a great time. We would start with covering basics of RL including MDP, Bandits, some simple RL strategies like Monte-Carlo and TD Learning.
We will build autonomous intelligent agents to play games like Tic-Tac-Toe, Taxi (Gym Game) and many more. We will also solve the famous Travelling Salesman Problem using Q-Learning for a new experience. Thereafter, we will progress to the world of Deep Reinforcement Learning and solve more complicated games. After gaining sufficient knowledge, we will start with the most interesting part of the journey - the project!

Mentees will be encouraged to formulate their own problem solving strategies and adapt their solutions to the problem statement. By the end of this project, our hope is to come up with a diverse range of strategies to tackle the challenge of building recommendation systems.

Last but not the least we would urge you to go through this :) -
https://youtu.be/kopoLzvh5jY?si=WWdzfXfAx0RgMPiX

Some Useful Resources-
1)David Silver Lectures : https://www.davidsilver.uk/teaching/
2)Reinforcement Learning: An Introduction by Sutton & Barto
3)https://spinningup.openai.com/en/latest/ : A great resource for exploring Reinforcement Learning",8-10,Basic python skills and lots of enthusiasm!,projects/thumbnail.jpg,https://drive.google.com/file/d/1U-GL7LMz9PYi8iHS0N0T1DHzprV9SbY9/view?usp=sharing,"Week 1: Introduction to Reinforcement Learning and Multi-Armed Bandits
Week 2: Markov Decision Processes (MDPs) and fundamental RL concepts - Value Functions, Policies and Policy Improvement
Week 3-4: Playing simple games like Tic-Tac-Toe, Games based on Open AI Gym, solving the Travelling Salesman Problem using sampling and temporal-difference algorithms like Monte-Carlo, Q-Learning, SARSA and TD(0)
Week 5: Introduction to Neural Networks and implementing a simple NN using TensorFlow/PyTorch
Week 6: Introduction to Deep RL
Week 7-8: Final project - building a commercially relevant recommendation system using Deep Reinforcement Learning techniques acquired through this camp.","Checkpoint 1: Covering theory and solving simple assignments to dive into the field of Reinforcement Learning
Checkpoint 2: Playing games using strategies based on RL algorithms as mentioned above
Checkpoint 3: Getting comfortable with libraries such as TensorFlow and Torch for implementing Deep RL techniques 
Checkpoint 4: Developing strategies using Deep RL to play more complicated games by implementing DQN, A2C and PPO algorithms
Checkpoint 5: Final Project which would be building a commercially relevant recommendation system using Deep Reinforcement Learning techniques acquired through this camp.",Others
29,Arvind Yadav 22B1025,A UNIX journey: Ctrl+Alt+Delight,"Himanshu Gangwal(22B0956), Mayank Motwani(22B1052) and Arihant Vashista(22B0958)",(UNIX-like) Operating Systems,"We will dive into the lovely utilities that *nix based systems offer ( not your regular Windoze machine ). For the first few days, we'll try to make you believe in the saying:
""A computer is like air conditioning – it becomes useless when you open Windows."" - Linus Torvalds. We will begin with the basics of command line tools and create programs to automate file management/ task automations, etc. using scripting languages. (see sched() for more details. . .)
However, this will be largely to familiarize you with UNIX-based operating systems.
We will then move on to another important aspect that we need to take care of before diving into a full-fledged operating system, which is threads and concurrency. 
After familiarizing ourselves with these concepts, we can finally look at a real but simple enough Operating system, viz. MINIX OS.",13,C/C++,projects/socICON.jpeg,https://drive.google.com/file/d/1RwmFs-SDcWfOB8PIgbNdDn2HHy3V6ogv/view?usp=sharing,"POLICY():
#checkpoints will be allied rather lighter exercises that the assignments which in contrast will have greater weightage
and will require significant effort. . .
#each week will have two mentors and atleast one mentor will be same across two consecutive weeks. . .
#checkpoints and assignments may be merged if there's a need to do so in the intrest of time. . .

SCHED(): 
Week1(CommandLineUtils)
Installations, Linux, OhMyZsh, Information about Linux
Intro to CommandLineUtils
Filesystem and Navigation
Processes (ps, jobs, status)
Regex (https://www.regexone.com/)
grep, cut, paste, sort
I/O redirection, piping, concurrent and sequential exectutions
(CHECKPOINT1)
Week2(CommandLineUtils)
Introduction to scripting and automation
batch, cronjobs
misc. makefiles,curl, wget ,etc.
(CHECKPOINT2)
    Assignment 1: To be decided, most likely an automation job
Alternatively, Operating Systems Design and Implementation 3rd Edition
(https://github.com/8427003/study-minix-os/blob/master/OsDesign_text.pdf) can also be used
in place of OSTEP for reference
Week3(ThreadsAndConcurrency)(ref. OSTEP)
Introduction to Threads and Concurrency
Locks
Conditional Variables
(Optional)Concurrency Pzip
(Optional)Concurrency sort
Week4(ThreadsAndConcurrency)
Working with semaphores
Concurrency in Webservers
(Optional)Concurrency MapReduce
(CHECKPOINT3)
    Assignment2:TBD (Mostly going to be a variation of master-worker simulations)

We'll be using MINIX OS, alongside 
Operating Systems Design and Implementation 3rd Edition
(https://github.com/8427003/study-minix-os/blob/master/OsDesign_text.pdf)


Week5(OS)
Intro to Minix
Installation
Intro to the codebase
Customizing the intro/ logon screen/ terminal
Implementing custom commands ~cowsay
Implementing custom syscalls/ extending libc
(CHECKPOINT4)
Week6(OS)
Introduction to memory management
Dynamic memory allocation
(CHECKPOINT3)
    Assignment3: Writing a custom heap allocator
Week7(OS)
Introduction to processes scheduling
Implementing custom scheduling scheme for MINIX
(CHECKPOINT5)
Week8(MISC)
TBD, exploring and trying to implement fun utilities like figlet, toilet, sl, cowsay etc.
","1.Getting used to Command In line Tools
2.Using Scripting for automation
3.Thread and Concurrency
4.Implementing Basic stuffs in MINIX
5. Implementing FIGLET,TOILE,SL,cowsay",Others
30,Aryan Adinath Popalghat 210020088,Speech Emotion Recognition,"Lakavath Sidhartha(210020067), Abhinav Vaishnav(210020003)",Deep Learning,"Speech Emotion Recognition (SER) is a technology that involves analyzing audio signals to detect and interpret the emotions conveyed by the speaker's voice. It goes beyond simple speech recognition by capturing the tone, energy, and other acoustic properties of speech. Scientists use various audio processing techniques to extract features from speech, such as Mel Spectrograms or Mel-frequency cepstral coefficients (MFCCs). Commonly used models for SER include RNNs/LSTMs and CNNs, which are trained to classify emotions based on these features. SER finds applications in various fields, including online learning, HR for candidate evaluation, and call centers for customer service improvement. Common datasets for SER practice include the RAVDESS dataset and TESS dataset. Building SER models typically involves data preprocessing, model architecture design (such as CNN-LSTM), training, and testing. Potential project ideas related to SER include building conversational chatbots, mood-based music recommendation engines, and personalized voice recognition systems.
Reference: https://www.projectpro.io/article/speech-emotion-recognition-project-using-machine-learning/573
Github: https://github.com/siddugithubb/-SpeechEmotionRecognition_Realtime
",8-10,"Basics of Machine Learning and Deep Learning
",projects/default.png,https://drive.google.com/drive/folders/16yLJkJvOSNiAePV3g5n-d261wDY_HxPP,"Week 1: Introduction to Machine Learning

    Basics of Machine Learning: Understand concepts like supervised learning, unsupervised learning, and reinforcement learning.
    Introduction to Python: Learn Python basics, libraries such as NumPy, Pandas, and Matplotlib.
    Start with simple ML algorithms like Linear Regression, Logistic Regression using Scikit-Learn.

Week 2: Intermediate Machine Learning

    Dive deeper into ML algorithms: Decision Trees, Random Forests, Support Vector Machines (SVM), Naive Bayes.
    Evaluation Metrics: Learn about metrics like accuracy, precision, recall, F1-score, and how to choose the appropriate one.
    Hands-on projects: Work on small projects to implement the learned algorithms.

Week 3: Advanced Machine Learning

    Dimensionality Reduction: Principal Component Analysis (PCA), t-SNE.
    Ensemble Learning: Boosting, Bagging techniques.
    Cross-validation techniques.
    Work on more complex datasets and projects.

Week 4: Introduction to Deep Learning

    Basics of Neural Networks: Understand the structure of neural networks, activation functions.
    Introduction to TensorFlow/Keras: Learn to build simple neural networks using TensorFlow/Keras.
    Hands-on project: Implement a simple neural network for classification or regression tasks.

Week 5: Deep Learning Fundamentals

    Deep Dive into Neural Networks: Multi-layer Perceptrons (MLP), Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs).
    Hands-on projects: Implement MLP, CNN, RNN on different datasets for classification tasks.

Week 6: Advanced Deep Learning

    Advanced CNN architectures: Transfer Learning, Fine-tuning pre-trained models (VGG, ResNet, etc.).
    Sequence models: Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs).
    Hands-on projects: Work on image classification, text generation tasks using advanced DL techniques.

Week 7: Speech Emotion Recognition (SER)

    Introduction to SER: Understand the basics of SER, importance, and applications.
    Feature Extraction: Learn about Mel Spectrograms, MFCCs, and their significance in SER.
    Hands-on projects: Start working on implementing SER models using simple architectures like CNNs.

Week 8: Advanced SER and Project Completion

    Advanced SER techniques: Attention-based models, CNN-LSTM architectures.
    Fine-tuning and Optimization: Hyperparameter tuning, regularization techniques.
    Complete project: Implement a robust SER model using advanced DL techniques, evaluate its performance, and fine-tune as required.","1) Completion of Basic ML Concepts and Python Fundamentals (Week 2):
        Ensure participants have a solid understanding of basic ML concepts like supervised and unsupervised learning.
        Verify proficiency in Python programming and key libraries like NumPy, Pandas, and Matplotlib.
2) Hands-on ML Projects (Week 3):
        Evaluate participants' ability to implement ML algorithms like Decision Trees, Random Forests, and SVM on real-world datasets.
        Assess their understanding of evaluation metrics and cross-validation techniques.       3) Transition to Deep Learning (Week 4):
        Confirm participants' grasp of neural network fundamentals and their ability to build basic neural networks using TensorFlow/Keras.
        Ensure they understand the principles behind training neural networks and the importance of activation functions.
4) Advanced Deep Learning Concepts (Week 6):
        Check participants' understanding of advanced DL architectures like CNNs, RNNs, and their applications in image and text processing tasks.
        Evaluate their ability to implement transfer learning and fine-tuning techniques for pre-trained models.
5) Implementation of SER Models (Week 7-8):
        Monitor participants' progress in implementing SER models using Mel Spectrograms and MFCCs.
        Assess their ability to build and optimize SER architectures, including CNNs, LSTM, and potentially CNN-LSTM hybrids.
        Evaluate the performance of their SER models on test datasets and provide feedback for improvements.",ML
31,Aryan Bhosale 210040024,Deep Generative Models: An Odyssey to a new generative model (that we create),-,Deep Learning,"Generative models took the world by storm in all modalities that we as humans can experience - text, image, audio, video. There is no doubt they are the most wonderful manifestation of Artificial Intelligence. This is your guide to generative models of the future. We will cover an exhaustive timeline covering the evolution of generative models from VAEs and GANs to Diffusion and Flow-based models. I hope to empower you to create an indigenous generative model of your own.
P.S. - the cover image was made using a generative model
Links to some applications of what we will be doing:
https://openai.com/sora
https://openai.com/dall-e-2
https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/
https://developers.google.com/machine-learning/gan/gan_structure
https://www.sony.com/en/SonyInfo/technology/activities/STEF2022/exhibition_0203/",10,"Prior knowledge of deep learning and enthusiasm is a must with some experience in coding in Python.

Experience in Torch and TensorFlow is appreciated. 

If your unsure if this course is for you, feel free to reach out via mail or LinkedIn.

Make sure your SOP contains your ML/coding journey describing the projects/courses you've done.

This is a very niche project specifically for those who wish to pursue ML in greater detail in the future. If that's you, welcome aboard!",projects/dgm_soc.jpeg,https://drive.google.com/file/d/1sKbbi5AE9M1f_4X0XBq5gdHNZ21cVOWy/view?usp=sharing,"Actual Timeline will be released later and will only be available to the mentees. 

Brush up on Deep Learning - Neural Networks, U-Net, Encoder-Decoder based Networks

Intro to Variational Autoencoders (VAEs) and implementation

Intro to Generative Adversarial Networks (GANs) and implementation

Intro to Flow based Models and Diffusion Models (DALLE) and implementation

Reading research papers on SOTA generative models and their applications

Intro to Vision Transformers and Diffusion Transformers (SORA)

Innovate a new generative model of your own (we will be brainstorming together)","Understanding and implementing:
VAEs
GANs
Flow-based Models
Diffusion Models
Diffusion Transformers


Creating ideas for a new generative model inspired by all that you have learnt",ML
32,Aryan Kumar 22b2423,Predicting handwritten texts using Deep Learning,Gaurav Bhalerao,Deep Learning,"Welcome to this project, where we embark on the exciting journey of building an alphabet classifier model to classify handwritten letters captured by a camera. This project is like the ""Hello, World! program"" of deep learning, the concepts you'll learn here will create a solid foundation about deep learning and neural networks for you, towards the end of this project we'll also learn how we can test it on our own data! and also to make a UI to see the model live in action!

Suggested Reading 

https://en.wikipedia.org/wiki/MNIST_database
https://www.geeksforgeeks.org/python-introduction-matplotlib/
https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627
https://towardsdatascience.com/data-visualization-for-machine-learning-and-data-science-a45178970be7
https://www.analyticsvidhya.com/blog/2020/02/beginner-guide-matplotlib-data-visualization-exploration-python/
https://towardsdatascience.com/understanding-bernoulli-and-binomial-distributions-a1eef4e0da8f
https://www.probabilitycourse.com/chapter4/4_2_1_uniform.php
https://www.mathsisfun.com/data/standard-normal-distribution.html
https://www.coursera.org/learn/machine-learning
https://medium.com/@saishruthi.tn/math-behind-gradient-descent-4d66eb96d68d
https://stats.oarc.ucla.edu/stata/dae/multinomiallogistic-regression/
https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d
https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc
https://www.youtube.com/watch?v=Xvg00QnyaIY&list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&index=31
https://www.youtube.com/watch?v=G6djH3I0rG0&list=PLreVlKwe2Z0TTN9vNEsMhA2JVswctec2g
http://neuralnetworksanddeeplearning.com/chap3.html
https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU",6,Lots of Enthusiasm,projects/SOC.jpg,https://drive.google.com/file/d/1v-jrzxZAltG-4JHYHcAN1MhOBn89hqt3/view?usp=sharing,"Week 1:

Introduction to Essential Libraries: Begin by understanding the importance and functionality of essential Python libraries - Numpy and Matplotlib.
Exploring Data Distribution: Dive into the concept of data distribution, its significance in machine learning, and its impact on model training.
Week 2:

Linear Regression Fundamentals: Delve into Linear Regression, one of the fundamental algorithms of machine learning. Learn its concepts, implementation, and practical applications.
Logistic Regression Basics: Explore Logistic Regression, focusing on classification tasks. Understand its differences from Linear Regression and its applications.
Week 3:

Understanding Feedforward Neural Networks: Learn the basics of feedforward neural networks, including architecture and information flow.
Deep Dive into Activation Functions: Explore different activation functions such as sigmoid, tanh, and Relu. Understand their properties, advantages, and practical considerations in neural network design.
Week 4:

Optimization Techniques: Dive deeper into optimization problems in neural network training. Focus on gradient descent and backpropagation algorithms.
Loss Functions: Explore the concept of loss functions and their role in minimizing error during training. Understand maximum likelihood, cross entropy, and their application in neural networks.
Week 5:

Implementation of Backpropagation: Learn how backpropagation is used to update model parameters based on calculated errors. Understand its significance in improving model performance.
Training Neural Networks: Explore the process of training neural networks over multiple epochs to minimize loss and increase accuracy.
Week 6:

Multi-class Classification: Dive into multi-class classification using neural networks. Understand how to extend classification beyond binary outcomes.
Building a Classifier for MNIST: Begin building a classifier for the MNIST dataset from scratch using NumPy.
Week 7:

Adapting the Model for EMNIST: Modify the MNIST classifier to work with the EMNIST dataset. Implement necessary changes and evaluate its performance on handwritten alphabet recognition.
Testing Phase with Custom Data: Explore different testing methods, including integrating a drawing app and capturing text images using a camera. Evaluate the model's performance with custom data inputs.
Week 8:

Project Conclusion and Reflection: Reflect on the journey of building and training neural network models. Discuss key learnings, challenges faced, and potential areas for future exploration.","Checkpoint 1: Foundations of Machine Learning

Introduction to Essential Libraries (Numpy and Matplotlib)
Understanding Data Distribution
Checkpoint 2: Regression and Classification

Learning Linear Regression Fundamentals
Exploring Logistic Regression Basics
Checkpoint 3: Neural Networks Basics

Understanding Feedforward Neural Networks
Deep Dive into Activation Functions
Checkpoint 4: Training and Optimization

Implementation of Backpropagation
Exploring Optimization Techniques and Loss Functions
Checkpoint 5: Model Building and Evaluation

Building a Classifier for MNIST
Adapting the Model for EMNIST
Testing Phase with Custom Data",ML
33,Ashish Patel 200260011,Parallelized Scientific Computing Framework,,"Parallel Programming, High Performance Computing","Develop a Python framework for scientific computing that utilizes parallel programming techniques, CUDA for GPU acceleration, and interfaces with C++/Fortran libraries for performance-critical tasks. The framework could include modules for numerical simulations, data analysis, and visualization.",8-10,Basic Python,projects/images.jpeg,https://drive.google.com/file/d/19i7ZIEN97tqL_Z0XyQIcmZIP3fvjV9jt/view?usp=sharing,"Month 1:
Week 1-2: Project Setup and Planning
Define the scope and objectives of the project.
Set up version control (e.g., Git) and establish a repository for the project.
Plan the architecture of the framework and break it down into manageable tasks.

Week 3-4: Implement Parallel Programming
Learn about parallel programming concepts in Python using libraries like multiprocessing and threading.
Implement parallel versions of algorithms for tasks such as numerical integration, matrix operations, etc.

Week 5-6: Integrate CUDA for GPU Acceleration
Study CUDA programming and GPU architecture.
Implement GPU-accelerated versions of computationally intensive tasks using libraries like pycuda or numba.cuda.

Month 2:
Week 1-2: Linking with C++/Fortran Libraries
Learn about interfacing Python with C++/Fortran libraries using tools like Cython or ctypes.
Implement wrappers to call performance-critical functions from C++/Fortran libraries within Python.

Week 3-4: Numba Optimization and Performance Tuning
Explore Numba for just-in-time compilation and optimization of Python code.
Profile the framework for performance bottlenecks and apply optimization techniques.
Benchmark the framework against various test cases and optimize further as needed.

Week 5-6: Documentation, Testing, and Presentation
Write comprehensive documentation for the framework, including usage examples and API references.
Conduct thorough testing to ensure the correctness and robustness of the framework.
Prepare a presentation or demo to showcase the project's features and outcomes.","Checkpoint 1: Project Setup and Parallel Programming Implementation
Checkpoint 2: CUDA Integration for GPU Acceleration
Checkpoint 3: Integration with C++/Fortran Libraries
Checkpoint 4: Numba Optimization and Performance Tuning
Checkpoint 5: Documentation, Testing, and Presentation",Others
34,Ashutosh Agarwal 22B2187,Advanced AI Investment Advisor Chatbot,Ayush Singh (22B2203),Natural Language Processing,"This project is a culmination of the two broad fields viz; Time Series Modelling and the Natural Language Processing (NLP), where you will embark on a journey to redefine personal finance management through via the power of artificial intelligence (AI). The goal of this project is to develop a sophisticated investment assistant bot that seamlessly integrates ML driven analytical models, natural language processing (NLP), and predictive modeling to deliver investment strategies and recommendations, thus empowering the users to navigate the complexities of financial markets with confidence and minimized risk.

Key Features:

This chat bot will implement the algorithms to analyze user profiles, including risk tolerance, investment objectives, and financial constraints (as fed by user), to craft  personalized investment strategies aligned with individual goals thus reducing potential risks.

Based on comprehensive data analysis and user preferences, the assistant will deliver actionable investment recommendations, spanning asset allocation, security selection to optimize returns and minimize volatility. It will also proactively monitor portfolio performance, identify downside risks, and recommend appropriate hedging strategies to safeguard against market volatility.

Project Objectives:

Develop time series modelling AI algorithms capable of processing vast amounts of financial data and generating actionable investment insights.
Implement intuitive and user-friendly chat interfaces, leveraging NLP techniques for natural and fluid interaction.
Conduct rigorous testing and validation to verify the accuracy, reliability, and effectiveness of the AI investment advisor across diverse market conditions.

Technological Stack:

Machine Learning: Python, TensorFlow, time-series modelling and scikit-learn for building predictive models and data analysis.
Natural Language Processing (NLP): NLTK, spaCy for processing user queries and generating contextual responses.
API Integration: Incorporate financial data APIs or Yfinance for real-time market information and analysis.
Frontend Development & Backend Development: We will be providing the responsive and intuitive user interfaces. You can extend this project to bring it on a software to be visually compatible for a user.

As a mentee, you'll have the opportunity to delve into the realms of AI development and financial technology, while contributing to the creation of a investment advisor",7-8,"Intermediate proficiency with Python
Basic Machine Learning
Understanding of Deep Learning is an additional benefit.
And a lot of enthusiasm as this is a rigorous project",projects/pixlr-image-generator-ef627f0a-2652-4993-a30c-35dc5809b5a3.png,https://drive.google.com/file/d/1YIb_msuW3zYPpcHIK8-qzn4a64dqXAft/view?usp=sharing,"Week 1:
Introduction to Advanced Machine Learning, Exploratory Data Analysis, Learning about popular time series forecasting methods such as ARIMA, SARIMA, and Exponential Smoothing.

Week 2:
Implementing basic forecasting models using Python libraries like statsmodels and scikit-learn and Model Evaluation and Validation

Week 3:
Understanding the fundamentals of NLP, including tokenization, stemming, and lemmatization.
Text Preprocessing and Feature Extraction techniques like Bag-of-Words (BoW) and TF-IDF.

Week 4:
Sentiment Analysis: Analyzing sentiment from textual data using lexicon-based approaches and machine learning classifiers.
Named Entity Recognition (NER): Identifying and extracting named entities from text using NLP techniques and libraries.
Part-of-Speech Tagging (POS): Tagging words in a sentence with their respective parts of speech using POS tagging algorithms.

Week 5-6:
Incorporate real time stock data to understand how to correlate NLP inputs like risk tolerance and investment goals to deliver investment strategies to enhance decision making using statistical measures.

Week 7-8:
Integrate open source API to finally build a chatbot providing investment advice based on input which would facilitate communication between different components of the system and external data sources.


","1 - Introduction to Machine Learning, EDA and popular time series forecasting methods
2- Implementation and understanding of stock prediction model using ML frameworks
3 - Understanding basics of NLP and a mini project on sentiment analysis
4 - Incorporate real time stock data to understand how to correlate NLP inputs like risk tolerance and investment goals to deliver investment strategies
5- Integrate open source API to finally build a chatbot providing investment advice based on input.",ML
35,Ashwani Dubey 22b3024,When 'LLM' meets 'Web-Dev'!,"Amit Tiwari(22b3006), Sathwik Shetty(22b2209)",Natural Language Processing,"Customizing GPT with Different LLMs: Diving deep into understanding the architecture and capabilities of different LLMs such as GPT, BERT, and RoBERTa. It's fascinating to explore how these models are trained, their strengths and weaknesses, and how they can be fine-tuned for specific tasks or domains.

Integrating NLP Techniques: Beyond just leveraging pre-trained LLMs, incorporating additional NLP techniques like Named Entity Recognition (NER), sentiment analysis, and summarization. Understanding how these techniques work and how they can augment the capabilities of our model is crucial for our project's success.

Deployment with React Frontend: Once our customized model is ready, the focus will shift to deploying it in a user-friendly manner. Integrating it with a React frontend will offer users a seamless way to interact with the model through a web interface, enhancing accessibility and usability.

Learning Resources:

Tutorials and Documentation: The documentation provided by Hugging Face's Transformers library invaluable for leveraging pre-trained language models and fine-tuning them for our specific needs. Additionally, I refer to TensorFlow and PyTorch official documentation for implementing NLP techniques and building models from scratch.

Research Papers: Keep up with the latest advancements in NLP by reading papers from conferences like ACL, NeurIPS, and EMNLP. These papers offer valuable insights into cutting-edge techniques and approaches in the field.",11,"Python skills
Basic web development skills
A general understanding of machine learning will be appreciated.
And most important a lot of enthusiasm to learn ",projects/default.png,https://drive.google.com/file/d/1CTwRbOjmOkzUgo-QF42WMSjPiXhzXB6d/view?usp=sharing,"Week 1-2 (May 6th - May 19th):

Python basics: Variables, data types, control structures, and functions.
ML basics: Supervised and unsupervised learning, regression, and classification.
Deep learning basics: Neural networks, activation functions, and basic architectures.

Week 3-4 (May 20th - June 2nd):

NLP fundamentals: Word embeddings, sequence modeling, and language models.
LLMs exploration: GPT, BERT, and RoBERTa architecture and applications.
Initial planning for the final project.

Week 5-6 (June 3rd - June 16th):

Advanced NLP techniques: Named Entity Recognition (NER), sentiment analysis, and text summarization.
Fine-tuning LLMs: Customization for specific tasks or domains.
Designing the integration of NLP techniques with LLMs.

Week 7-8 (June 17th - June 30th):

Implementation of integrated system.
Testing, validation, and optimization.
Documentation preparation and final project submission.

Week 9-10 (July 1st - July 10th):

Finalizing React.js frontend.
Conducting extensive testing and debugging.
Submitting the final project by July 15th deadline.
","Checkpoint-1: Research and Selection of Language Models

Explore different LLMs such as GPT, BERT, RoBERTa, etc. Evaluate their architectures, strengths, and weaknesses. Select the most suitable LLMs for the project based on requirements.

Checkpoint-2: Fine-tuning and Customization of LLMs

Fine-tune the selected LLMs for specific tasks or domains. Experiment with different hyperparameters and training techniques. Validate the performance of customized LLMs through thorough evaluation.

Checkpoint-3: Integration of NLP Techniques

Incorporate additional NLP techniques such as Named Entity Recognition (NER), sentiment analysis, summarization, etc. Implement these techniques in conjunction with the customized LLMs. Ensure seamless integration and compatibility between different NLP components.

Checkpoint-4: Development of React Frontend

Design and develop a user-friendly React frontend for interacting with the customized language models. Implement features for inputting text, displaying model predictions, and handling user interactions. Ensure responsiveness, accessibility, and aesthetic appeal of the frontend interface.

Checkpoint-5: Deployment and Testing

Deploy the entire system, including customized LLMs and React frontend, to a production environment. Conduct extensive testing to ensure the functionality, performance, and reliability of the deployed system. Gather feedback from users and stakeholders, and iterate on the system based on their input.
",ML
36,Ashwin Panchal 210020026,ChirpIt : Social Media Web App,Dheeraj Kumar Solanki (210020041),Web Development,"ChirpIt is a social media project, developed with Node.js, Express.js, React, and database systems like MySQL or PostgreSQL. Mentees learn backend setup, REST API development, authentication with JWT, React frontend design, Recoil state management, and deployment.",8-10,Lots of enthusiasm and a basic understanding of programming fundamentals.,projects/banner.png,https://drive.google.com/file/d/1hgyJ1SyKhhZ4hKzurXEdaXVRT_pPPFdS/view?usp=sharing,"Week 1: Introduction to web basics - JavaScript, HTML, CSS.
Week 2: Git basics and backend setup with Node.js and Express.
Week 3: RESTful API implementation and basic database management.
Week 4: Database design and authentication setup.
Week 5: Frontend development with React and UI design.
Week 6: State management and additional feature implementation like live chat.
Week 7: Optimization, and deployment.
Week 8: Documentation and final review.","Checkpoint 1: Backend Setup and API Development with Express.js.
Checkpoint 2: Database Integration and Schema Design.
Checkpoint 3: Authentication System Implementation with JWT.
Checkpoint 4: Frontend Development using React and UI Design.
Checkpoint 5: Optimization, and Deployment",Development
37,Avaneesh Sai 210070015,Implementation of Out-of-Order commit on ChampSim,,Computer Architecture,"Current out-of-order processors use in-order commit so that they can provide precise exceptions. Orinoco, a paper that came out in ISCA 2023, proposes out-of-order commit while dealing with the issues that come with it. The paper has implemented the same in Gem5 simulator, and we shall try to implement the same in ChampSim. ",6,Basics of Computer Architecture is recommended,projects/0_pPgqu6f2zz76HrQE.jpeg,https://drive.google.com/file/d/1ifxoaAwc5GB4OZmrTA0Ox1Op-tHg-wj1/view?usp=sharing,"Week 1 and Week 2 - Computer Architecture Fundamentals (OoO processors for people who are comfortable with the basics of Comp Arch, the rest shall cover the basics as well)
Week 3 and Week 4 - Introduction to ChampSim and gaining complete familiarity with the front-end of the CPU implemented by Champsim
Week 5 - Reading Orinoco, implementing the AGE matrix, and testing the same
Week 6 - Integrating the AGE matrices and other relevant structures with the required structures in the microarchitecture
Week 7 - Verification of unordered commit working, tabulation of results and relevant useful information","Checkpoint 1 - Strengthening computer architecture fundamentals
Checkpoint 2 - Development of sound understanding of front-end in ChampSim
Checkpoint 3 - Successful implementation of matrices and relevant structures individually
Checkpoint 4 - Integration of new structures with the current structures present in ChampSim
Checkpoint 5 - Achieving complete functionality of unordered commit in ChampSim",Others
38,Avipsa Swain 22B2168,Speech Emotion Recognition,,Deep Learning,"Objective:
Develop a machine learning model for accurately recognizing and classifying emotions conveyed in speech to enhance human-computer interaction in applications like customer service, virtual assistants, and mental health monitoring.

Dataset:
Utilize diverse audio recordings from publicly available datasets such as RAVDESS and EMO-DB, labeled with emotions including happiness, sadness, anger, fear, disgust, and neutrality.

Model Architecture:
Explore a combination of signal processing techniques, including MFCCs, prosodic features, and statistical features, along with deep learning models such as CNNs, RNNs, or hybrid architectures like CRNNs. Incorporate attention mechanisms to focus on important audio segments.

Training and Evaluation:
Split dataset into training, validation, and testing sets. Employ hyperparameter tuning and cross-validation techniques to optimize model performance and prevent overfitting. Evaluate based on metrics like accuracy, precision, recall, and F1-score across emotion classes.

Deployment:
Once achieving satisfactory performance, deploy the model in real-world applications with scalability in mind, potentially integrating into existing systems, APIs, or standalone applications for efficient handling of real-time audio inputs.

https://blog.dataiku.com/speech-emotion-recognition-deep-learning

https://github.com/lorenanda/speech-emotion-recognition/tree/main/speech_emotion_recognition",7,,projects/Banner.jpg,https://drive.google.com/file/d/1F_64qDL2a32Qm5Rqz_JJNizIUudxs1zo/view?usp=sharing,https://docs.google.com/document/d/1RQv90XUzvBwT-DynOSY-aMMQNs9_iUqAEbans8YLEE0/edit?usp=sharing,"Checkpoint 1: (After week-3)
Data Handling Preparation:
Ensure that you're proficient in basic data handling tasks such as loading data, understanding its structure, handling missing values, and performing exploratory data analysis (EDA) using tools like Pandas.

Checkpoint 2: (After week-6)
Feature Extraction Proficiency:
Master the use of Librosa library for extracting audio features and experiment with various techniques like MFCC, Spectral Contrast, or Mel-Scaled Spectrograms to effectively represent audio data.

Checkpoint 3: (Mid week-7)
Project Proposal Finalization:
Finalize the project proposal, outlining clear goals, objectives, and the selected dataset along with its relevance to Speech Emotion Recognition. Establish success criteria for the project.

Checkpoint 4: 
Model Development Progress:
Make substantial progress in developing a baseline deep learning model for Speech Emotion Recognition, ensuring it's trained, evaluated, and fine-tuned to achieve optimal performance.

Checkpoint 5: Project Completion
Deployment and Documentation Finalization:
Successfully deploy the trained SER model using a framework such as Flask or FastAPI and thoroughly document all aspects of the project, including data preprocessing, model architecture, training process, evaluation metrics, and deployment instructions. ",ML
39,Ayan Tanwar 22b0931,Visual Tales : Image Caption Generator,"Sarthak Chaurasia(22b1014) , Shikhar Kunal Verma(22b2201), Danish Siddiqui (22b2104) ",Deep Learning,"Our aim is to study the foundational deep learning models to be used for image captioning. We start off from the very basics thus covering neural networks, image pre processing, and proceed towards state-of-the-art transformer based image captioning models. We learn and implement the ideas of convolutional neural networks (CNNs), recurrent neural networks (RNNs) and long short-term memory (LSTM) models. Towards the end, we will learn to deploy the model by integrating it as a chat bot on discord/telegram.

The project will be highly collaborative, with mentees being strongly encouraged to participate in numerous group discussions with both the mentors and other mentees. Most assignments will be team based and will involve a decent amount of Python programming using libraries such as keras and Pytorch.

People who are just starting out in their machine learning journey and are interested in working with image based models are encouraged to apply. No prior experience in deep learning or image processing is required, just great enthusiasm and a knack for learning new things.",10-12,Basic programming skills,projects/default.png,https://drive.google.com/drive/folders/1lwfvNcQmjV5OjFIO06_qmrvd8fHrnIgS?usp=sharing,"
Week 1: Introduction to Python fundamentals including Object-Oriented Programming, Pandas, Numpy, and Matplotlib.
Week 2: Exploring basic Machine Learning concepts such as Linear Regression and Logistic Regression.
Week 3: Creating a Neural Network using Pytorch ,analysing use of different optimization techniques.
Week 4: Constructing a Convolutional Neural Network and exploring different architectures.
Week 5: Developing a Recurrent Neural Network, LSTM .
Week 6: Analyzing and reviewing state-of-the-art research papers on advanced image caption endoder decoder  models based on attention mechanism and transformer.
Week 7: Completing the final project.
Week 8: Basic MLOps and deploying model as Discord/Telegram bot","Checkpoint-1: Implementation of ANN using pytorch(or tensorflow) 
Checkpoint-2: Implementation of CNN architecture using pytorch
Checkpoint-3: Implementation of RNN architecture
Checkpoint-4: Reviewing Research Papers based on Image captioning
Checkpoint-5: Implementation of final Image Captioning Model",ML
40,Ayush Kumar 22B0689,Alphabet Recognition Through Gestures —Deep Learning and image processing,"Kshaunish chandalia,22b2117",Machine Learning,"image processing techniques such as edge detection, contour analysis, and motion tracking to capture and analyze the hand gestures in real-time.
Deep Learning Fundamentals: Understanding the basics of deep learning, including neural networks, training processes, and optimization algorithms for building an effective recognition model.
Model Training and Evaluation: gain hands-on experience in data preprocessing, model training, and performance evaluation using popular deep learning frameworks like TensorFlow or PyTorch.
https://www.kaggle.com/code/bryanb/cnn-for-handwritten-letters-classification
https://www.geeksforgeeks.org/create-air-canvas-using-python-opencv/
OpenCV Documentation 
",6,should be able to understand logics ,projects/default.png,),"8104630334,ayushkr7apr04@gmail.com","Week 1: Project Introduction and Setup
Introduction to the project goals, objectives, and technologies involved.
Set up development environment: install necessary libraries (OpenCV, TensorFlow/PyTorch), IDEs, and Explore sample datasets and familiarize mentees with the data structure.

Week 2: Image Processing Basics
Dive into image processing fundamentals: grayscale conversion, thresholding, edge detection (e.g., Canny edge detector), and contour analysis.
Implement basic image processing operations using OpenCV.
Begin developing the gesture recognition module to capture hand movements.

Week 3: Advanced Image Processing Techniques
Learn about more advanced image processing techniques like morphological operations, Hough transform, and motion tracking.
Implement motion tracking algorithms to track hand gestures in real-time.
Test and refine the gesture recognition module with sample hand gesture data.

Week 4: Introduction to Deep Learning
Introduction to deep learning concepts: neural networks, layers, activation functions, loss functions, and optimization algorithms.
Explore deep learning frameworks (TensorFlow or PyTorch) and set up a basic neural network architecture for alphabet recognition.
Begin training the initial version of the deep learning model using synthetic data.

Week 5: Data Preparation and Augmentation
Dive deeper into data preprocessing techniques: normalization, resizing, and data augmentation.
Prepare the dataset for training: collect and preprocess real-world hand-drawn alphabet images.
Augment the dataset to increase its diversity and robustness.

Week 6: Model Training and Optimization
Train the deep learning model using the augmented dataset.
Experiment with different network architectures, hyperparameters, and optimization algorithms to improve model performance.
Monitor training progress, analyze loss curves, and fine-tune the model as needed.

Week 7: Integration and User Interface Design
Integrate the gesture recognition module with the trained deep learning model.
Design a user-friendly interface for real-time alphabet recognition,.
Test the integrated system.

Week 8: Final Testing and Documentation
Conduct comprehensive testing of the complete system, including functionality, accuracy, and user experience.
Debug any issues and optimize performance for smooth operation.
Document the project workflow, including code documentation, and usage instructions.
Prepare a final demo showcasing the project's capabilities and achievements",ML
41,Ayush Patel 22B3027,Image Caption Generator using CNN and LSTM,"Jayesh Ahire, (22B2101)",Deep Learning,"This project aims to build an image caption generator using Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks. The project involves:
1) Understanding CNNs and LSTMs and their application in image captioning.
2) Preprocessing image and text data from the Flickr_8K dataset.
3) Extract features from images using CNN predefined model (Xception).
4) Tokenizing text data to map words to numerical indices.
5) Designing and training a CNN-LSTM model to generate captions for images.
6) Evaluating the model's performance and iterating for improvements.

Reading material and resources:
""Deep Learning"" by Ian Goodfellow, Yoshua Bengio and Aaron Courville
""Natural Language Processing with Python"" by Steven Bird, Ewan Klein and Edward Loper
TensorFlow documentation: https://www.tensorflow.org/
Keras documentation: https://keras.io/",8-10,"Familiarity with Python programming language
Basic understanding of deep learning concepts
Understanding of CNNs and LSTMs is a plus",projects/default.png,https://drive.google.com/drive/folders/165yo9-g7YhVFcwjj-dT9ZxpSmMUV8Erw?usp=sharing,"Week 1: Understanding CNNs and LSTMs, exploring the Flickr_8K dataset
Week 2: Preprocessing image and text data, tokenizing text data
Week 3: Extracting features from images using pre-trained CNN model
Week 4: Designing and implementing the CNN-LSTM model architecture
Week 5-6: Training the model and optimizing hyperparameters
Week 7: Evaluating the model's performance and debugging
Week 8: Finalizing the project, documenting the code, and preparing for presentation","Data Preparation: Preprocess image and text data, tokenize text data.
Feature Extraction: Extract features from images using a pre-trained CNN model.
Model Design: Design and implement the CNN-LSTM model architecture.
Training and Optimization: Train the model, optimize hyperparameters and evaluate performance.
Documentation and Presentation: Document the code, results and findings. Prepare for presentation or demonstration.",ML
42,Ayush Singh 22b0672,Diving Into CNN,Vipul Mishra (22b0671),Image Processing,"This project is an introduction to the world of ML, and particularly Computer Vision. We'll start off by teaching basics of AI/ML and delve into the different kinds of models used in industry currently. We'll try to cover week 1 of the material of 2nd notion link and week 2, if time permits and mentees are interested. This project will be mostly for freshers or for someone new to the domain of AI/ML.
Basics of AI/Ml
https://wids-2023.notion.site/WIDS-PROJECT-3f543ec7a36b4f978b2324890b893bec
CNN(week 1 majorly and maybe week2)
https://glow-pillow-0b7.notion.site/WiDS-DeepVision-Odyssey-Navigating-the-Depths-of-Visual-Learning-c92bc0bf86c840f484fd854fed9315d7
",6-8,,projects/technics-central-processing-unit-hardware-technology-wallpaper-preview.jpg,https://drive.google.com/file/d/14xkrNfE7HhitdiGbH3dMxcT-Yhb4SS63/view?usp=sharing,"Week 1& 2- Introduction to AI/ML and Basics of ML like Neural Networks etc.( Andrew Neg's Courses etc.)
Week3 - Implementation of NN using Numpy
Week 4 & 5- Introduction to Pytorch
Week 6&7 - Introduction to Well established CNN models and Transfer learning
Week 8 - Final Project Report Submission ","C1 : Basics of Neural Networks
C2 : Implementation of NN using Numpy
C3 : Implementation of NN using PyTorch
C4: Transfer Learning Assignment
C5: Report Submission",ML
43,Bhaskar Biswas 22b1834,Sentiment analysis on social media trends using transformer models,"Abhimanyu Singh Rathore(22b1806), Shanttanu Oberoi(22b1823)",Natural Language Processing,"Develop a sentiment analysis tool that specifically targets discussions around major events like elections, sports events, or product launches. The tool would use natural language processing (NLP) to analyze social media posts, identifying and categorizing public sentiment into positive, negative, and neutral.
https://www.researchgate.net/publication/359860049_Transformer-based_deep_learning_models_for_the_sentiment_analysis_of_social_media_data
",7,Basics of machine learning,projects/banner.jpg,https://drive.google.com/file/d/1Mar719uXfYGRcfOv37xupH7WlUo8mwLw/view?usp=sharing,"Week1- Review basic machine learning concepts, focusing on python implementations.
Week2 - Study the basics of transformer models, Explore sentiment analysis, its applications, and how it's implemented using transformer models.
Week3 - Continue with advanced learning on transformer architectures, like Generative Pretrained Transformers (GPTs).
Week4 - Building a basic transformer model on python using various python libraries such as tensorflow or pytorch.
Week5 -  Learn about preprocessing the data, including cleaning, tokenization, and normalization.
Week6 -  Gather datasets for training and testing the sentiment analysis model. Learn about the various different methods for building the model.
Week7 - Continue building the model with the various APIs to use.
Week8 - Fine-tuning and Testing the performance of the final model  to evaluate the model's accuracy, efficiency, and reliability in sentiment analysis.","Checkpoint-1: Completion of foundational learning in machine learning and python
Checkpoint-2: Understanding of transformer models and sentiment analysis basics
Checkpoint-3: Development of a prototype transformer model
Checkpoint-4: Completion of dataset acquisition from various social medias and initial model training
Checkpoint-5: Finalization and testing of the sentiment snalysis model",ML
44,Bhavya Sri Kottana  22B0981,Disease prediction from symptoms ,Nakka Sai Deepthika ,Machine Learning,"Are you a budding ML enthusiast eager to kickstart your learning journey or looking to apply your skills in a real-world project? Join us and gain hands-on experience in machine learning through building classification models

This project aims to develop machine learning model that predicts diseases from symptoms, offering you the perfect opportunity to dive into the fascinating field of machine learning. This revolutionizes healthcare by enabling early diagnosis, personalized treatment, and efficient resource allocation. These models analyze symptoms to identify high-risk patients, detect disease trends in real-time, and support clinical decision-making.

By the end of the project, you'll acquire proficiency in Python programming, particularly in utilizing libraries like NumPy for data manipulation and preprocessing. Additionally, you'll gain hands-on experience in implementing classification algorithms . This includes understanding the theoretical foundations of these algorithms and applying them effectively to real-world datasets.",5-8,No prior experience needed—just bring your enthusiasm and curiosity:) (Python would be soft prerequisite.),projects/default.png,https://drive.google.com/file/d/1W_oftcLGQ5lmLu45w2AFp0nt_SN5NfRg/view?usp=drivesdk,"Week 1-2: Basics of Python, Introduction to NumPy, Introduction to Pandas
Week 3: Introduction to Machine Learning
Week 4-5: Some classification algorithms like SVC and Naive Bayes Classifier
Week 6: Random Forest Classifier and Cross Validation 
Week 7-8: Working on the final project and Documentation ","Checkpoint-1: Using NumPy and Pandas for dataset analysis and manipulation 
Checkpoint-2: Gaining basic understanding of Machine Learning 
Checkpoint-3: Understanding of Classification algorithms 
Checkpoint-4: Application of Classifiers through assignment 
Checkpoint-5: Final Project ",ML
45,Bibhuti Kumar Mishra 210040035,Extending testing and optimising Boost.Multiprecision library,Not any,Competitive Programming,"The project focused on enhancing the Boost.Multiprecision library by optimizing mathematical functions for higher precision, reaching up to 10K digits. Integral to this endeavor was the implementation of various equations within the C++ codebase to bolster functionality and performance.
For instance, devising two distinct methods for square root calculation - the Newton-Raphson iteration and Karatsuba square root - significantly improved efficiency, with the latter demonstrating remarkable performance enhancements. Additionally, integrating the Newton-Raphson method for k-th root computation yielded substantial gains, particularly evident with large digit numbers. Moreover, implementing the log AGM method for logarithm computation showcased notable efficiency improvements, especially for higher precision values. The inclusion of multiple pi computation algorithms, like Gauss-Legendre and Quadratic Borwein, further contributed to performance enhancements, as validated by rigorous testing.
To delve deeper into these equations and their application within C++ coding contexts, mentees can explore specialized literature such as ""Numerical Recipes in C++"" by Press et al. and ""The Art of Computer Programming"" by Donald E. Knuth. Additionally, engaging with online resources like math-focused forums and academic papers can provide valuable insights, enriching both mathematical understanding and C++ programming skills.",Not any,Not any except enthusiasm,projects/Boost.png,https://drive.google.com/file/d/10pKqzTA-LaB7X0-kUcCq2IJsWZicISuw/view?usp=sharing,"Week 1: Familiarization and Setup
- Task 1: Familiarize mentees with the Boost.Multiprecision library and its existing functionality.
- Task 2: Set up development environments and ensure mentees have necessary tools installed.
- Task 3: Review basic concepts of C++ programming language, focusing on data types and control structures.

Week 2: Square Root Optimization
- Task 4: Study the Newton-Raphson iteration method for square root calculation.
- Task 5: Implement the Newton-Raphson method for square root calculation in C++.
- Task 6: Test and debug the implemented method for accuracy and efficiency.

Week 3: Karatsuba Square Root
- Task 7: Research the Karatsuba algorithm for square root calculation.
- Task 8: Implement the Karatsuba square root method in C++.
- Task 9: Compare the performance of the Karatsuba method with the Newton-Raphson method.

Week 4: K-th Root Computation
- Task 10: Understand the Newton-Raphson method for k-th root computation.
- Task 11: Implement the Newton-Raphson method for k-th root computation in C++.
- Task 12: Evaluate the efficiency and accuracy of the implemented k-th root method.

Week 5: Logarithm Computation
- Task 13: Study the log AGM method for logarithm computation.
- Task 14: Implement the log AGM method for logarithm computation in C++.
- Task 15: Validate the implemented logarithm method through testing and benchmarking.

Week 6: Pi Computation Algorithms
- Task 16: Explore various algorithms for pi computation, including Gauss-Legendre and Quadratic Borwein.
- Task 17: Implement selected pi computation algorithms in C++.
- Task 18: Analyze and compare the performance of different pi computation methods.

Week 7: Integration and Documentation
- Task 19: Integrate implemented methods into the Boost.Multiprecision library codebase.
- Task 20: Document the implemented functionalities, including usage examples and performance considerations.
- Task 21: Prepare a comprehensive report summarizing the contributions and findings.

Week 8: Finalization and Review
- Task 22: Finalize any pending tasks and address feedback from project mentors.
- Task 23: Conduct a thorough review of the project's codebase and documentation.
- Task 24: Prepare for project presentation or demonstration to showcase the completed work and lessons learned.","Checkpoint 1: Square Root Optimization
- Implement the Newton-Raphson method for square root calculation in C++.
- Test and debug the implemented method for accuracy and efficiency.

Checkpoint 2: Karatsuba Square Root
- Implement the Karatsuba square root method in C++.
- Compare the performance of the Karatsuba method with the Newton-Raphson method.

Checkpoint 3: K-th Root Computation
- Implement the Newton-Raphson method for k-th root computation in C++.
- Evaluate the efficiency and accuracy of the implemented k-th root method.

Checkpoint 4: Logarithm Computation
- Implement the log AGM method for logarithm computation in C++.
- Validate the implemented logarithm method through testing and benchmarking.

Checkpoint 5: Pi Computation Algorithms
- Implement selected pi computation algorithms (e.g., Gauss-Legendre, Quadratic Borwein) in C++.
- Analyze and compare the performance of different pi computation methods.",CP
46,Charel Jaykumar Kanjibhai 20D070022,Votechain,"Siddhartha Shekhar Kusum, 20d070077",Blockchain Development,"This project aims to develop a blockchain based electronic voting system in Python.

Why Blockchain?
Blockchains are being used to cut out the middleman and create a secure, decentralized way for service providers and customers to connect and transact safely and directly.

Where is it important to cut the middleman?
You guessed it right : It is indeed in elections

What can we do?
With the knowledge of Blockchain, we can create a secured, tamper-proof Electronic Voting System to avoid any adultery during elections.

We will start with understanding the basics of blockchain, how blockchain works, and the
implementation of BitCoin which will include some understanding of cryptography. We will then start building upon the simulated prototype of the blockchain to understand its each building block in detail. We will simulate a blockchain while implementing vote casting, block generation, block mining, proof of work, and cryptographic signatures. It will contain basic functions for the users like view contesting candidates, cast vote which will be registered securely and anonymously, and display the result at the end.

It is important to note that this project might be a bit heavy on the learning side, so applicants should be well prepared for the same.",8,Basics of Python,projects/default.png,https://drive.google.com/file/d/1a9uytJEIEBA1Jg3YB8_a3ActHUGJeHyY/view?usp=share_link,"Week 1

Reading material for this week -

- [Python Basics](https://www.w3schools.com/python/) (you can leave file handling onwards part)
- [Understanding Blockchain](https://www.tutorialspoint.com/blockchain/index.htm) (Upto Proof of work)
- [Bitcoin white paper](https://bitcoin.org/bitcoin.pdf) (Only the sections 1, 2, 3 and 4)


Week 2

Reading Material for this week - 

- [Understanding Blockchain](https://www.tutorialspoint.com/blockchain/index.htm) (Proof Of Work, Network, Incentives and Privacy)
- [Bitcoin white paper](https://bitcoin.org/bitcoin.pdf) (Only the sections 5, 6, 9 and 10)

Week 3

Reading material for this week -

- [Bitcoin white paper](https://bitcoin.org/bitcoin.pdf) (revise all the sections)
- [Understanding Blockchain](https://www.tutorialspoint.com/blockchain/index.htm)

Week 4

This week we will build an implementation plan for VoteChain which should contain the following things -

- All classes that will be required
- Methods to be defined in each class (only names and their description, not the complete implementation)
- A flow chart describing which function is called when

Note: Keep in mind that we are only simulating a blockchain, so we cannot implement some parts of the blockchain like updating target threshold, actual broadcasting between physically divided nodes, building the complete merkle tree for each block etc.

Week 5

This week we will start the implementation","- Kickstarting with Bitcoin White paper , Understanding Cryptography, Basics of Python and git
- Reading Recent Paper(s) based on E voting System and Implementation Plan for Backend
- Implementation of important classes and identifying the required internal functions
- Wrapping up backend implementation
- Adding mentioned APIs for users",Blockchain
47,Cherish Jain 22b3937,The Ultimate AI Bucket Projects List: Bridging Research & Application  ,"Ayush Gaur(22b3973), Chaitanya Keshri(22B2472)",Machine Learning,"This project presents an unparalleled opportunity for students eager to plunge deep into the realm of machine learning. 
If you happen to follow Apple Smart watches, they had just released their latest smart watch  ""Apple Watch Ultra 2"". It detects hand gesture so as to receive Calls.... It also predicts various Health vital parameters .Are you excited to learn how it works and how it detects various Health parameters......Well, we will be learning that as a sub-project in this 8 week long project along with various other brief aspects of Machine Learning.

Over eight weeks, participants will explore how smartwatches utilize machine learning to detect vital parameters like heart rate and Respiration Rate. Through hands-on sessions, students will grasp the basics of convolutional neural networks (CNN) and implement various machine learning models such as random forest (RF), CNN, and logistic regression (LR) to predict vital parameters using datasets.

The project then transitions to cutting-edge concepts like Generative Adversarial Networks (GAN), where students will learn about GAN through practical implementations on large dataset(We will be using Google Collab GPU if your PC doesn't have one.....). 

After that, we'll delve into Reinforcement learning and create a game where a snake can play itself.

After that in the end week, as a Bonus we'll also see the Hand gesture technique in Apple Watch and how it works....we may not implement it but will sure catch a good idea about it's working and implementation process.",13-16,"No Hard Pre-req, though existing python knowledge would aid the learning process",projects/soc_pic.jpg,https://drive.google.com/file/d/1fA5qRjdda-DJSFyuLiCGvQPIqBZsoU8U/view?usp=sharing,"Week 1 to 3:
1) Python Learning and Introduction to how Smart watches detect Heart Rate, RR, Stress and various Vital Parameters using Machine Learning. This will involve skimming through 1-2 basic Research Papers (dw..... wont require much knowledge....)
2)Understanding pyPPG Library and preprocessing of Dataset and Gain Understanding on Basic CNN
3) Implement a research paper using various ML models such as Random Forest, CNN, Linear Regression on the dataset and compare the results(We will actually predict Heart rate and some other parameters)


Week 4 to 6:
4) Understand GAN(Gen. Adversarial Network) (Some cool trendy shit..... xd:>)
5) Assignment on GAN
6) Implement GAN on a styleGAN Dataset so as to Create deepfake Images( Will be a lot of fun xd:>)

Week 7 to 8:
7,8) Make an AI game having a self playing snake using Reinforcement Learning ","1-Introduction to how Smart watches detect Heart Rate, RR,
2-Gain Understanding on Basic CNN
3-Implement a research paper
4-Implement GAN on a styleGAN Dataset
5-Make an AI game having a self playing snake",ML
48,Chiransh Somani 22B1202,Data Structures & Algorithms (C++),Kaushal Malpure,Competitive Programming,"Our project aims to simplify learning data structures and algorithms by focusing on practical implementation. Participants will explore concepts like arrays, OOPs, linked lists, trees, heaps, graphs and dynamic programming, understanding their effective application. Using platforms like LeetCode, CodeStudio, and GeeksforGeeks, they'll solve problems of different difficulties. Weekly assignments are supposed to be submitted via a shared GitHub repo. We will also conduct weekly meetings to track the progress of each mentee, address any doubts, and provide additional support as needed.",8-10,"Basic knowledge of C++, including basic STL functions as well as a good grasp on CS101",projects/DSA logo.png,https://drive.google.com/file/d/1TRUUTSL65mmJtvT8x2HoOc_sBRSjErpT/view?usp=sharing,"Week 1 - Arrays, binary search, different sorting methods like bubble sort, selection sort, and insertion sort
Week 2 - Strings, pointers, recursion, understanding and calculating the time complexity of different algorithms
Week 3 - Understand object-oriented programming structures and linked lists
Week 4 - Stacks, queues, deques, binary trees, and different methods of their traversal
Week 5 - Heaps, hashmaps, and graph algorithms such as Dijkstra's, Kruskal's, and Kosaraju's algorithms
Week 6 - Dynamic programming (1-D)
Week 7 - Dynamic programming (2-D)","Checkpoint-1 : Complete 10 questions, including easy/medium/hard, based on arrays, searching and sorting
Checkpoint-2 : Complete 6-7 questions, including easy/medium/hard, based on strings, pointers and recursion
Checkpoint-3 : Complete 10 questions, including easy/medium/hard, based on linked lists, stacks, queues, deques and binary trees
Checkpoint-4 : Complete 6-7 questions, including easy/medium/hard, based on heaps, hashmaps and graph algorithms
Checkpoint-5 : Complete 10 questions, including easy/medium/hard, based on dynamic programming",CP
49,Daksh Anchaliya  22B0641,Competitive programming,Nopes,Competitive Programming,"We would delve into the realms of competitive programming by learning various topics and solving problems from various websites such as codeforces,spoj and some chinese websites too. Prior experience in Cp is highly appreciated and kindly mention ur handles.",5,"Stl,Bit manipulation,basic number theory.",projects/Screenshot (736).png,https://drive.google.com/file/d/16cRvDCQ8kIGnVLu6vYzMSPeYMa8yJaHS/view?usp=sharing,"
1. Number theory
2. Miscellaneous topics (greedy algorithms, geometry, string algorithms...)
3. Binary search and two pointers
4. Backtracking, divide and conquer
5. Graphs_(first half)
6. Dp_(first half)
7. Graphs
8. Dp","Ch1 : Upto topic 4
Ch2 : Upto topic 8",CP
50,Daksh Soni 22B2150,PriceTrackr,Yuvraj Khandelwal (22B0726),App Development,"In this mobile app development project, you'll explore Frontend and Backend technologies to create a dynamic price tracking application. Beginning with JavaScript, HTML, and CSS, you'll transition to React Native for mobile app development. We'll delve into backend development using kotlin, utilizing frameworks like Springboot, and MySQL for database management.

The goal is to develop an intuitive mobile application enabling users to track prices of products across various online platforms. Users can search for products, receive real-time price updates, and set price alerts for desired items.

You'll start with mini-projects to grasp foundational concepts before moving to the main app development phase. The app will feature a user-friendly interface, seamless navigation, and integration with APIs for product data retrieval. This project will give you an introductory experience into the world of software development with an actual hands-on project, that you might even use :)",5-6,"Interest in development. No background other than CS101 needed.
(Some knowledge about HTML, CSS and JavaScript is preferable)",projects/PriceTrackr.png,https://drive.google.com/file/d/17Aa7jpdGCYkWEspHpaGxiRu9EL14jSi4/view?usp=sharing,"Week 1: Introduction to App development(languages and frameworks)
Week 2: Working on Mini Projects like calculator, budget tracker. 
Week 3: Web scraping and data collection.
Week 4-5: API development and integration, DB management.
Week 6: Testing and iterative debugging.
Week 7: Frontend design and Deployment.","1. Implementation of App Development using mini-projects.
2. Setting up Frontend using React Native.
3. Setting up Backend using Springboot.
4. API development and integration.
5. Testing and Design/UI changes.",Development
51,Dasari Venkata Sai 210070024,Image segmentation for self driving cars,"Bekate Mahesh Dnyaneshwar(210070020), Motupalli Yaswanth(210050099)",Machine Learning,"In the realm of autonomous vehicles, it's crucial for the car to have a precise understanding of its surroundings. This project involves developing a machine learning model that can segment an image captured by the self-driving car's camera, meticulously classifying each pixel. The goal is to assign each pixel to a specific category, such as:

Road
Lane markings
Vehicles (cars, trucks, motorcycles)
Pedestrians
Cyclists
Traffic signs and signals
Buildings
Vegetation
With this level of detail, the self-driving car can make informed decisions about navigation, avoiding obstacles and adhering to traffic rules.
Learning Objectives: ML techniques 
Resources:
GitHub Repositories:
Semantic Segmentation for Self-Driving Cars (https://github.com/qiaoxu123/Self-Driving-Cars/blob/master/Part3-Visual_Perception_for_Self-Driving_Cars/Module5-Semantic_Segmentation/Module5-Semantic_Segmentation.md): This repository provides a good starting point, using a U-Net architecture with TensorFlow for semantic segmentation.
Awesome Semantic Segmentation (https://github.com/mrgloom/awesome-semantic-segmentation): A curated collection of resources, including research papers, code implementations, and datasets, for semantic segmentation tasks.
YouTube Tutorials:
DeepLab for Semantic Image Segmentation (https://m.youtube.com/watch?v=b6jhopSMit8): A TensorFlow tutorial demonstrating how to use DeepLab, a popular framework for semantic segmentation.
Semantic Segmentation with PyTorch (https://m.youtube.com/watch?v=IHq1t7NxS8k): A tutorial introducing semantic segmentation concepts and implementing a basic model with PyTorch.",5,Prerequisites are none. Interest in image processing is appreciated. Basic knowledge about python and deep learning is a bonus but not necessary.,projects/default.png,https://drive.google.com/drive/folders/1X2kxVoCblWPYk12HhonTk7yYwvDUlnq8?usp=drive_link,"Week 1: Introduction & Setting Up of environment
Week 2: Data Acquisition & Preprocessing
Week 3: Learning Image Segmentation Models
Week 4-5: Model Implementation & Training
Week 6: Model Refinement & Optimization
Week 7: Project Wrap-Up & Documentation
Week 8: (Optional) Future Directions & Exploration","Checkpoint 1: Foundational Knowledge & Environment Setup 
Checkpoint 2: Data Preparation & Exploration
Checkpoint 3: Model Selection & Conceptualization
Checkpoint 4: Model Implementation & Evaluation
Checkpoint 5: Project Finalization & Communication",ML
52,Dattaraj Salunkhe 22B1296,Visual Spotlight: Mapping Regions of Interest using Computer Vision,"Saurabh Srivastava, 22B1294",Image Processing,"Objective: To build a model that can detect and localize specific objects in images. We will be implementing the Single Shot Multibox Detector (SSD), a popular, powerful, and especially nimble network for this task. There are some important steps that will be carried out in this project and have been listed below : 
Single-Shot Detection: A region proposal network that performs object localization and a classifier for detecting the types of objects in the proposed regions.

Multiscale Feature Maps. In image classification tasks, we base our predictions on the final convolutional feature map – the smallest but deepest representation of the original image. In object detection, feature maps from intermediate convolutional layers can also be directly useful because they represent the original image at different scales.

Priors. These are pre-computed boxes defined at specific positions on specific feature maps, with specific aspect ratios and scales.

Multibox. This is a technique that formulates predicting an object's bounding box as a regression problem, wherein a detected object's coordinates are regressed to its ground truth's coordinates. In addition, for each predicted box, scores are generated for various object types.

Non-Maximum Suppression. At any given location, multiple priors can overlap significantly. Non-maximum suppression (NMS) is a means to remove redundant predictions by suppressing all but the one with the maximum score.",15,Intermediate proficiency in Python,projects/Banner.png,https://drive.google.com/file/d/1tRnS-ZGrCuiE4gYWaNs-V9Fb-amz51r_/view?usp=sharing,"Week 1, 2 —> Literature on the topic and videos of Deep Learning
Week 3,4 —> Understanding and deployment of VGG based architecture
Week 5,6 —> Understanding and deployment of single shot detection
Week 7,8 —> Implementation of multibox, non-max suppression and deployment of final project","1) Literature Reading
2) Deployment of VGG based architecture
3) Deployment of single shot detection
4) Implementation of multibox, non-max suppression
5) Final Project",ML
53,Dhriti Maniar 22b2176,Digit Recognizer,Atharva Kolte (22b1203),Machine Learning,"You will learn the fundamentals of machine learning, starting from simple classification, regression to simple neural networks. By the end of this summer, you will be armed with enough knowledge to build your own model and finish the final project: Building a Digit Recognizer. This will include a large training data of handwritten digits from which your model will learn and be able to identify and classify other digits. This project focuses on building a strong ML base which will spark further interest and lead to the undertaking of more complex projects in the future. So if you are a beginner, this is the perfect start for you to dive deep into the depths of Machine Learning!",6-8,,projects/default.png,https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.kaggle.com%2Fcompetitions%2Fdigit-recognizer&psig=AOvVaw2G7M5Hp43ELagDIldXnWfE&ust=1712681668558000&source=images&cd=vfe&opi=89978449&ved=0CBIQjRxqFwoTCODHooqLs4UDFQAAAAAdAAAAABAE,"Week 1: Getting to know your mentors, co-mentees and starting off with an introduction to ML and its applications, linear algebra essentials for those struggling, PCA, SVD, preparation of data,
Week 2:  preparation of data, perceptron learning algorithm and variations to it, SVM, least square method, linear regression, multilinear regression, logistic regression
Week 3: multinomial regression, K-nearest neighbors,  Naive- Bayes, LDA, QDA, Regularization, cross-validation
Week 4: Decision-trees, random forest, mini project to strengthen basic concepts 
Week 5: Simple neural networks, feed forward, backward propagation, intro to CNN and RNN
Week 6-7: Final Project: Digit Recognizer","Checkpoint-1: completion of assignment based on topics upto SVM
Checkpoint-2: mini-project
Checkpoint-3: assignment on neural networks
Checkpoint-4: model building for final project
Checkpoint-5: Final project     ",ML
54,Dhruvi Ganatra 21d070027,Image colourization,"Hrithik Mhatre , Mehul Agarwal",Image Processing,"Image colourization of black-and-white images is one of the most exciting operations in image processing. It has many applications in aesthetics and visual enhancement. One way to do it is by converting it into LAB space. We will be following the given research paper:
https://arxiv.org/pdf/1603.08511.pdf
The demo of what the final project would be like can be found below",10,,projects/colorise.jpg,https://drive.google.com/file/d/1SUYFQUC11r_xFMP0KykYRLrLhbgAY22y/view?usp=sharing,"Week 1 : Introduction to image processing fundamentals
Week 2 :  Introduction to basic CNN architecture
Week3: Using CNNs to classify images
Week 4 and Week 5 : Implementation of image colourisation architecture","Checkpoint 1 - Introduction to ML libraries like Pytorch
Checkpoint 2 - IP Fundamentals
Checkpoint 3- CNNs for image classification
Checkpoiint 4- Understanding the LAB space
Checkpoint 5 - Final implementation",ML
55,Divyadarshan Soni 22b0387,The Pixel Playground: Exploring UI/UX Development,"Prashabdhi Athawale, 22b0363",UI/UX Development,"Dive into the world of UI/UX Development through this project which introduces you to all key concepts that one requires for their Design path. You will learn how to use Figma and related platform, their tools and how to efficiently use them. Also you will get to know about design theories and apply all of these on mini projects every week. Finally you will design your own Online Learning App Platform. This projects requires no prior knowledge but will require you to work regularly.
You can always go through the ANT Design Guidelines: (https://ant.design/docs/spec/introduce) or read an article about color theory
(https://99designs.com/blog/tips/color-meanings/)",10,,projects/Gemini_Generated_Image_59lywm59lywm59ly.jpeg,https://drive.google.com/file/d/1x1sunVCgAYeOB_6vEC1gcPiSQKEyrx8A/view?usp=sharing,"Week 1 - 
1) Introduction to Design
2) Familiarisation with Figma and it's tools
3) Making of first Figma Design

Week 2 -
1) Understanding of Design Fundamentals
2) Introduction to Design theories.
3) Project - Designing a Instagram post

Week 3 -
1) Wireframing and it's concepts
2) Introduction to wireframing platforms
3) Project - Making of first Wireframe

Week 4 -
1) Introduction to Advanced Color Theory
2) Making mockups out of the wireframes
3) Project - Revamp a popular app

Week 5 - 
1) Introduction to Advanced tools like components.
2) Prototyping in Figma
3) Project - Prototyping of the previous project

Week 6 -
1) Understanding UX (user experience)
2) Animations and advanced prototyping
3) Project -  E- commerce website design

Week 7 and 8 -
1) Final Project  - Designing an Online  Learning app platform featuring courses, degrees, certificate programs, etc
2) Applying all the concepts to improve the project","Checkpoint 1) Introduction to Figma and it's tools
Checkpoint 2) Wireframing
Checkpoint 3) Making of low fidelity mockups.
Checkpoint 4) Understanding UX concepts 
Checkpoint 5) Final Project",Development
56,Divyansh Tripathi 210260015,Competitive Programming using C++.,Ayushi Priya (210020029),Competitive Programming,"In this project, goal for mentors is to achieve an intuition for Competitive Programming in C++ (best language known for CP). Although mentees are free to do CP in any language of their choice, I will provide resources for that too. By the end of the project, mentees are supposed to have a very attractive coding profile and strong grip over fundamentals for data structures and algorithms. Mentees are supposed to solve questions on Leetcode and Codeforces regularly and give regular contests there.
Resources will contain online resources for algorithms involved in CP.",12,"CS101, but not necessary.",projects/Screenshot 2024-04-08 232241.png,https://drive.google.com/file/d/1xra-UZraYwmp8Otv1Twg-_9Tv0wegrI7/view?usp=sharing,"Week 1: Basics (basic math, patterns, and hashing) and C++ STL/Java collections
Week 2: Linear Data Structures (Array, String, Linked Lists, Stack and Queue)
Week 3: Searching and Sorting Algorithms
Week 4: Bit Manipulation, Two Pointer and Sliding Window
Week 5: Greedy Algorithms
Week 6: Recursion and Backtracking
Week 7: Non Linear Data Structures (Binary Trees, Binary Search Tree, Heaps, Graphs, Tries)
Week 8: Dynamic Programming (Memoization, Tabulation and Space Optimization)","Checkpoint-1: Implementation of very basic algorithms (basic maths, patterns etc)
Checkpoint-2: Implementation of Searching and Sorting Algorithms
Checkpoint-3: Greedy Algorithm
Checkpoint-4: Recursion and Backtracking
Checkpoint-5: Memoization, Tabulation and Space Optimization in Dynamic Programming",CP
57,Divyansh Tripathi 210260015,Intro to MERN stack: A Course Selling Web Application (Like Udemy/Coursera),Ayushi Priya (210020029),Web Development,"Mentors will learn to make a course selling application for both admin and user side using the MERN(MongoDB, Express, React.js and Node.js) stack. The web application will contain both the frontend as well as backend of the project. If time is spare, we will move further to next.js and typescript for the frontend part, but mostly we will stick to react and recoil. 
Mentors are supposed to build a frontend and backend and connect them both.",5-7,Basics of javascript and knowledge of git/github is appreciated but not necessary.,projects/Mern.png,https://drive.google.com/file/d/1sFLmU4FjmQbe8jnY762qoy-_9X54RCb6/view?usp=sharing,"Week 1: Basics of HTML, CSS and javascript, intro to git/github
Week 2: Async, awaits, callbacks, promises
Week 3: Express, Node.js, Intro to backend systems
Week 4: Middlewares and Authentication. Requests and Responses.
Week 5: Intro to reconcilers, frontend. Intro to react.js
Week 6: React effects and custom hooks
Week 7: State management in react. context, recoil and prop drilling
Week 8: MongoDB and intro to databases","Checkpoint-1: Working with Git/Github. What are push/pull requests, how to contribute to projects on Github.
Checkpoint-2: Learning javascript along with basics of HTML, CSS. Asynchronous functions, awaits and promises in Javascript. Ways to write a particular javascript function (arrow functions more specifically).
Checkpoint-3: Express using Node.js, making of backend using express.
Checkpoint-4: Implementation of react.js in making the frontend. Learning to use recoil and state management in react.
Checkpoint-5: Intro to MongoDB and how to implement in backend of the website.",Development
58,Entenuka Jogarao (Joy) 22b2702,Image Classification from scratch,"Utkarsh Maurya - 22b3910 (Contact : 8005379332), Shubhdeep Singh - 22B0454 (+917303426733)",Machine Learning,"Here's an overview of what students will learn from this 8-week course on Python for Machine Learning and Image Processing:

1. Python Fundamentals for Machine Learning:
   - Understanding data types, variables, loops, and functions in Python.
   - Manipulating data structures like arrays/lists and dictionaries.
   - Implementing basic algorithms and logic required for machine learning tasks.

2. Image Processing with OpenCV and Pillow:
   - Performing image manipulation, filtering, resizing, and other operations using OpenCV and Pillow libraries.
   - Reading and saving images, handling different image formats.
   - Preprocessing images for machine learning tasks like feature extraction.

3. Basic Machine Learning Algorithms:
   - Learning foundational machine learning algorithms such as linear regression, logistic regression, decision trees, and k-nearest neighbors.
   - Understanding the concepts of training, testing, and evaluating machine learning models.
   - Applying algorithms to real-world datasets and evaluating model performance.

4. Deep Learning with Tensorflow and Keras:
   - Building neural networks using Tensorflow and Keras libraries.
   - Defining model architecture, including layers, activation functions, and optimization techniques.
   - Training deep learning models on various datasets and understanding the importance of hyperparameter tuning.

5. Convolutional Neural Networks (CNNs):
   - Understanding the theory and architecture of Convolutional Neural Networks (CNNs).
   - Implementing CNN layers such as convolutional layers, pooling layers, and fully connected layers.
   - Applying CNNs to image-related tasks such as image classification, object detection, and segmentation.

6. Project Implementation (Image Classification):
   - Applying the acquired knowledge and skills to a real-world project on image classification.
   - Preprocessing image data, defining and training CNN models.
   - Evaluating model performance, optimizing hyperparameters, and documenting the project.

Overall, students will gain a comprehensive understanding of Python programming for machine learning, image processing techniques, basic and deep learning algorithms, and their practical application in solving image-related tasks. They'll develop hands-on experience through project-based learning, which will prepare them for further exploration and specialization in the field of machine learning and computer vision.

The project will ensure that the necessary resources are carefully selected to cover the fundamental topics required, making them available as needed throughout the project.",12,"Basic understanding of python would be helpful however, we'll be doing everything from scratch. ",projects/default.png,https://drive.google.com/drive/folders/13CXOKurx8ytG83UiD0y6_WCIcRfqSDa0,"Here is the proposed Week Wise plan for the project :

Week 1: Basics of Python for Machine Learning
  - Data types, variables, and control structures
  - Python libraries for ML: NumPy, Pandas

Week 2: Introduction to Image Processing using OpenCV and Pillow
  - Image manipulation: reading, writing, and filtering
  - Geometric transformations and color space operations

Week 3: Introduction to Basic ML Algorithms
  - Supervised learning algorithms: linear regression, logistic regression
  - Decision trees, k-nearest neighbors (KNN)

Week 4: Tensorflow and Keras
  - Deep learning frameworks: TensorFlow, Keras
  - Neural network basics: layers, activation functions, optimizers

Week 5: CNN Model Architecture
  - Convolutional Neural Networks (CNNs) architecture
  - Feature extraction, pooling, and fully connected layers
  - Transfer learning and pre-trained models

Week 6-8: Project Implementation (Image Classification)
  - Data preprocessing: augmentation, normalization
  - CNN model training, hyperparameter tuning
  - Model evaluation: accuracy, precision, recall
  - Results visualization and project documentation

This structured plan ensures a gradual progression from Python basics to advanced concepts in machine learning and image processing, culminating in a hands-on project to apply the learned skills in a real-world scenario.

The timeline is subject to change based on the project's specific requirements.","CheckPoint: 1 - Completion of Basics of Python and Introduction to Image Processing:
By the end of Week 2, ensure that participants have a solid understanding of Python basics for machine learning and are familiar with essential libraries like OpenCV and Pillow for image processing.

CheckPoint: 2 - Understanding Basic ML Algorithms and Introduction to Tensorflow/Keras: By Week 4, participants should have a good grasp of basic machine learning algorithms and be comfortable using Tensorflow and Keras for building neural networks.

CheckPoint: 3 - Finalizing CNN Model Architecture:
By the end of Week 5, participants should have finalized their Convolutional Neural Network (CNN) model architecture for the image classification project. This includes choosing layers, activation functions, and optimization techniques.

CheckPoint: 4 - Project Setup and Data Preparation:
In Week 6, focus on setting up the project environment, gathering and preprocessing the dataset for image classification. Ensure that participants are ready to start implementing their CNN models.

CheckPoint: 5 - Project Implementation and Evaluation:
By the final week, participants should have completed the implementation of their CNN models for image classification. Conduct evaluations to assess model performance and provide feedback for improvement if needed. Additionally, encourage participants to document their project and share their learnings from the entire process.

These checkpoints should help in monitoring progress and ensuring that participants are on track throughout the 8-week project.",ML
59,Gaurav kannaujiya 22b2147,Build a Modern Real Estate Marketplace with react MERN Stack,Rohit Kumar (22b0766),Web Development,"In this project, I am going to build a Modern Real Estate Marketplace using the MERN Stack. Throughout this project, you will learn HTML, CSS, React.js, MongoDB, Node.js, and Express. For the frontend, we will primarily use React, which is a JavaScript library.

This project will include the following features: authentication functionality, Redux Toolkit for improved state management, advanced search functionality, and deployment of our fully functional MERN stack website using the Render platform.

Resources
-MDN Web Docs
-W3Schools
-React & Redux Complete Course (2024) by KG Coding by Prashant Sir
-Full Stack Web Development for Beginners by freeCodeCamp.org
",5,No prerequisites,projects/default.png,https://drive.google.com/file/d/1ZvZjjnaoteoVPS3paKgMht0LMb-ufE4D/view?usp=drive_link,"1- Basic Introduction to HTML, CSS, React, and Node.js.
2- Frontend Design Development using React.
3- Adding Functionalities using React.
4- Database Creation using MongoDB.
5- Integration of Backend and Frontend.
6- Deployment of the App using the Render platform.","1.Frontend Development with React:

2.Backend Development with Node.js and Express:

3.Integration of Backend and Frontend:

4.Advanced Functionality and State Management:

5.Deployment using the Render Platform:
",Development
60,Gaurav kannaujiya 22b2147,"Build Your Own Code Editor using HTML, CSS, JS, and ReactJS ",Adithya Dileep (22b2204),Web Development,"In this project, I am going to build an online code editor where you can run C++, Java, JavaScript, and Python code. Throughout the course, we will utilize HTML, CSS, and React for the frontend, and for the backend, we will use an API. At the end of the project, we will combine these components.

This project will include the following features:
Support for four languages (C++, Java, JavaScript, Python).
Ability to save your code in the online editor.
Import and export functionality for your code in the editor.
Customizable themes for the editor.",5,,projects/Code Editer.png,https://drive.google.com/file/d/1XrIaKRtxctD0aOmfBMJ7MF-JqTu7a9P4/view?usp=sharing,"Week 1: Frontend Development
Set up project structure with HTML, CSS, and React.
Design basic UI elements for code editor.

Week 2: Backend Development
Integrate code execution for C++, Java, JavaScript, and Python.

Week 3: Integration
Connect frontend and backend.
Test API functionality.

Week 4: Additional Features
Implement code saving and import/export.
Add customizable themes.

Week 5: Testing and Debugging
Test application for bugs and performance issues.
Address any discovered issues.

Week 6: Deployment and Finalization
Prepare for deployment.
Deploy application.
Document project and reflect on the process.","1.Frontend Development with HTML, CSS, and React:
2.Backend Development with API:
3.Integration of Frontend and Backend
4.Implementing Additional Features:
5.Testing and Deployment:",Development
61,Hanish Dhanwalkar  210100060,RL in Cybersecurity ,Na,Network and Cyber Security,"Intrusion detection using RL, 
This is the project I worked under prof. Amit Sethi and then applied the concept of IDS in my InterIIT (Certin Cybersecurity PS).
Project will involve:
Exploring RL algorithms for intrusion detection in network, learning  network monitoring tool like wireshark, netcat, burpsuit, etc., work with a large number of features in the network (like protocol being used in the network, type of communication, transfer rates, etc), choosing right RL algo (I have used deep Q learning and PPO for my projects, many different algos can be discussed), integration of the model with network tools.
If time permits IPS (intrusion prevention systems) can also be integrated.",6 to 8,"Basics of ML, enthu:)",projects/default.png,Will share soon,"1, 2 week: introduction to problem and literature review 
2,3,4 week: intro to RL algos
4,5 week: learning networking tools
5,6,7 week: implement IDS
8+ week: wrapping up and further reading ","C1: implement RL algo
C2: integration of RL in tool",Others
62,Hardik Gohil 22B1293,Virtual Try-On Closet using GAN,"Sreekar Reddy(22B1274), Madhava Sriram(22B1233), Preetam Bhanoth(22B1254)",Image Processing,"Create a virtual try-on system that allows users to upload their images and see how different clothes look on them. This involves understanding body postures and sizes, and overlaying clothing items realistically.
Technologies: Computer Vision, GANs (Generative Adversarial Networks), OpenCV, PyTorch.",5-6,Python,projects/default.png,https://drive.google.com/file/d/1Jg4mJvmEbfnfidf38rZYrj5dqL9LXe9P/view?usp=drive_link,"Week 1: Introduction and Environment Setup
Review the awesome-virtual-try-on GitHub page and other relevant resources to understand the scope and technologies involved.
Install and set up your development environment, including Python, PyTorch, OpenCV, and other necessary libraries.
Week 2: Deep Dive into Computer Vision
Begin with OpenCV to learn about basic and advanced image processing techniques.
Start exploring PyTorch, focusing on understanding its application in image processing tasks.
Week 3: Generative Adversarial Networks (GANs)
Study the theory behind GANs and their application in generating realistic images.
Week 4: Pose Estimation
Explore pose estimation models and understand how they can be utilized in a virtual try-on system.
Week 5: System Architecture Planning and Data Preparation
Finalize the system architecture, including data flow and component interaction.
Collect and preprocess datasets needed for pose estimation and clothing overlay, preparing them for training or testing.
Week 6: Clothing overlay module
Develop the core components of the system, focusing on integrating pose estimation and beginning work on the clothing overlay module.
Start coding the overlay functionality, experimenting with basic transformations of clothing items to fit the user's pose.
Week 7: Refinement and User Interface
Refine the overlay technique, incorporating more advanced features for realism.
Develop the user interface, focusing on simplicity and functionality, allowing users to upload images, select clothing, and see the try-on results.
Week 8: Testing, Documentation, and Review
Conduct comprehensive system testing, focusing on overlay accuracy and user experience.
Document the project, detailing technical specifications, user instructions, and development insights. Review the project outcomes, gather feedback, and outline future improvements or additional features for subsequent iterations.
","Checkpoint 1: Understanding Project Scope and Technologies
Checkpoint 2: Deep Dive into Computer Vision and PyTorch
Checkpoint 3: GANs and Pose Estimation
Checkpoint 4: System Architecture Planning and Data Preparation
Checkpoint 5: Core Development, User Interface, and Testing
",ML
63,Hardik Patil 22B2406,WinGive - digital wings for Non-Profit,-,App Development,"This project intends to prepare a mobile app platform for Non-Profit organizations. Many NGOs can't cater to their members and beneficiaries easily through digital platform such as mobile app. Our project aims to develop digital capabilities for NGO to simplify their activities. NGO can adapt our platform ""WinGive - digital wings for Non-Profit"" and improve effectiveness of their operations. This platform will help NGO to build trust and confidence amongst their stakeholders such as Beneficiary, Volunteers and Donors. 

This development project shall give following learnings and exposures to the mentees:-
1. Learn mobile app development tools and techniques
2. Coding (Flutter , React Native)
3. User experience through mobile app
4. Software development life-cycle
5. Database (SQL)
6. UI/UX designing and tools/techniques for the same
7. Software testing (formation of test cases)",12,"Pre-requisites for mentees:-
1. Enthusiasm
2. Basic Understanding of Coding 
3. Love of learning
4. Problem Solving Attitude
5. Perseverance 
6. Responsible
7. Collaborative
8. Interest in designing
9. Dedication
10. Time management
11. Punctuality",projects/banner.jpg,https://drive.google.com/file/d/1LpHvoeNLU32pjBOzp9nStz5bh5zVIEvP/view?usp=sharing,"1.	Project Setup:		                        1-May-24    to    8-May-24
2.	UI/UX Design:		                        9-May-24  to   19-May-24
3.	Authentication and Profile Management:		20-May-24	to   27-May-24
4.	Push Notifications:		                28-May-24    to    4-Jun-24
5.	Location Tracking:		                5-Jun-24	 to    13-Jun-24
6.	Search Functionality:		                14-Jun-24	to    24-Jun-24
7.	Messaging/Chat:		                        25-Jun-24	 to     5-Jul-24
8.	Social Media Integration:		        6-Jul-24    to    21-Jul-24","1. Project Setup
2. UI/UX Design
3. Authentication and Profile Management
5. Location Tracking
8. Social Media Integration
9. Payment Gateway Integration
10. Testing",Development
64,Hari Bhavsar 22b0934,One Program to Outspeed them All,"Geet Singhi (22b1035), Brian Mackwan (22b0413), Shravan S (22b1054)",Computer Architecture,"Parallel computing on CPU using hyperthreading and Single Instruction Multi-Data (SIMD) type instructions. Parallel computing on GPU using openCL. Finally, creation of either a machine learning library or an optimized SAT solver. ",24,Willingness to learn about systems and implementation close to hardware,projects/GPU.jpg,https://drive.google.com/file/d/1lN4R7lpJhdexnybPV1oGvbKzmjrXNSRx/view?usp=sharing,"Week 0 : Setup of WSL and basic C/C++ style coding
Week 1 : Introduction to threading libraries
Week 2 & 3 : SIMD instructions and their usage for matrix operations
Week 4 & 5 : Introduction to openCL
Week 6 : Applications of openCL
Week 7 & 8 : Implementing either an ML library or a SAT solver ","End of Week 1
End of Week 3
End of Week 5
End of Week 6
End of Week 7",Others
65,Harman Agrawal 22b3012,Development of a logical game,none,Game Development,"For a course project, I had to come up with a ruleset for a game. I have coded a basic version of this game in python using tkinter for the interface. I wish to make this into a proper web-based application (both single-player and multi-player) using python, html, CSS, etc. and put it on the web for anyone to play. The ruleset is somewhat similar to the game Othello in terms of the logic being implemented and I will be following a youtube playlist (for Othello as a web app) as a guidance tool for the project in terms of what we have to do. However, the game is extremely customizable (It had to be so to analyze it effectively) and we will also spend some time to ensure that happens. 
After the game is developed, we would like to build another program which will help us in conducting the analysis (I am not clear on how this looks like currently but am currently thinking by brute force)
The first 6 weeks will however be unrelated to this and mentee role in the second part is not going to be a requirement. If a mentee does not wish to do this they will be given some other tasks

Link to the playlist - https://www.youtube.com/playlist?list=PLix7MmR3doRoEJj8wIqXy_byOcGZ-ZoP7

DISCLAIMER: **We will NOT be using Unity for this project**
IT DOES NOT INVOLVE HIGH END GRAPHICS ",3 - 4,"N/A
Beginner friendly - Freshmen wanting to learn game development (more python and logic than game development) are recommended to enlist for this project",projects/default.png,https://drive.google.com/file/d/1m-M8_AvK4bTAr7KDVdOLGyC7c4s6y-8p/view?usp=drive_link,"Week 1: Python and it's basics, understanding combinatorial games and the ruleset of the game and setting up the environment
Week 2 - 5: Building the game, its board, its size and making it customizable, implementing the logic, enhancing user interface, providing single-player and multiplayer support, etc
Week 6: Making the game accessible to everyone, i.e. launching it online
Week 7 -8: Enhancing the design and other aspects of Ui/UX and integrating it with the game
OR working on the algorithm to help conduct the combinatorial analysis of the game","Checkpoint 1: Game environment (basic interface) development
Checkpoint 2: Game logic implemented and successful
Checkpoint 3: Multiplayer and single-player (with computer as opponent) are both successful and working
Checkpoint 4: Enhanced Ui/UX and appealing and interactive layout
Checkpoint 5: Satisfactory algorithm to analyze the game",Development
66,Harsh Shivhare 22b2433,Visual Style Transfer Engine,"Rishabh Tibrewal (22b2478) , Ayush Jha (22b0051)",Deep Learning,"Have you ever wondered what remarkable possibilities could unfold if we could harness and utilize the extraordinary abilities found in nature? Imagine if we could extract the power of flight from birds or the resilience of marine life to navigate the depths of the oceans. Similarly, it is possible to transfer features from one image to another to enrich their artistic design using a concept called Neural style transfer (NST).
Currently, Neural style transfer (NST) is used by technical team of film and animation production to create stylized visual effects, enhancing scenes with unique artistic interpretations. It is also used by Game developers to generate or enhance environment more relevant to their theme. Additionally, it allows game developers to experiment with different visual styles and themes.
In this project, we'll delve into the fundamentals of Machine Learning (ML) and Deep Learning (DL), guiding you through the implementation of Convolutional Neural Network (CNN) models for feature extraction and transfer learning. By the end of this project, you'll have gained a strong understanding of ML and DL principles, you will have trained and used neural networks for tasks such as image classification. Additionally, getting exposure to advanced techniques like transfer learning, enabling you to fine-tune pre-trained models to suit your specific dataset. And finally, we'll explore the realm of neural style transfer, where you'll learn to extract and integrate features from one image into another.

Some references ,

1 ) Applications of Neural Style transfer 
https://youtu.be/_v0ZNogoK6w?feature=shared ( for Game development)
https://youtu.be/vAelubuwquE?feature=shared   ( for Cinematic production)

2) Theory behind neural style transfer 
https://towardsdatascience.com/how-do-neural-style-transfers-work-b76de101eb3
https://youtu.be/R39tWYYKNcI?feature=shared ( By Andrew Ng)
 
3) Deep Learning by Ian Goodfellow, Yoshua Bengio and Aaron Courville (Reference Book)`",8-10,Basics of Python and CS101,projects/WhatsApp Image 2024-04-06 at 17.53.33.jpeg,https://drive.google.com/file/d/1t7FdgoqVYTT8RS-nMHeyU5BfdvibKL1g/view?usp=sharing,"Timeline
Week 1: Basics of Python and OOPs using Jupyter/Collab Notebook 
Week 2: Understanding basic Python libraries (Numpy, Matplotlib, Pandas) and basic theory of Machine Learning 
Week 3: Applying Machine Learning concepts through coding and introduction to Deep Learning 
Week 4: Exploring more Deep Learning concepts (Neural Networks) and understanding libraries such as Keras/PyTorch
Week 5: Further exploration of Keras/PyTorch and working on a project involving Neural Networks 
Week 6: Understanding Convolutional Neural Networks (CNN) and Intro to Transfer Learning 
Week 7: Understanding Neural Style Transfer and Beginning Final Project
Week 8: Final project development and documentation

","Checkpoint 1 : Proficiency in Python basics, familiarity with key libraries, understanding of ML fundamentals. 
Checkpoint 2 :  Basic theory of Deep Learning and Algorithm of Neural Network
Checkpoint 3 :  Familiarity with Keras/PyTorch 
Checkpoint 4 : Hands on Experience with the projects on NN and CNN
Checkpoint 5 : Theory of Neural Style Transfer
",ML
67,Harshit Maurya 22B1020,Language Translator,Aditya Bansal (22B2143),Deep Learning,"Traveling to a new place often brings the challenge of communicating in the local language. Many of us have turned to tools like Google Translator to bridge this gap, attempting to mimic accents and phrases. Machine Translation (MT) is a field of computer linguistics dedicated to translating text from one language to another. With the rise of deep learning, Neural Machine Translation (NMT) has emerged as the most effective method for this task. Google Translator stands as a prime example of this technology. NMT models, utilizing deep learning, aim to seamlessly translate text inputs from any language into another.

In this project, the developer leverages RNN sequence-to-sequence learning in Keras to translate English text into French.",6-8,"Good command on Python and some packages like NumPy, Pandas.",projects/Screenshot 2024-04-06 032829.png,https://drive.google.com/file/d/1YC8aZC5NyZQpyIv9Uh1QeCZ8FZdf5_6U/view?usp=sharing,"Week 1- Learn python libraries like NumPy, Pandas, Scikit-learn.
Week 2- Learn basics of TensorFlow and the mathematics behind Linear Regression.
Week 3- Learn gradient descent optimizer and the mathematics and implementation of Neural Networks.
Week 4- Learn Recurrent Neural Networks (RNN) and implementation of it.
Week 5- Understanding of Neural Machine Translation (NMT): A grasp of the principles behind Neural Machine Translation, including attention mechanisms and encoder-decoder architectures.
Week 6 and Week 7- Build and train the model using given dataset.
Week 8 - Fine-tuning, Evaluation, and Documentation.","Checkpoint 1- Gained knowledge of numpy, pandas, sklearn and tensorflow.
Checkpoint 2- Implementation of Neural Networks.
Checkpoint 3- Learn Recurrent Neural Networks (RNN) and implementation of it.
Checkpoint 4- Writing the main code of the model.
Checkpoint 5- Training, testing and evaluation of the model.",ML
68,Hemant Kabra 22b0399,Image Cartoonifier,Akshit singhal,Image Processing,"The Image Cartoonifier project aims to transform regular images into cartoon-like versions through computer vision techniques and image processing algorithms. The process involves preprocessing the image to enhance edges and reduce noise, detecting prominent edges, simplifying the color palette, and applying cartoon effects by overlaying simplified colors onto detected edges. Optional enhancements such as texture addition or artistic filters can further stylize the image. Implemented using Python with libraries like OpenCV and scikit-learn, the project offers customization options for experimenting with various techniques and parameters to achieve different cartoon effects, making it an engaging exploration in image manipulation and artistic rendering.",10-15,Basic knowledge from CS101 course,projects/default.png,https://drive.google.com/drive/folders/1qd-4qhBjtb5TYLgY1zuXdIgw8UwJ8Adk?usp=sharing,1 topic per week,"Image Preprocessing: The input image is preprocessed to enhance edges and remove noise, which is crucial for achieving a cartoon-like effect. Techniques such as Gaussian blurring and edge detection (e.g., using Canny edge detector) may be employed.

Edge Detection: Once the preprocessing is complete, the next step involves detecting prominent edges in the image. Edges are important for defining the outlines and features of objects in the cartoonized image. Techniques like Sobel or Prewitt operators may be used for edge detection.

Color Reduction: To achieve the characteristic flat and vibrant colors seen in cartoons, the color palette of the image is simplified. This can be done using techniques like color quantization or clustering algorithms such as k-means clustering, where similar colors are grouped together.

Applying Cartoon Effects: After simplifying the color palette, the cartoon effect is applied to the image. This typically involves combining the simplified colors with the detected edges. One common approach is to overlay the simplified colors onto the edges, giving the appearance of hand-drawn strokes.

Optional Enhancements: Depending on the desired output, additional enhancements may be applied. These could include adding texture to the colors, adjusting brightness and contrast, or applying artistic filters to further stylize the image.

Output Generation: Finally, the processed image is generated and saved or displayed to the user.

The project can be implemented using programming languages like Python, leveraging libraries such as OpenCV for image processing and scikit-learn for clustering algorithms. Additionally, it offers opportunities for experimentation and customization, allowing developers to explore various techniques and parameters to achieve different cartoon effects",ML
69,Himanshu Kumar 19D110007,Deep Reinforcement Learning for stock trading,None,Deep Learning,"Ever wondered what it's like to teach a computer to trade stocks for you? That's what we're doing here! We're using reinforcement learning (RL) to make a computer program that can make smart trading decisions.

You'll get to play with coding, teach the computer how to make money in the stock market, and see your ideas come to life. It's not just about making profit; it's about making a smart trading buddy using deep learning. In this project you'll get your hands dirty with some actual coding, using Python and maybe a bit of TensorFlow or PyTorch.

To Get Started:
Read up on the basics of reinforcement learning and how it's used in trading.
Check out some Python tutorials. Python is what we'll use to talk to our computer and tell it what to do.

And hey, take a look at this article to get an idea of what we're diving into: https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02 

Ready to make the stock market your playground? Let's get started!",6-7,"Must have - 
1. Hands on coding skills
2. Curiosity About the Stock Market

Good to have-
1. Knowledge about reinforcement learning
2. Experience with ML/Deep Learning
3. Math Skills - Good to have, especially if you're comfortable with probability and statistics. These will help you understand how algorithms make predictions.

What We Expect in Your Proposal -
1. Tell Us About Yourself
2. How can you contribute to this project

Remember, this project is about learning and growing. Don't stress if you're not an expert in everything listed. If you're eager to learn and ready to dive in, we want to hear from you!",projects/default.png,https://drive.google.com/drive/folders/1KTidFX3ARMUzWNRzGReGlhd1W7cupbvD?usp=drive_link,"Week 1 - Getting familiar with RL/Stock markets
Week 2 - Literature and reading upon how RL algorithms
Week 3 - Coding Out few basic RL based agent for atari games
Week 4 - Coding Environment for our trading agent
Week 5 - Coding our Agent 
Week 6 - Integrate and lets see it working
Week 7 - Improve the architecture for env/agent","Week 1 - Getting familiar with RL/Stock markets
Week 2 - Literature and reading upon how RL algorithms

Checkpoint-1

Week 3 - Coding Out few basic RL based agent for atari games

Checkpoint-2

Week 4 - Coding Environment for our trading agent

Checkpoint-3

Week 5 - Coding our Agent 

Checkpoint 4

Week 6 - Integrate and lets see it working

Checkpoint 5

Week 7 - Improve the architecture for env/agent",ML
70,Ishan Grover 22B1528,Mind-Moves: Reinventing Checkers,Abhishek Hazra (22B2424) / Anuj Waje,Deep Learning,"Mentees will get a chance to build a checkers engine (similar to a chess engine), using the principles of Machine Learning & Neural Networks",6-8,Lots of Enthusiasm for learning and exploring Python and Machine Learning,projects/default.png,https://drive.google.com/file/d/1CUl2VgQiHtmBuYLVuJ8JCyWv2WCFSkYI/view?usp=drivesdk, Webmail - 22b1528@iitb.ac.in / 22b2424@iitb.ac.in,"Week 1 & 2: Learn Checkers & Basic ML Concepts
Week 3 & 4: Curate Training & Testing Dataset, initial model training, implementing evaluation function 
Week 5 & 6: Improving Model, Implementing best move prediction 
Week 7 & 8: Making an interactive GUI and integrating the model in it",ML
71,Ishan Pandit 22b2141,Deep Dive: Computer Vision,Ashok Nayak (22b0455),Machine Learning,"Throughout the project, participants will engage in a comprehensive journey through the realms of computer vision and deep learning. They will start by gaining a solid foundation in Python programming and PyTorch. As they progress, they'll delve into the theoretical aspects of computer vision, understanding the principles behind image processing and analysis. Through hands-on assignments and projects, they'll learn to implement various image processing functions and techniques, culminating in the application of these skills in real-world tasks such as face detection and recognition. They'll explore advanced topics like Convolutional Neural Networks (CNNs), a powerful tool for image recognition tasks. Throughout the project, there will be checkpoints to assess their understanding and progress, ensuring they grasp the concepts effectively. Optional modules on reinforcement learning offer additional depth to their learning journey. The final project, an open-ended face recognition problem, encourages creative thinking and application of learned techniques, potentially incorporating reinforcement learning for enhanced performance and adaptability.

RESOURCES: YouTube videos which we have found, optional research papers if students are interested, GitHub repositories (example linked below)
https://github.com/omonimus1/super-computer-vision",5-6,Basic python skills and lots of enthusiasm!,projects/WhatsApp Image 2024-04-08 at 23.34.08_219035a2.jpg,https://drive.google.com/file/d/1OqFps0QCdZXeBkC9R_KTXaJuRdABzYYs/view?usp=sharing,"Week1: Introduction to Python (if required), PyTorch and Basic PyTorch Assignment
Week2: Basics of Computer Vision (theory-oriented) along with submission of report
Week3: Learning and implementing image processing functions
Week4: Checkpoint1 - Image Processing Task
Week5: Advanced image processing and face detection
Week6: Basics of Neural Networks (more specifically CNNs)
Week7: Face Recognition and Applications
Week8: Checkpoint2 - Face Recognition Task
Week9: Reinforcement Learning and its application in CV (optional)
Week10: Final Project - Open ended problem on face recognition (optional use of RL) (we will provide a potential list of problems but students have freedom to consult us and choose their own problem)","Checkpoint 1 - Understanding PyTorch and Theoretical CV
Checkpoint 2 - Image Processing Task
Checkpoint 3 - Assignment on Advanced Image Processing
Checkpoint 4 - Face Recognition Task
Checkpoint 5 - Final Project i.e. implementation of advanced CV ",ML
72,Jagmeet Singh 210040071,Intro to Full Stack Web Development (with project),Aditya Jangid,Web Development,"The objective is to introduce you to Full Stack Web Development and build a project to utilise the skills learned. We'll cover the essentials from scratch using the MERN stack - MongoDB, Express, React, and Node.js.
Starting with HTML and CSS, you will gain a solid understanding of web design before delving into JavaScript fundamentals. Moving on, we'll tackle server-side programming with Node.js and Express, along with Git for code management.
Hands-on experience with MongoDB for database management and user authentication will follow. Then, we'll dive into React for dynamic user interfaces and Redux for state management.

Finally, you will build a website from scratch, covering everything from planning to deployment.",10-12,CS101 is a plus and most importantly the enthusiasm in development,projects/SoC-Web-Development.jpeg,https://drive.google.com/file/d/1aVofpFjsdIBjWjWYlnBVvEZDgZ10z-pP/view?usp=sharing,"Week 1: Getting familiarised with HTML, CSS, tailwind
Week 2: JavaScript Fundamentals
Week 3: Node.js, Express, and Git
Week 4: Databases(MongoDB) and Authentication
Week 5-6: Foundation for React, Redux State Management
Week 7-8: Website Development and Deployment","Checkpoint-1: Complete HTML, CSS and Tailwind
Checkpoint-2: Complete JavaScript, Node.js, Express, and Git
Checkpoint-3: Complete Databases(MongoDB) and Authentication concepts
Checkpoint-4: Complete React, Redux concepts
Checkpoint-5: Complete the Website Development",Development
73,Jatin Gupta 22B3967,Sentiment Insight Engine: Advanced Opinion Mining and Analysis,"Krishna Kumar Singh(22B3968), Madhur Kholia(22B3944)",Natural Language Processing,"The project aims to develop an advanced sentiment analysis and opinion mining system using deep learning techniques for processing textual data. Sentiment analysis involves classifying text into positive, negative, or neutral sentiments, while opinion mining delves deeper into identifying nuanced opinions, emotions, and aspects within the text.",6,"    Python Programming
    Basics of Natural Language Processing (NLP)
    Understanding of Data Handling and Preprocessing
    Familiarity with Machine Learning Concepts",projects/1.jpg,https://drive.google.com/file/d/1BprfcY4XURA_CpKJTvwewr19o9AzUBq_/view?usp=sharing,"Week 1-2: Project Setup and Data Collection

    Week 1: Introduction to sentiment analysis, project overview, setting up Python environment.
    Week 2: Identify data sources (e.g., online reviews, social media data), collect and preprocess data.

Week 3-4: Data Preprocessing and Text Representation
 Week 3: Data cleaning (remove duplicates, handle missing values), tokenization, and normalization.

    Week 4: Convert text data into numerical vectors using techniques like Bag-of-Words (BoW) or TF-IDF.

Week 5-6: Model Building and Training
 Week 5: Select machine learning models (e.g., Naive Bayes, Support Vector Machines, LSTM for deep learning).

    Week 6: Split data into training and testing sets, train the selected models using the training data.

Week 7: Model Evaluation and Optimization
Week 7: Evaluate model performance using metrics like accuracy, precision, recall, and F1-score. Optimize hyperparameters to improve model performance.

Week 8: Finalize Project and Presentation
Week 8: Finalize the sentiment analysis model, create a report documenting the project steps, results, and findings. Prepare a presentation for showcasing the project.","Checkpoint-1: Data Collection and Preprocessing
Checkpoint-2: Text Representation and Feature Engineering
Checkpoint-3: Model Selection and Training
Checkpoint-4: Model Evaluation and Optimization
Checkpoint-5: Finalize Project and Documentation",ML
74,Kalpesh Khare 22b0069,Amazon Clone,no,App Development,"Make an Amazon clone using Fluter and NodeJS. You will learn to build the UI of Amazon from scratch, create REST APIs, store data in MongoDB using Mongoose, use REST APIs with Flutter & Dart using Models, use the Flutter State Management tool as a provider, and create a cross-platform app that works on Android and iOS.",6,,projects/amazonflutter.png,https://drive.google.com/file/d/1XP27psCnlqJEyR-QvwDtc3FsyWLgwDpQ/view?usp=sharing,"To divide the given topics into an 8-week plan, we need to allocate the topics appropriately while ensuring a balanced distribution of workload and complexity. Here's a proposed breakdown:

Week 1: Flutter Basics & Project Setup
Introduction & Demo
Setting Up The Flutter Project
Setting Up Themes
Folder Structure
Setting Up Routes
Auth Screen UI

Week 2: Introduction to Node.js & Server Setup
What is Node.js
Node.js Installation
Initializing Node
First Node.js Script
NPM & Dependencies
Creating Server

Week 3: Building APIs with Node.js
Nodemon
Create your First API
Exercise 1: Create GET API
Solution 1
Routers
Middleware

Week 4: User Authentication with Node.js & MongoDB
Sign up Route
Connecting to MongoDB
Creating User Model
Sign up Route continued
Connecting Sign Up Route With Client Side

Week 5: Implementing Sign In Functionality
Adding TextField & Form Validator
Sign In Route / Exercise 2
Creating Sign In Route (Solution 2)
Connecting Sign In Route with Client Side
Persisting State

Week 6: Building User Interfaces in Flutter
Creating BottomNavBar
Account Screen UI
Home Screen UI
Admin Screen BottomNavBar

Week 7: Admin Panel Development
Add Product Screen UI
Picking Images
Admin - Selling Product
Create Admin Middleware / Exercise
Solution
Sell Product Continued

Week 8: Finalizing Features & Deployment
Admin - Fetching & Displaying All Products
Admin - Deleting Product
Self Exercise (Add Product Realtime)
Deployment to Heroku
Testing on Android Device
(Bonus) Flutter 3 (Everything Works!)
Material 3
","Checkpoint-1: Setup Project
Checkpoint-2: User Authentication and Sign-In
Checkpoint-3: Ui/Ux
Checkpoint-4: Admin panel
Checkpoint-5: Final Deployment",Development
75,Kanika Gupta 210010032, MERN Stack project : JobHive (job seeking platform),"Mayur Ahire,(210020010),  Prashasti Pravin(210010004)",Web Development,"I'll guide you through the creation of a dynamic MERN Stack job-seeking web application from scratch. Learn how to leverage MongoDB, Express.js, React, and Node.js to build a powerful platform for job seekers and employers alike. Follow along step-by-step as we cover everything from setting up the backend server to designing a user-friendly frontend interface. Whether you're a beginner or an experienced developer, this project will equip you with the skills to create your professional-grade job portal.",12,"enthusiasm for coding, basic web development skills (not compulsory) (HTML , CSS , JAVASCRIPT).",projects/SOCimage.png,https://drive.google.com/file/d/1WMUY4F3qh0i5SilOZ366_UzKA_mRd3pq/view?usp=sharing,"Week 1: Learning Full Stack Fundamentals
Week 2: Setting Up the Development Environment
Week 3-4: Building the Backend with Node.js and Express.js
Week 5-6: Developing the Frontend with React
Week 7: Testing, Debugging, and Optimization
Week 8: Deployment and Finalization","1.Learning Full Stack Development Fundamentals:
2. Setting Up the Development Environment
3. Building the Backend with Node.js and Express.js
4. Developing the Frontend with React.js:
5.Testing, Debugging, and Deployment
",Development
76,Kartik Gokhale 200100083,Would you bet your life on it?,Hastyn Doshi (200070025),Deep Learning,"We trust ChatGPT to help us in our assignments. Don't we rely on Google maps to optimise our travel? Needless to say, we have seamlessly incorporated AI/ML into our lives. But where do we draw the line? Would you trust an AI algorithm to make financial decisions for us (some of us do already)? In the age of self-driving cars, would you trust an ML model with your life? A popular, albeit dramatic, question is if you believe that no robot uprising is possible in the days to come? :)

The pervasive question still stands; where do you draw the line? How confident are you that nothing ""wrong"" will happen? Would you bet your life on it?

This brings us to today; we stand in a day and age where the power of AIML seems endless. But with endless power, comes endless responsibility. In this project, we will explore the recent advances in providing guarantees relating to neural networks. We will build a framework to identify potential failures of some simple neural networks. Finally, we will work on making these simple neural networks more robust to various kinds of failure.

In terms of outcome, you will receive exposure to basic machine learning and artificial intelligence. Additionally, you will experience working with formal methods. More importantly, you will be exposed to some of the latest ideas in a very unique and relevant frontier of computer science. And if you get there, you may answer the haunting question; would you bet your life on it?

P.S. : This will NOT be a very heavy project, in case you're concerned about that. ",2-3,"Prereq: Enthusiasm (obviously). Exposure to Machine Learning and/or Formal Reasoning would be good but not mandatory. Familiarity with python (or any programming language), however, is a must. Please apply only if you are definitely enthusiastic and have time to spare.

Proposal: Elaborate on why you want to work on this project. Be sure to mention what experience you have in computer science (both related to machine learning as well as otherwise)",projects/Banner.jpeg,https://drive.google.com/file/d/1RDFaD_9hxyp9jWb0aq7eNRXPKU3rtrQa/view?usp=sharing,"Week 1-3 : Revise some fundamentals related to python, machine learning as well as formal reasoning
Week 4-5 : Utilise formal methods to identify weaknesses in an MNIST model
Week 6-8 : Devise techniques to make the model more robust ","Checkpoint 1: Use existing tools to verify pretrained neural networks
Checkpoint 2: Identify points of failure of an MNIST model
Checkpoint 3: Make the MNIST model more robust",ML
77,Kaushal Malpure 22B1276,Data Structures & Algorithms(C++),Chiransh Somani (22B1202),Competitive Programming,"Our project aims to simplify learning data structures and algorithms by focusing on practical implementation. Participants will explore concepts like arrays, OOPs, linked lists, trees, heaps, graphs and dynamic programming, understanding their effective application. Using platforms like LeetCode, CodeStudio, and GeeksforGeeks, they'll solve problems of different difficulties. Weekly assignments are supposed to be submitted via a shared GitHub repo. We will also conduct weekly meetings to track the progress of each mentee, address any doubts, and provide additional support as needed.",8-10,"Basic knowledge of C++, including basic STL functions as well as good grasp on CS101.",projects/default.png,https://drive.google.com/file/d/1TRUUTSL65mmJtvT8x2HoOc_sBRSjErpT/view?usp=sharing,"Week 1 - Arrays, binary search, different sorting methods like bubble sort, selection sort, and insertion sort
Week 2 - Strings, pointers, recursion, understanding and calculating the time complexity of different algorithms
Week 3 - Understand object-oriented programming structures and linked lists
Week 4 - Stacks, queues, deques, binary trees, and different methods of their traversal
Week 5 - Heaps, hashmaps, and graph algorithms such as Dijkstra's, Kruskal's, and Kosaraju's algorithms
Week 6 - Dynamic programming (1-D)
Week 7 - Dynamic programming (2-D)","Checkpoint-1 : Complete 10 questions, including easy/medium/hard, based on arrays, searching and sorting
Checkpoint-2 : Complete 10 questions, including easy/medium/hard, based on strings, pointers and recursion
Checkpoint-3 : Complete 15 questions, including easy/medium/hard, based on linked lists, stacks, queues, deques and binary trees
Checkpoint-4 : Complete 10 questions, including easy/medium/hard, based on heaps, hashmaps and graph algorithms
Checkpoint-5 : Complete 10 questions, including easy/medium/hard, based on dynamic programming",CP
78,Kirthan Kamble 22b1229,Neural Net from scratch in code.,Jatin Singhal(22B1277),Machine Learning,"Neural Nets today are so abstracted thanks to various libraries like PyTorch, Tensorflow etc that beginners often learn these libraries and often only have a superficial understanding of the mathematics behind these structures. In this project we aim to spell out in code as to how one may go about to implement Nets and understand the details the mathematics behind them primarily the backpropagation algorithm and SGD optmizer.",6-7,Knowledge of Linear algebra and Calc-2,projects/soc project banner.png,https://drive.google.com/file/d/1NCxP-_KhcZP5GukyRhJV6F__3tm_wWz8/view?usp=sharing,"Week0:
Basics of python(OOPS), numpy 
Week1:
Basics of NN, feedforward in NN
Week2:
Loss, accuracy, SGD
Week3:
Backpropagation, Testing with MNIST dataset
Week4(if permits):
Convolutional layers and autograd","Checkpoint 1 : Feedforward working correctly
Checkpoint 2: Loss and Accuracy working correctly
Checkpoint 3: Backpropagation working correctly
Checkpoint 4: Accurately trains over MNIST csv dataset",ML
79,Komal Sai  22b0440,Alum Link,Vikash Kumar(22b0359),App Development,"Alum Link: Bridging Past and Present

Alum Link is a platform which aims to connect the vibrant community of alumni with the ambitious students of our college. We believe that our alumni are the best to guide us and provide valuable insights and opportunities available.

Work: You will learn developing app in Flutter. Firstly learn flutter and design a basic app for your practice. Then you can search for UI or can design by yourself if interested using Figma. We will provide and guide you with all the resources. Complete designing the UI of the app. After the frontend is done, you need to learn firebase and integrate into the app. Don't get overwhelmed by all these! We will provide all resources and take regular meets. Just have a lot of enthusiasm!!",8-10,"N/A
Need a lots of enthusiasm 🔥",projects/default.png,https://drive.google.com/file/d/1n6fB0wmGP87j4BmpL4i8o1m9mpfdwjvy/view?usp=drivesdk,"Week 1-2: Learn Flutter and make a basic app like to-do list of interested
Week 3-4: Design the UI of our app and  work on the frontend part of app
Week 5: Learn Firebase
Week 6: Integrate and work on backend part of our app
Week 7-8: Work on Additional features.  Learn deployment of the app if mentees are interested.","Checkpoint 1: Developing a basic app in Flutter (like to-do app)
Checkpoint 2: Develop UI of our application 
Checkpoint 3: Complete frontend part of app
Checkpoint 4: Integrate backend
Checkpoint 5: Create some additional features",Development
80,Krishna kumar singh 22b3968,CyberGuard: Building an Intrusion Detection System (IDS),"Jatin Gupta(22B3967), Madhur Kholia(22B3944)",Network and Cyber Security,"The Intrusion Detection System (IDS) project involves creating a system using Python or another programming language to monitor network traffic for suspicious activities. It includes features such as anomaly detection and real-time alerts for potential intrusions, helping learners explore network security and cybersecurity concepts in practice.",6,"Basic networking knowledge (TCP/IP, protocols, IP addressing).
    Familiarity with Python or another programming language.
    Understanding of Linux command line basics.
    Interest in cybersecurity concepts and willingness to learn.",projects/Bluebackground with picture placed on it showing c.jpeg,https://drive.google.com/file/d/1gu3BzIhzGoeJ_6KBN80EdBYQfM_08uYY/view?usp=sharing,"Project Implementation:

    Week 1-2: Research and Understanding
        Mentees research networking protocols (e.g., TCP/IP, UDP), security concepts (firewalls, encryption), and common network attacks (DDoS, SQL injection).

    Week 3-4: Packet Capture and Analysis
        Implement packet capturing tools using libraries like Scapy in Python.
        Analyze captured packets for basic anomalies like unusual traffic patterns or suspicious payloads.

    Week 5-6: Machine Learning Techniques
        Learn about machine learning algorithms for anomaly detection (e.g., supervised learning, clustering, deep learning).
        Implement simple ML models (e.g., decision trees, k-means clustering) on sample network data to detect anomalies.

    Week 7-8: Integration and Optimization
        Integrate machine learning algorithms into the NIDS framework.
        Evaluate the NIDS performance using real-world datasets or simulated attacks.
        Optimize the system for better accuracy and efficiency based on evaluation results.","Checkpoint 1: Research and Understanding
Checkpoint 2: Packet Capture and Analysis
Checkpoint 3: Anomaly Detection Techniques
Checkpoint 4: System Implementation
Checkpoint 5: Integration and Testing",Others
81,Kunal Chaudhari 22B1060,Automated Trading System,Shresth Verma (22B2211),Machine Learning,"This project seeks to synergize two fascinating domains: finance and machine learning. Our goal is to foster an understanding of the financial world uninfluenced by preconceived notions. We plan to enrich learning by addressing queries through data and analysis with Python. The project will introduce and implement concepts such as regression and neural networks, allowing participants to directly observe the benefits derived from their application. Emphasis will be on encouraging out-of-the-box thinking, especially for feature extraction, a crucial step towards effective model building. Upon successful mastery of these elements, we will progress to designing trading systems",6-8,Basic knowledge of python,projects/soc_banner_trading.jpg,https://drive.google.com/file/d/1kh3BgFb7exB3P7D1fNh_aMI2pKfk2CLq/view?usp=sharing,"Week 1: Introduction to Financial Markets and Trading Principles. Get familiar with the working and tools of the market. Brainstorm on all the strategies and try it out in a paper trading environment. Start with the basics of python.
Week 2: Fundamentals of Trading. Review on the raw ideas and conversion into structured ideas. Significance of risk management, analysis etc. using template codes and result data.
Week 3: Python for Finance. Introduction with Jupyter notebooks and matplotlib for financial charting. Familiarity with github to maintain the codebase.
Week 4: Data Analysis and Introduction to Algorithmic Trading. Data sourcing (APIs for financial data), data cleaning, and preparation. Basic statistical analysis and introduction to machine learning with scikit-learn. Introduction to algorithmic trading concepts, backtesting frameworks.
Week 5: Machine Learning in Trading .Building predictive models (regression, classification).
Feature engineering, overfitting prevention strategies. Integrating ML models with trading strategies.
Week 6: Developing and Testing Trading Strategies. Strategy development (identifying signals, entry/exit rules). Backtesting strategies with historical data. Strategy optimization and risk evaluation.
Week 7: Advanced Algorithmic Trading Concepts and Tools. Towards a robust software system along with more advanced AI concepts.
Week 8:  Project Development and Presentation. Final presentations and review - sharing projects with the group, receiving feedback, and discussing future steps. Perhaps yolo our life-saving away ;)","Checkpoint-1 : Completing a specific target of trading reward on a paper trading platform
Checkpoint-2 : Completing the assignment on data analysis and charting using python
Checkpoint-3 : Training and testing of various ML models for prediction.
Checkpoint-4 : Implementation of APIs for real-time data extraction and placing orders
Checkpoint-5 : Yolo away life savings",ML
82,Lakshya Gadhwal 22b0995,Quantumania,Yug Agarwal,Quantum Computing ,https://github.com/A9B8C7D6/To-The-Quantum-Future-SoC2023,8,,projects/default.png,https://drive.google.com/drive/folders/1AaykPkAmkIAmK1R5gFZwHMuNwx2XNHNB?usp=share_link,"Week1: basics of quantum mechanics and linear algebra
Week2: Operators and POVMs
Week3: Quantum teleportation and Superdense Coding
Week4: Basics of Quantum circuits
Week5: Shor’s Algorithm and Grover’s search
Week6: Quantum cryptography ","Checkpoint 1: Learn the basics
Checkpoint 2: Understand basic protocols
Checkpoint 3: Learn Circuits
Checkpoint 4: Learn advanced algorithms 
Checkpoint 5: Learn quantum Cryptography ",Others
83,Lakshya Gadhwal 22b0995,Quantumania,Yug Agarwal,Quantum Computing ,This project will introduce students to the exciting world of Quantum Computing by the means of theory and implementation both. By the end of the project the students will have learned some of the important quantum algorithms and designed their respective circuits. Here is the github repo based on which this project will run: https://github.com/A9B8C7D6/To-The-Quantum-Future-SoC2023,8,"Basic Linear Algebra, MA110 should be fine",projects/IMG_0228.jpeg,https://drive.google.com/file/d/1VCv-hrjr0_nF17V17i7Tbg8l_RbsJ1Ex/view?usp=sharing,"Week 0: Learn basic Linear Algebra and Quantum mechanics 
Week 1: Learn basic quantum protocols like quantum teleportation and superdense coding along with POVMs, operators and measurements 
Week 2: Learn basics of Quantum circuits and design simple adders
Week 3: Study and implement Shor’s algorithm and Grover’s search
Week 4: Study and implement Quantum Cryptography algorithms","Checkpoint 1: Learn the basics of Quantum Mechanics and Linear Algebra 
Checkpoint 2: Learn some basic Quantum protocols
Checkpoint 3: Learn basics of Quantum Circuits
Checkpoint 4: Study and implement quantum algorithms in circuits
Checkpoint 5: Study and Implement a Quantum Cryptographic Algorithm",Others
84,Likhitha Manduri  20D110009,Image Caption Generator ,,Deep Learning,"Image caption generation utilizes both computer vision and NLP to automatically generate textual captions of an image for a wide spectrum of visual scenarios and linguistic expressions, making it useful for tasks such as image organization, search, and aiding visually impaired individuals. This task requires understanding the visual content of the image and learning the text used to describe it. Hence, we will be using CNNs for image feature extraction and RNN/LSTMs for text generation. The goal of this project is to familiarize mentees with the intricacies of deep learning and gradually equip them with the skills to develop their own caption generator, starting from a foundation of basic Python proficiency and a fundamental understanding of machine learning principles. 
This project aims to introduce the mentees with deep learning and subsequently build upon the knowledge to build the caption generator.",4-5,"Basic Python, Basics of ML",projects/default.png,https://drive.google.com/file/d/1E6fJ_cXKXvUL_HR7fsDuc53WENTR-6Vv/view?usp=drivesdk,"Week 1: Study about Deep Neural Networks and learn about PyTorch/TensorFlow 
Week 2: Study and implement CNNs on a simple classification task to get to know it's potential
Week 3: Learn about NLP fundamentals and Word Embeddings
Week 4:	Study sequence models like RNNs and LSTMs
Week 5: Revision of topics or covering any missed topics
Week 6-9: Explore various image Captioning architectures through research papers and other sources and finally the build your own Image Captioning Model!","1. Understanding of deep learning models 
2. Understanding and implementing CNNs for image feature extraction
3. Learning about NLP fundamentals and sequence models like RNNs and LSTMs
4. Exploring different image captioning architectures through research papers
5. Building and fine-tuning the Image Captioning Model",ML
85,Madan Y N 200070040,Automated Inference Latency Estimation of LLMs on FPGA,,DevOps,"The project aims to develop a software package that automates the process of estimating the latency of machine learning models when deployed on FPGA (Field-Programmable Gate Array) devices. Don't worry if you don't know what FPGA is. Watch this short video - https://www.youtube.com/watch?v=ePwo3P1iZO4. 
Refer to this short paper to learn about the task we are trying to automate - https://tinyurl.com/bdz34ntx

The project will involve parsing the given PyTorch source code, determining resource requirements, and optimizing the architecture for minimal latency using a genetic optimization algorithm. The major goals of the project can be summarized as follows,

1. Parse the given source code of the given LLM and generate a compute flowgraph.
2. Develop a library (in JSON) containing details like latency and resource requirement of each mathematical operation in a given FPGA board (eg. floating-point multiplier)
3. Derive an expression for the end-to-end latency of the model.
4. Efficiently partition the resources to minimize latency using a genetic optimizer.
5. Streamline the whole process into a software package.

Refer to the paper cited above to know about each of the steps in detail","4 (two mentees will work on goals 1, 2 & 5 and the other two on goals 3, 4)","1. Python Programming (having a project is good)
2. Basic knowledge of graph data structure and graph traversal algorithms (for goals 1 & 2)",projects/image (1).png,https://drive.google.com/file/d/1dVMG5RMLDmb51yx-_7OaMipz5rk0vM_M/view?usp=sharing,"week1 - Revise Python & graph data structure, genetic optimizer
week2 - Study AST(abstract syntax tree), latency of digital circuits
week3&4 - Generate compute flowgraph, pipelining & total latency concepts
week5 - Learn JSON, generate latency expressions from flowgraph
week6 - Finish component library, finalize latency expressions
week7 - Streamline all components, design space exploration using genetic algorithm
week8 - Testing & Documentation

note: In any week if the tasks to be done are a, b then mentees working on goals 1, 2 & 5 will do the task 'a', and those working on goals  3 & 4 will do the task 'b'.","Checkpoint-1: Implement parser script to generate compute flowgraph from PyTorch source code
Checkpoint-2: Design a library of mathematical operations in JSON and integrate it with the flowgraph
Checkoin-3: Drive mathematical expressions of end-to-end latency form the flow graph
Checkpoint-4: Efficient resource partitioning using genetic algorithm to minimize latency
Checkpoint-5: Streamline all the steps and create a single software package",Others
86,Madhur kholia 22b3944,Advanced Sentiment Analysis and Opinion Mining System,"Jatin Gupta(22b3967) , Krishna kumar singh(22b3968)",Machine Learning,"The Intrusion Detection System (IDS) project involves creating a system using Python or another programming language to monitor network traffic for suspicious activities. It includes features such as anomaly detection and real-time alerts for potential intrusions, helping learners explore network security and cybersecurity concepts in practice.",6,"Basic networking knowledge (TCP/IP, protocols, IP addressing).
    Familiarity with Python or another programming language.
    Understanding of Linux command line basics.
    Interest in cybersecurity concepts and willingness to learn.",projects/default.png,https://drive.google.com/file/d/1BprfcY4XURA_CpKJTvwewr19o9AzUBq_/view?usp=sharing,"   Week 1-2: Research and Understanding
        Mentees research networking protocols (e.g., TCP/IP, UDP), security concepts (firewalls, encryption), and common network attacks (DDoS, SQL injection).

    Week 3-4: Packet Capture and Analysis
        Implement packet capturing tools using libraries like Scapy in Python.
        Analyze captured packets for basic anomalies like unusual traffic patterns or suspicious payloads.

    Week 5-6: Machine Learning Techniques
        Learn about machine learning algorithms for anomaly detection (e.g., supervised learning, clustering, deep learning).
        Implement simple ML models (e.g., decision trees, k-means clustering) on sample network data to detect anomalies.

    Week 7-8: Integration and Optimization
        Integrate machine learning algorithms into the NIDS framework.
        Evaluate the NIDS performance using real-world datasets or simulated attacks.
        Optimize the system for better accuracy and efficiency based on evaluation results.","Checkpoint 1: Research and Understanding
Checkpoint 2: Packet Capture and Analysis
Checkpoint 3: Anomaly Detection Techniques
Checkpoint 4: System Implementation
Checkpoint 5: Integration and Testing",ML
87,Madhur kholia 22b3944,"Unveiling Faces: Harnessing Python for Age and Gender Detection,",na,Image Processing,"
https://drive.google.com/drive/folders/1E1xqBQPuurFZe2QZoJIk-UmqcuVL8Gvi?usp=drive_link
",6,,projects/default.png,https://drive.google.com/file/d/1_14qVdW6XePE6GSuygoDcGoTV4cIfAbR/view?usp=drive_link,"Week 1-2: Project Planning and Research
Research existing age and gender detection algorithms and libraries.
Set up development environment and necessary tools.
Create a detailed project plan including milestones and deliverables.

Week 3: Data Collection and Preprocessing
Gather datasets containing images with annotated age and gender labels.
Clean and preprocess the data to ensure consistency and quality.
Split the dataset into training, validation, and testing sets.

Week 4-5: Model Development
Choose a suitable deep learning architecture for age and gender detection.
Implement the selected model using Python and appropriate libraries (e.g., TensorFlow, PyTorch).
Train the model using the prepared dataset, fine-tuning parameters as needed.
Validate the model's performance using the validation dataset, iteratively improving as necessary.
Week 6: Model Evaluation and Optimization

Evaluate the trained model's performance using the testing dataset.
Identify areas for optimization and fine-tuning based on evaluation results.
Implement optimizations to improve accuracy, speed, or resource efficiency.
Week 7: Integration and Testing

Integrate the trained model into a Python application for age and gender detection.
Develop a user-friendly interface for interacting with the model.
Perform comprehensive testing to ensure the application functions correctly under various conditions.
Week 8: Documentation and Deployment

Document the project including code, usage instructions, and technical details.
Prepare for deployment, ensuring compatibility and packaging dependencies.
Deploy the age and gender detection application, making it available for use.
Conduct a final review and reflection on the project, noting lessons learned and areas for future improvement.","checkpoint1- download all required libraries
checkpoint2-Data Collection and Preprocessing
checkpoint3-model development
checkpoint4-evaluate the trained model's performance using the testing dataset.
checkpoint5-Integration and Testing",ML
88,Mahek Hinhoriya 22b3031,Fashion Recommendation System,"Rishi Daga 22b3003, Aditya Sancheti 22b3004",Deep Learning,"Have you ever wondered how Google Lens magically identifies objects in your photos or how Myntra suggests similar fashion items based on your uploaded images? 
Dive into the world of image processing and learn to make useful project that has wide scaled implementation

The Fashion Recommender System aims to provide product recommendations to users based on their uploaded images of garments or shoes. Leveraging deep learning  techniques, the system learns to associate visual features from the user’s input with relevant items in its dataset. 

Certainly! In addition to coding and model implementation, we’ll also focus on deploying the system. Our goal is to make it accessible and usable for real-world scenarios.",11,"Python Libraries  - Numpy, Pandas. 
Basic Understanding of Machine Learning and Deep Learning is a plus point.
and LOTS OF Enthusiasm !!!",projects/default.png,https://drive.google.com/file/d/1JnD3NanplEWNm-YWWU2RD5Dza4AQ7UT_/view?usp=sharing,"Week 1: Introduction to pandas, numpy, matplotlib, and classification algorithms.
Week 2: Exploring Image Processing.
Week 3-4: Delving into Deep Learning.
Week 5: Developing a Mini Project.
Week 6-7: Understanding Transfer Learning and deployment techniques.
Week 8-9: Creating a Final Project.","Checkpoint 1: Mastery of pandas, numpy, matplotlib, and basic classification algorithms.
Checkpoint 2: Proficiency in fundamental image processing techniques using OpenCV or PIL.
Checkpoint 3 Successful implementation and evaluation of deep learning models for image-related tasks.
Checkpoint 4: Completion of a mini project demonstrating integration of learned concepts.
Checkpoint 5: Understanding and application of transfer learning techniques and deployment strategies for deep learning models.",ML
89,Maithri Suresh  210020072,Attacking LLMs with Projected Gradient Descent,Shravya Suresh (210260046),Machine Learning,"How far can you push a Large Language Model before it breaks? 🎃
This project entails attacking a language model using Projected Gradient Descent and fine-tuning the language model on adversarial prompts to enhance its robustness against jailbreak attacks. The following paper will be used as a reference: https://arxiv.org/abs/2402.09154",6,"Python, Basics of Probability and Statistics.
Experience with python libraries (including PyTorch/TensorFlow, NumPy, Matplotlib) is preferred, but you can learn on the go :)",projects/default.png,https://drive.google.com/file/d/1wqDoUy_1DaPQrlG87L8Q4sxiTwYVMhF7/view?usp=drivesdk,"Week 0-1.5 - Required Optimization Theory (simplex, entropy, discrete optimization), Gradient Descent, theoretical understanding of LLMs and Prompt Learning. 
Week 1.5-2.5 - Reading the Paper. 
Week 2.5-5 - Coding the algorithms. 
Week 6 - Fine-tuning the LLM on adversarial prompts. 
Week 7 - Testing and Documentation.","Checkpoint-1: Preliminary Theory
Checkpoint-2: Paper Reading
Checkpoint-3: Implementing the algorithms
Checkpoint-4: Coding the supplementary files to facilitate the execution of the code (train.py, test.py, utils.py etc)
Checkpoint-5: Fine-tuning the LLM",ML
90,Manav Patel 22B0989,LiteTune - Parameter efficient tuning of transformers,No co-mentors,Natural Language Processing,"Transformers have revolutionized the field of natural language processing (NLP), introducing unprecedented capabilities in tasks such as language generation, translation, and sentiment analysis. With models like GPT-3.5 boasting a staggering 175 billion tokens, the sheer scale of these architectures has opened new horizons for AI-driven language understanding. However, as transformer models have grown in size, so too has the demand for more efficient fine-tuning methods. Traditional fine-tuning approaches may struggle to cope with the immense complexity of these large-scale models. In response, innovative techniques like Prefix Tuning have emerged, offering a promising avenue to enhance model performance without compromising efficiency. In this project, we delve into the realm of Prefix Tuning, exploring its potential to optimize transformer-based NLP models for a wide range of tasks and applications.


Repo link to my code :-

https://github.com/manavpatel03/SentiMeter-Review-Sentiment-Classifier",7-8,"None, but basic python knowledge and familiarity with libraries like is beneficial",projects/Display.jpg,https://drive.google.com/file/d/1bvN0xlS766-KM_0DukuQQiS2qsmaJSbB/view?usp=sharing,"Here's an improved version of the text with better formatting, grammar, and clarity:

**Week 1**
- Introduction to Basic Python
- Data Visualization using Matplotlib
- Understanding Data Distribution
- Working with NumPy

**Week 2**
- Introduction to Linear Regression
- Introduction to Logistic Regression

**Week 3**
- Neural Networks
- Forward Propagation
- Backward Propagation

**Week 4**
- Checkpoint 1: Basic Classification using Neural Networks

**Week 5/6**
- Introduction to Sequence Models: Recurrent Neural Networks (RNNs)
- Word Embeddings
- Introduction to Transformers (using videos and articles)
- Basic Fine-tuning Task for Text Classification

**Week 7/8**
- Final Implementation of the Research Paper: ""Prefix Tuning/Prompt Tuning""
- Exploring a method that reduces trainable parameters by approximately 1000x
- Getting familiar with Pytorch to implement the idea","1 --> Basic Python assignment to get familiar with numpy, matplotlib etc
2 --> Neural network with 1 hidden layer to classify MNIST dataset
3 --> Pytorch assignment to get familiar with basic pytorch
4 --> Fine tuning assignment to introduce to Huggingface pretrained models
5 --> Final implementation of the research paper ""Prefix-Tuning: Optimizing Continuous Prompts for Generation""",ML
91,Menda Hima Vamsi  22b1001,Competitive Programming,"Gnana Mahesh Vetcha (22b0949), Trasula Umesh Karthikeya (22B0913)",Competitive Programming,"This project offers a comprehensive pathway from beginner to pro in Competitive Programming (CP). Mentees will dig into essential data structures and algorithms vital for CP, drawing from standard algorithmic literature and competitive programming handbooks. Through problem-solving on platforms like CSES Problem Set and Codeforces, alongside tailored weekly or biweekly assignments, participants will steadily build their skills. The goal is to encourage comfort and proficiency in commonly used CP algorithms and structures, providing guidance, experiences, and strategies along the way. By embracing a supportive community atmosphere and regular participation in CP contests, mentees can expect a journey of continuous improvement, ultimately transforming from novices to adept CP practitioners.
",8-10,"Basic CS 101 knowledge, proficiency in at least one language (most commonly c++ or python)",projects/cp_soc.png,https://drive.google.com/file/d/1aXnwKlUYFosYk2HIf0gL0kzYt1RjN9ak/view?usp=sharing,"Week 1: Foundations of Programming and Data Structures

Topics:
Basic programming exercises focusing on logic and problem-solving skills.
Introduction to C++ STL Basics including vectors/arrays.
Activities:
Practice basic programming exercises.
Get comfortable with own competitive programming (CP) template and predefined functions.
Explore concepts like stacks, queues, sliding window, two-pointer method, basic bit operations, etc.

Week 2: Building on Basics and Introducing Algorithms

Topics:
Sorting and Searching Algorithms.
Introduction to Divide and Conquer.
Activities:
Explore sorting and searching algorithms.
Learn about Divide and Conquer paradigm.
Solve problems related to these topics.
Introduction to C++ STL algorithms like binary search, sort, etc.

Week 3: Data Structures and Advanced Algorithms

Topics:
Graph Algorithms (DFS, BFS, graph representation).
Greedy Algorithms.
Activities:
Study and practice graph algorithms.
Explore greedy algorithms and their applications.
Solve problems related to graph algorithms and greedy approach.

Week 4: Dynamic Programming and Advanced Concepts

Topics:
Dynamic Programming (DP).
Introduction to Range Queries.
Activities:
Understand DP concepts and techniques.
Explore problems on dynamic programming.
Introduce range queries and their applications.

Week 5: Advanced Algorithms and Techniques

Topics:
Advanced Dynamic Programming.
Flow Algorithms.
Activities:
Dive deeper into dynamic programming with more challenging problems.
Explore flow algorithms and basic implementations.
Solve moderately challenging problems related to flow algorithms.

Week 6: Advanced Data Structures and Trees

Topics:
Segment Trees.
Fenwick Trees.
Implementing Djikstra's Algorithm.
Activities:
Study segment trees and fenwick trees.
Implement Djikstra's algorithm.
Solve problems involving these advanced data structures and algorithms.

Week 7: Contest Participation and Review

Topics:
Participate in various contests on competitive programming platforms.
Activities:
Participate actively in contests to apply learned concepts.
Analyze contest problems and solutions.
Review weaknesses and areas needing improvement.

Week 8: Consolidation and Improvement

Topics:
Review weak areas and challenging problems.
Encourage self-improvement through editorial reading and code analysis.
Activities:
Address weaknesses identified in previous weeks.
Aim to solve around 75 problems from various platforms with a good distribution of difficulty levels.","1) Arrays and Sorting:
 basic standard questions and models should be covered
Understanding Essential Data Structures and Algorithms
2) Dynamic Programming and Greedy Algorithms:
3) Third checkpoint is for increasing proficiency in the above topics and then next we go into graphs and trees.
4)Graph Algorithms:
 Weekly/Biweekly Assignments
5) Miscellaneous questions, how to get idea of what topic should be used exactly in a short time by seeing the question ",CP
92,Mohak Vyas 210040098,Sign language to text convertor (ASL2TXT),Hrithik (210040092),Machine Learning,"The goal of this machine learning project is to develop a system that interprets sign language gestures captured through a camera and converts them into text. 
We plan to train ML algorithms on Sign Language MNIST and train a model using CNN which takes an image of hand gesture of American Sign Language and shows the output of the particular sign language in text format converts it into text.
The project encompasses the basics of machine learning and computer vision.


https://docs.google.com/document/d/1FDZUo7p6y2ndVh24eykDaeEVakQ1YP--8wuYeYOhHco/edit?usp=sharing
",12,"No hard prerequisites...
That being said, some xp in openCV &/or CNN would be helpful.",projects/sign_lang.png,https://drive.google.com/file/d/1TknVJwPW0WDQN9ytQiddmwP6iN63x98J/view?usp=sharing, 92844 36016=> Hrithik),"Week 1 : python(numpy, panda) + open-CV 
Week 2 : Basic of ML
Week 3/4 : Deep Learning specialisation course
Week 5/6 : implementation
Week 7 : Presentation",ML
93,Mrinal Garg 22b0930,tRAYcer,"Kavya Gupta, Harsh Jakhar",C++ implementational project in Ray Tracing,"This Project introduces to a very useful and commonly used technique in image rendering- Ray Tracing. We start from the ""Hello world"" of image rendering to generating images like the banner of this project(Likely even more complex :)) just by feeding our program the ""scene"" we want to render. We also study techniques(used these days) and algorithms to fasten our image generation. Finally, we will benchmark our image using the popular(maybe) Cornell Box test.
Expected Learning Outcome: A deep knowledge and implementational skill in C++, learn about core important concepts like threads, how to modularize and effectively write code and the best part-you learn how to generate cool images.",4-5,Basic C++. Enthusiasm to learn something different. ,projects/img-2.23-book2-final.jpg,https://drive.google.com/file/d/1Z3b6FLMiApjJGiDd0PdBsPykAyGGXCa5/view?usp=sharing,"Week1-Learn about the actual aim of the project, What it means and why is it important. Some read ups regarding ray-tracing and all. Start with the basic class implementations for the library.
Week 2-Introduce inheritance through reading material, Optimistic goal of covering the hittable class.
Week-3 Let's pace things up. Understand smart pointers and related concepts. Understand Antialiasing and the concept of ""camera"". Introduce modularization  of code here. Also Makefiles.
Week-4-5-Explore various types of materials and play with parameters. At this point one should start experimenting with their code to understand the code better.  Let's aim to complete the Book1 here. Many new concepts are introduced here both mathematical and implementational.
Week 6- For the people done with previous stuff , we move on to Bounding Volume Hierarchies. 
Week 7-At this point let's try to move forward as much as possible. This can range from Completing ""Ray Tracing in one Weekend"" to completing the full project.","Checkpoint 1- Implementation of basic materials(Diffuse etc.).
Checkpoint 2- Implementation of Refraction.
Checkpoint 3- Rendering the Book1 final image.
Checkpoint 4- Implementing Bounding Volume Hierarchies
Checkpoint 5- Implementing a random scene given by mentors(not present in the book)",Others
94,Nandnee Priya 22B3302,Computational Graph Theory,Gaurav Revankar (22B0011),Computational Graph Theory,"This project introduces various graph algorithms used to solve problems like shortest path, maximal flow, etc. We will use BFS, DFS, Dijkstra and A*. Depending on the interest of mentees and timeline, we might also include RRT and RRT*. We will use Prim’s and Kruskal’s algorithm for Minimum spanning trees. For the bipartite matching problem, we will use the technique outlined by the algorithmic proof of Hall's theorem. Then we will solve it again using the network flow approach. We will introduce the Ford-Fulkerson Algorithm for Maximum Flow Problem. We will present different problems based on these algorithms where you can sharpen your problem-solving skills.  It will also help you in learning DSA. This project will also cover approximate algorithms for NP-hard problems like graph coloring and the travelling salesman problem. If time permits then we will implement multiple approximate algorithms for graph colouring and TSP, and compare their efficiency and completeness. You will also get to implement a sudoku solver using a graph colouring algorithm!
While you are not supposed to know any algorithms beforehand, do mention your previous coding experience if you have any.

A reference book is given below for understanding the mathematical theory behind graph algorithms. Other resources would also be given in the project on specific topics and implementation of algorithms.
Computational discrete mathematics combinatorics and graph theory with Mathematica (Sriram V. Pemmaraju, Steven S. Skiena)",8,Basic programming skills and an interest in mathematics and algorithms. Enthusiasm for puzzles can earn you brownie points!,projects/DALLE3_GraphTheory.png,https://drive.google.com/file/d/1F8EhrJyWfOxgcwagUuj6M-Qo0DiBvDcp/view?usp=sharing,"Week 1: Learning the data structure of graphs and basic ideas about dynamic programming and greedy algorithm
Week 2: Implementation of BFS, DFS
Week 3: Dijkstra and A* search algorithm
Week 4: Minimum spanning tree algorithms
Week 5: Bipartite Matching problem, Hall’s Theorem
Week 6: Network Flow algorithms like the Ford-Fulkerson Algorithm
Week 7: Graph coloring algorithms and make a sudoku solver based on it
Week 8: Approximate Algorithms for the Travelling Salesman Problem","Checkpoint 1: Implementation of BFS, DFS
Checkpoint 2: Shortest path search algorithms like Dijkstra and A*
Checkpoint 3: MST and bipartite matching problem
Checkpoint 4: Network flow problems and graph coloring algorithms
Checkpoint 5: Implementation of approximate algorithms for TSP",Others
95,Navya 22b1007,Statistical Methods For Image Segmentation ,"Sambhav Jain (22b0932), Adwai (22b1282)",Image Processing,"Project will be based on exploring the statistics behind image segmentation and implementing algorithms. It will start with learning basics of probaility like random variable, probability distribution function and unsupervised clustering methods.  This will be followed by learning advanced techniques for image segmentation such as Gaussian Mixture Modelling etc. Meanwhile, mentees will also have to implement different algorithms for image segmentation, understand how the algorithm works, what are issues with it and how the newer algo rectifies it. In order to check on copying, vivas may be conducted after assignments.   

Search for ""Tissue Segmentation in Brain MRI"" It has many applications in biology and medicine. ",10,Applicant must be excited and dedicated to learn probability and statistics. The project will involve a lot of it. He/she can expect mathematical analysis of algorithms. Prior knowledge of python is good to have but not mandatory.      ,projects/default.png,https://drive.google.com/file/d/1auXkX3rhcbk15CqOwzoTKARVZWIyOpWt/view?usp=drive_link,"First week : Random variables, PDF, Joint and Conditional PDFs, Basics of python
Second week : K - means clustering, Fuzzy - C - means clustering, Implementation 
Third week : Multivariate Gaussian, fun exercise on it
Fourth week : Gaussian Mixture Modelling and EM method
Fifth week: Implementing GMM-EM for image segmentation.
Sixth week: Markov Random Field, MAP method
Seventh week: Improving Image Segmentation method by HMRF
Eight week: Improving Image Segmentation method using saliency map","Checkpoint-1 : Basics of Python and Probability
Checkpoint-2 : Foundational algorithms and statistics for Image Segmentation
Checkpoint-3 : Learning GMM- EM and Implementing it
Checkpoint-4 : Statistics for Advanced methods
Checkpoint-5:  Implementing Advanced Image Segmentation algorithm   ",ML
96,Neha Pedgaonkar 22B1805, Adaptive Automated Car Parking Simulator,Jalajakshi Palli (22b1047),Machine Learning,"In the Adaptive Automated Car Parking Simulator project, you'll design and implement reinforcement learning algorithms that enable an AI agent to navigate through environments with moving obstacles to reach and park the agent in the parking space. 

Resources:
Book- Reinforcement Learning: An Introduction (by Sutton & Barto)
Websites- Medium (for MDPs & Q - learning ), 
https://gibberblot.github.io/rl-notes/single-agent/multi-armed-bandits.html   (for MDPs & Multi-armed bandit).",9-10,"Intermediate level.
Good understanding of Python required. Any prior experience could earn you brownie points. ",projects/Firefly 3. Automated Car Parking Simulator Week ... elop an RL agent that learns to park a car i.jpg,https://drive.google.com/file/d/1atyUvduSihkMe0qxdMKez4aHs5cYxKR8/view?usp=sharing,"Week 1) Quick revision of Python and introduction of ML. 
Week 2) Overview of reinforcement learning, differentiating it from supervised learning, and introducing core RL terminology and exploration strategies.
Week 3) Deep dive into Markov Decision Processes (MDPs) and the value iteration algorithm, including its formal proof of convergence and practical implementation.
Weeks 4-5) Learning and applying the Q-learning algorithm through the development and training of an agent in the OpenAI Gym environment to achieve successful parking of the agent without the presence of any obstacles or environmental movements. 
Week 6) Strategies for handling dynamic obstacles, including environment representation and prediction models, and techniques for dealing with partial observability in RL. 
Weeks 7-8) Introduction to advanced RL techniques such as Deep Q-Networks (DQN) for high-dimensional state spaces and Policy Gradient Methods like REINFORCE and actor-critic methods for direct policy optimization and Training of an agent in openAI Gym environment, culminating in the project demonstration.","Checkpoint-1: Crack the Multi-Armed Bandit implementing Epsilon-Greedy, UCB & Thompson Sampling algorithms.
Checkpoint-2: Solving MDPs using Value-Iteration algorithms.
Checkpoint-3: Successfully parking the automated agent by implementing Q - Learning Checkpoint-4: Completion of the assignment implementing RNN.
Checkpoint-5: Create an agent to navigate dynamic environments with moving obstacles and park. ",ML
97,Nidhi Prajapati 21D180026,spam mail detection,Nidhi Prajapati (21D180026),Machine Learning,"1. https://www.youtube.com/watch?v=YncZ0WwxyzU&ab_channel=CampusX
2. https://sifisheriessciences.com/index.php/journal/article/download/1249/624/1390
3. https://www.youtube.com/watch?v=7wnove7K-4.ZQ&list=PLu0W_9lII9agwh1XjRt242xIpHhPT2llg&ab_channel=CodeWithHarry
5. https://www.youtube.com/watch?v=rxkGItX5gGE&ab_channel=Siddhardhan
6. https://www.youtube.com/watch?v=gmvvaobm7eQ&list=PLeo1K3hjS3uvCeTYTeyfe0-rN5r8zn9rw&ab_channel=codebasics
7. https://github.com/topics/email-spam-detection


One of the primary methods for spam mail detection is email filtering. It involves categorize incoming emails into spam and non-spam. Machine learning algorithms can learn from labeled email datasets to build models capable of recognizing patterns indicative of spam. These models can then be used to automatically classify new, unseen emails.",8-10,"Basic understanding of Python
Basic ML concepts is plus, however can be learnt
loads of enthusiasm",projects/default.png,https://images.app.goo.gl/J9rJ9R2ebskyRPSE8,"Week 1 : Basics of Python

Week 2 : Python Libraries i.e. scikit-learn, TensorFlow, or PyTorch

Week 3 : Basics of Machine Learning

Week 4 : ML algorithms i.e, Naive Bayes, Support Vector Machines (SVM), Random Forest

Week 5 : Data Cleaning & Exploratory Data Analysis (EDA)

Week 6 : Text Preprocessing & Model Building

Week 7 : Evaluation  & Improvement

Week 8 : deploy
","Checkpoint 1 : Python training
Checkpoint 2 : Machine Learning training
Checkpoint 3 : Exploratory Data Analysis (EDA)
Checkpoint 4 : Model Building or writing code 
Checkpoint 5 : Term Report Preparation & Video Recording
Checkpoint 6(additional) : Create a web interface to check if mail is spammed or not.
",ML
98,Nilabha Saha 210260037,Algorithmic Number Theory and Algebra,,Algorithmic Number Theory,"In this project, we will develop a library from scratch in Python implementing various algorithms for topics based on number theory and algebra. We will also implement algorithms which are used to attack several cryptosystems in the real world.

For the content, we will largely follow Victor Shoup's book ""A Computational Introduction to Number Theory and Algebra"". There is a significant amount of mathematics involved in understanding the theory underlying these algorithms, and this whole project would be very unrewarding without an appreciation for the underlying mathematics. You may expect a healthy balance between both theory and coding in this project.",4-5,"Knowing how to code in Python is a must.
Comfort with mathematics would be extremely helpful.",projects/Banner.jpg,https://drive.google.com/file/d/1WurtWbNiitgFf03BvwqWGuUcYiHBoyL3/view?usp=sharing,"Week 1: Congruences, Modular inverses, Euclid's Algorithm
Week 2: Quadratic Residues, Chinese Remainder Theorem, Fast Exponentiation
Week 3: Probabilistic Algorithms 
Week 4: Primality Checking (Probabilistic and Deterministic)
Week 5: Quadratic Reciprocity, Modular Sqaure Roots, Generator Finding, and Discrete Logarithm Problem
Week 6: Subexponential-time algorithms for DLP and Factoring
Week 7: Algorithms for Finite Fields
Week 8: Documentation and Finalisation","Checkpoint-1: Contents of Weeks 1-2 implemented 
Checkpoint-2: Contents of Weeks 1-4 implemented
Checkpoint-3: Contents of Weeks 1-6 implemented
Checkpoint-4: Library code finalised
Checkpoint-5: Fully documented library finalised",Others
99,Nilesh Choudhary 200110074,DEEP-VOICE: DeepFake Voice Recognition,"Harshit Upadhyay, (200110044)",Deep Learning,"There are growing implications surrounding generative AI in the speech domain that enable voice cloning and real-time voice conversion from one individual to another. This technology poses a significant ethical threat and could lead to breaches of privacy and misrepresentation, thus there is an urgent need for real-time detection of AI-generated speech for DeepFake Voice Conversion. You will gain hands-on experience in hot AI/ML areas like data analysis, model building, and real-time processing.. We will use various machine learning and deep learning algorithms to see which performs best for our model. 

",5-10,"Basics of python.
Basic knowledge of machine learning will be helpful but not required",projects/default.png,https://images.ctfassets.net/cnu0m8re1exe/6pHDO2pgfqi5cJv3m0cTmo/c815b159250ee2f4464859dacee39bf6/Untitled_design_-_2022-11-15T122800.147.png?fm=jpg&fl=progressive&w=660&h=433&fit=fill,"Week 1-3: Laying the Foundation: Explore Core Machine Learning and deep learning concepts and Algorithms
Week 4-5: Data Wrangling and Analysis: Prepare and Understand the Data for Modeling
Week 6-7: Model Development and Training: Build, Train, and Evaluate Different Machine Learning Models
Week 8: Performance Evaluation and Insights: Analyze the Final Results and Draw Conclusions","Checkpoint 1: Creating a Jupyter Notebook
Checkpoint 2: Basic Data Analysis
Checkpoint 3: Approach
Checkpoint 4: Sample Model
Checkpoint 5: Final Report  ",ML
100,Omkar Nitsure 210070057,The notion of an emotion,Dhruvi Ganatra (21d070027),Natural Language Processing,"An early morning newspaper reporting riots in the country makes our mood gloomy. A smile embarks on our face after reading a comic novel. What if machines could also be sensible enough to detect and identify emotions by parsing a text? It would be a blast! We could have our own models  identifying the sentiment of the market and and devising optimal trading strategies or we could use them for providing consumer recommendations. This is one of the stepping stones to delve into the world of NLP.  We hope to introduce you to the exciting domain of NLP and give a feel of how the current GPTs work, along with a hands on experience to build a complex emotion detector. Join us for a fun summer learning NLP!",6-8,,projects/banner_img.png,https://drive.google.com/file/d/1ElHI-rnslCDVXHLHaAh3TTjtbhWLe0r9/view?usp=sharing,"Week 1: Basic Python brush up with some additional Libraries
Week 2: Learning to build and train models in PyTorch
Week 3: Learn to use Huggingface for various tasks
Week 4: Learn theoretical aspects of NLP
Weel-5: Understand the Transformer architecture and implementations
Week 6: Understand BERT and how pre-trained models can be finetuned for specific NLP tasks
Week-7&8: Work on the final implementation of Emotion Detector and improve accuracy","Checkpoint-1: Introduction to PyTorch and HuggingFace
Checkpoint-2: Theoretical aspects of NLP
Checkpoint-3: Implementation of some models for simple NLP tasks in PyTorch
Checkpoint-4: Transformers and BERT architectures
Checkpoint-5: Final implementation of Emotion Predictor",ML
101,Param Shah 210050144,Learning Machine Learning,Shantanu Welling (210010076),Machine Learning,"It is often the case that students start completing difficult ML tasks (for example Face Recognition) using libraries like SciKit-Learn/PyTorch (not to mention public GitHub repositories) without even knowing basic concepts of Machine Learning like gradient descent, back-propagation or convolution. This project will aim to fill the separating river with stepping stones, where the students will build their own ML library and utilise it to complete a task of their choice. Hence, they shall develop a strong intuition for ML.",6,"Basics of Python programming, Enthusiasm, Good understanding of probability and linear algebra is a bonus",projects/default.png,https://drive.google.com/file/d/17kCVIrZw_au-42sQay5b3_9zWzq4kPDe/view?usp=drive_link,"Week 1: Brush up python skills and pick-up basic OOP concepts
Week 2: Learn the mathematical tools required for ML
Week 3: Read the ML material provided
Week 4: Master vectorisation using the NumPy library
Week 5-6: Build your own ML python library
Week 7-8: Utilise the homemade library to complete a ML task of choice","Checkpoint-1: Grasping mathematical ideas involved in ML
Checkpoint-2: Understanding ML
Checkpoint-3: Getting used to the NumPy library and vectorisation
Checkpoint-4: Self-implementation of the necessary ML modules
Checkpoint-5: Completing a ML task of choice using the homemade library",ML
102,Parshva Roliya 22b2722,Shaka Laka Boom Boom: Gesture based text creation,"Garvit Jain (22b2728), Shorya Sethia (22b2725)",Machine Learning,"Ever thought about writing in the air, like making doodles with your fingers? Well, imagine if you could do that and have it show up on a computer screen! That's what we're gonna work on together in this cool project called the ""Virtual Notepad."" Over the next couple of months, we'll learn how to use some fancy tech stuff to make it happen.

First, we'll learn about Fundamentals of ML, CNN architecture and OpenCV. Then, we'll figure out how to make a digital canvas where you can draw by moving your hands around. After that, we'll teach the computer to recognize what you're drawing, like letters and classify them accordingly

As we keep going, we'll make sure everything works smoothly and fix any hiccups along the way. Finally, we'll show off our awesome creation to everyone! So get ready to dive into some tech magic and turn your doodles into digital art and get identified what you wrote!",8,"Basics of python, strong dedication and Enthusiasm",projects/SoC_Banner.png,https://drive.google.com/file/d/1DiLnPC9kIsoPIxKLvil0tqGv0O5UKleB/view?usp=sharing,"Week1: Python programming and introduction to libraries like numpy and pandas along with fundamentals of machine learning
Week2: Introduction to OpenCV, including reading and displaying images along with fundamentals of Neural Network architectures
Week3: Creating a blank canvas using OpenCV and capturing video input from a webcam
Week4: Training a simple CNN model on the MNIST dataset for handwritten Alphabet recognition
Week5: Implement hand detection and tracking using OpenCV to identify hand movements and gestures on the canvas
Week6: Teach mentees about image preprocessing techniques such as converting to grayscale, resizing, and normalization
Week7: Assist mentees in integrating the trained model with the OpenCV code for real-time character recognition on the canvas
Week8: Buffer, Refinement and Presentation ","Checkpoint 1 : Have mentees demonstrate their understanding of OpenCV basics and fundamentals of machine learning 
Checkpoint 2 : Successfully implemented the canvas creation and learning Neural network Architecture
Checkpoint 3 : Understanding of image preprocessing and model training with hand detection functionalities
Checkpoint 4 : Successful integration of the model with the OpenCV, CNN architecture and validate the accuracy of character recognition.
Checkpoint 5 : Final Project Development and Presentation",ML
103,Parth Rasal 22B2236,Image Captioning Using Attention Mechanism,"Soham Joshi (22B2495), Abhishek Kumar (22B2210)",Image Processing,"The project is based on image captioning using CNN encoder and LSTM decoder. This project was done by my co-mentor in WiDS. Unfortunately, the output predicted in that project was not quite good. Hence, we have decided to incorporate the attention mechanism in the encoder and decoders.
Shared below is the WiDS project link my co-mentor has completed:
https://github.com/Soham-joshi04/Image-Captioning/blob/main/Image_Captioning.ipynb",10,Python and Basic Familiarity with Machine Learning,projects/default.png,https://drive.google.com/file/d/1Y4l6FbXu53EHVoyEsKiYyygL27rWX2Ha/view?usp=sharing,"Week 1: Learning Neural Networks 
Week 2: Exploring Convolutional Neural Networks 
Week 3: Exploring Sequential Models (RNN, LSTM)
Week 4: Learning Basics of Natural Language Processing
Week 5: Understanding Attention Mechanism & Encoder-Decoder Architecture
Week 6 & Week 7: Building Model","Checkpoint-1: Basic Classification Task using Neural Networks
Checkpoint-2: Classification of Images using CNN
Checkpoint-3: Stock Prediction using Sequential Models (Hands on with Sequential Model)
Checkpoint-4: Sentiment Analysis using NLP
Checkpoint-5: Final Model",ML
104,Pawan kumar 21b030025,Virtual Mouse Control using Hand Gestures,No,Image Processing,"    Understanding Image Processing: This project heavily relies on image processing techniques to interpret hand gestures captured from a webcam. Mentees need to understand concepts such as image representation, color spaces, thresholding, contour detection, and feature extraction to preprocess the video frames and detect the hands accurately.

    Resources:
        Book: ""GLOBAL EDITION Digital Image Processing FOURTH EDITION Rafael C. Gonzalez • Richard E. Woods
         
        Tutorial: Tech With Tim (https://youtube.com/playlist?list=PLzMcBGfZo4-lUA8uGjeXhBUUzPYc6vZRn&si=ykj-Pl58LXQ0m-rx)

    Hand Tracking and Landmark Detection: Hand tracking is a crucial aspect of the project. Mentees should learn about machine learning-based approaches for hand detection and landmark estimation. Libraries like Mediapipe provide pre-trained models for this purpose.

    Resources:
        Documentation: Mediapipe library documentation
        Tutorial: Hand Tracking 30 FPS using Python"" by Murtaza's Workshop - Robotics and AI

    Mouse Control and Gesture Recognition: Mentees need to map the detected hand gestures to mouse movements, clicks, scrolls, etc. Understanding coordinate mapping, cursor control, and simulating mouse events programmatically is essential.

    Resources:
        Documentation: PyAutoGUI library documentation
        Tutorial: ""Automate Anything with Python: PyAutoGUI for Mouse and Keyboard Automation"" by Al Sweigart

    Real-time Video Processing: Since the project involves processing video frames in real-time, mentees should learn about optimizing code for real-time performance, multi-threading, and handling video streams efficiently.

    Resources:
        Tutorial: https://youtube.com/playlist?list=PLQVvvaa0QuDdttJXlLtAJxJetJcqmqlQq&si=DasytiXRmieihoAT
        
    User Interface Integration: Integrating the virtual mouse control with a user interface (like the provided Tkinter GUI) enhances the project's usability. Mentees should learn about GUI frameworks and event-driven programming.

    Resources:
        Book:  
        Tutorial: https://youtube.com/playlist?list=PLs3IFJPw3G9IiHm9PEP1UaMtuvACmxVMj&si=ozUFTBGc4KwwWcvt
",4,"Python Programming, git, Motivation and Persistence",projects/default.png,https://drive.google.com/file/d/1kHXhSxdyfiMnQJe27d86Q5moNyM-KeSy/view?usp=sharing,"   Week 1: Introduction to Python programming language: syntax, variables, data types, operators, and basic input/output.
    Week 2: Control flow statements: if-elif-else, loops (for and while), and basic error handling (try-except).Introduction to Python standard library and commonly used modules (e.g., math, random)
    Week 3: Understanding external libraries and package management: installing, importing, and using third-party libraries (e.g., OpenCV, PyAutoGUI).
    Research image processing, computer vision concepts related to hand gesture recognition, and machine learning-based approaches for hand tracking.
    Week 4: Begin implementing hand tracking functionality using the Mediapipe library. Experiment with different hand detection models.
    Week 5: Continue implementation and integrate hand tracking with mouse control using PyAutoGUI. Implement GUI integration for visualizing the virtual mouse control interface.
    Week 6: Test the virtual mouse control system with live webcam feeds. Identify and debug any issues related to hand tracking accuracy and mouse control responsiveness.
    Week 7: Optimize code for real-time performance. Prepare comprehensive documentation covering project overview, implementation details, and usage instructions.","   1: Setup and Environment Configuration
  2: Hand Tracking Implementation
  3: Mouse Control Integration
  4: GUI Integration and User Interface
  5: Testing, Optimization, and Documentation",ML
105,Polamreddy Mohit Krishna 21B030026,Supply chain optimisation using advanced machine learning algorithms.,"Aryan Khaparde, 21B090020 ,Samuel  21B030031 and Vanshika 21B030038",Machine Learning,"This Project aims to make a completely optimisation supply chains for industries for various     variables and parameters to work on with sustainable chains, cost reduction, etc works.",15-20,Basics of python and some python libraries also basics of machine learning will be a plus,projects/Capture7.PNG,https://drive.google.com/file/d/10Bkq8xlPyuGs-2xHWifsHS_bEbab5C6K/view?usp=sharing,"Basics of Machine Learning ,learning optimisation tools and pyomo tools , starting with making up the model, research work in various new technologies and combining seperate models, report and documentation.","Checkpoint-1:Basics of Machine Learning 
Checkpoint-2:Starting with learning optimisation tools and pyomo tools and other works.
Checkpoint-3: Then research work in various new technologies 
Checkpoint-4:Merging of various optimised bits of chains and making the final model
Checkpoint-5:Final Documentation of the work done and making final report and also Working on the models",ML
106,Prabhu Sagar Chaudhary 22b0683,TechTutor,Shahu Patil(22b2126),Web Development,"We are going to make an Ed-tech website by using MERN stack.So we need to learn programming languages, frameworks, and tools best suited for developing our website (e.g., HTML/CSS, Tailwind,JavaScript,React ,Mongo DB,Node JS etc.).

Resources-
1..
https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://developer.mozilla.org/&ved=2ahUKEwjBouKLkrOFAxXZlFYBHd2JBVoQFnoECBAQAQ&usg=AOvVaw2SKyx0njvBQRAGWeriS8JP

2.
https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.w3schools.com/&ved=2ahUKEwjX4IWZkrOFAxWes1YBHfy3CyYQFnoECAoQAQ&usg=AOvVaw3Z63kcF6aawsbVZrfSzalJ



",6,,projects/default.png,https://1drv.ms/i/s!Ao_KIXFE0mqshzQjcPJ8iL-ukXDA?e=a9u8LL,"week 1:Learn  HTML & CSS
week 2:learn some of the basics of JavaScript
week 3:Learn React JS(basic)
week 4:Learn React JS(advance)
week 5-6-7: Backend Development","Checkpoint 1: Development environment set up, basic web page created using HTML/CSS/JavaScript.

Checkpoint 2: Static frontend components for at least one page completed with React.

Checkpoint 3: Basic backend server with RESTful API endpoints created using Node.js and Express.

Checkpoint 4: Database connected and schema implemented with MongoDB.

Checkpoint 5: All features implemented and tested, code optimized, and project ready for presentation.",Development
107,Pramiti Kumar Rana 22B3956,QuantEdge: Financial Analytics,NIL,Finance and Quant,"In this project, we take the first week a bit easy and just brush up on our previous concepts of python. I'll be giving them a few codes to work on from the book python crash course by Eric Matthews. In the 2nd week we start with the fundamental concepts related to finance. We start fundamental analysis in the 2nd week and then continue them for while during week 3 as well. Basically during week 2, 3 and 4 I would like the mentees to be thorough with Fundamental as well as Technical Analysis. For this I will be giving them material to study from Zerodha, Ticker, some materials I have from this project I did with Finlatics and a few other really insightful blogs I've come through on the internet. During the week 5, I would have the mentees start reading a few blogs on quantitative finance and how python can be used for trading and how they can do fundamental analysis of Stocks using Python. They can start having hands on practice on these concepts and learn more and more on them during week 6. During week 6 and 7 they would just be focusing on building on Technical Indicators in Python and practising as much as possible.During week 8 I would give them an insight on how world quant brain works and have them start working and studying about how to build alphas.",6-8,Basic Coding in Python,projects/1*BB1Py6rwDYtKt--p31N-UQ.jpg,https://drive.google.com/file/d/171RhVYNUwDD67XWM79RWM7sX6tw6V3bU/view?usp=sharing,"In this project, we take the first week a bit easy and just brush up on our previous concepts of python. I'll be giving them a few codes to work on from the book python crash course by Eric Matthews. In the 2nd week we start with the fundamental concepts related to finance. We start fundamental analysis in the 2nd week and then continue them for while during week 3 as well. Basically during week 2, 3 and 4 I would like the mentees to be thorough with Fundamental as well as Technical Analysis. For this I will be giving them material to study from Zerodha, Ticker, some materials I have from this project I did with Finlatics and a few other really insightful blogs I've come through on the internet. During the week 5, I would have the mentees start reading a few blogs on quantitative finance and how python can be used for trading and how they can do fundamental analysis of Stocks using Python. They can start having hands on practice on these concepts and learn more and more on them during week 6. During week 6 and 7 they would just be focusing on building Technical Indicators in Python and practising as much as possible.During week 8 I would give them an insight on how world quant brain works and have them start working and studying about how to build alphas.","Checkpoint 1: Basic Python and Fundamental Analysis.
Checkpoint 2: Fundamental and Technical Analysis.
Checkpoint 3: Quantamental and Trading strategy using fundamental data/ Fundamental Analysis of Stocks using Python.
Checkpoint 4: Technical Indicators in Python
Checkpoint 5: Building Alphas",Others
108,Pranav Singla 200040102,Few Shot Domain Generalisation,Neeraj Nixon (20D070056),Deep Learning,"The initial stages of the project would involve reading up about Machine Learning (Few shot and Zero shot ML). Followed by this simple Neural Networks (Multi Layered Perceptrons) would be introduced. A few layered Neural Network would be trained on the MNIST dataset. Next Convolutional Neural Networks would be introduced and a CNN model would be used for MNIST digit classification for improving results. Finally Domain Generalisation/Domain Adaptation techniques would be introduced by sharing papers and research articles. The final aim of this project would be to combine all the above knowledge gained in building a  U-net + ResNet18 classifier and use some of the classes for Few shot classification task. We will be building a Multi Domain classifier (U-net + ResNet18) model using the PACS dataset (4 domains and 7 classes) 

Resources/GitHub repos/Demonstrations:-

https://blog.paperspace.com/few-shot-learning/
https://www.geeksforgeeks.org/introduction-deep-learning/
https://dgresearch.github.io/
https://github.com/yulearningg/LRDG ",5-6,Basic Python Programming and Enthusiasm to Learn! (Basic ML knowledge - soft prerequisite),projects/default.png,https://drive.google.com/file/d/1yG4nlffpFiYEexrI32krrz1yHbNitBLt/view?usp=drive_link,"Week 1 : Introduction to ML, Few-shot ML and Zero-shot ML
Week 2 - 3.5 : Introduction to DL (Simple Feedforward Neural Network or MLP)
Week 3.5 - 4 : Building a MNIST digit classifier with CNN
Week 5 - 6 : Introduction to Domain Generalisation
Week 7 - 8 : Building Few-shot DG classifier on PACS","Checkpoint 1 - Introduction to ML, Few-shot ML and Zero-shot ML
Checkpoint 2 - Introduction to DL (Simple Feedforward Neural Network or MLP)
Checkpoint 3 - Building a MNIST digit classifier with CNN
Checkpoint 4 - Introduction to Domain Generalisation
Checkpoint 5 - Building Few-shot DG classifier on PACS",ML
109,Pranjal Sankhwar 210020097,ReinFLY: AI Learns to Play Flappy Bird,"Dheeraj Kumar Solanki (210020041) , Falak Mujeeb (210020047)",Machine Learning,"This project aims to train an agent to play Flappy Bird using reinforcement learning (RL). We'll build a custom Flappy Bird game using Pygame and integrate RL techniques. A reward system will be implemented to guide the agent's learning. Positive actions like passing pipes will be rewarded, while collisions will be penalized.

The core part involves training the RL model within the game environment. The agent will learn from its interactions with the game, constantly adjusting its strategies to achieve a higher score and survive longer. Finally, we'll evaluate the trained agent's performance based on metrics like average score and gameplay duration. This project showcases RL's ability to tackle challenging tasks in a game environment. The learnings from this project can potentially be applied to various real-world scenarios beyond games.",10,,projects/flappy.jpg,https://drive.google.com/file/d/1nS7dIB_WqcWRBFo8jc7Vxt6yRd_bNXdE/view?usp=sharing,"Week 1:
Learn basics of Python library Pygame, setup Pygame environment with the game window, bird, pipes, background, and collision detection. Implement scoring system and user input.

Week 2:
Learn the basics of reinforcement learning.

Week 3:
Research various RL algorithms suitable for Flappy Bird (e.g., Q-learning, DQN, policy gradients) and choose one.

Week 4:
Define the state representation for the RL agent (bird's position, velocity, distance to pipes, etc.).
Integrate the RL agent with the game environment.

Week 5:
Design a reward structure that encourages the bird to stay alive and pass through pipes.
Implement the reward system within the RL training loop.

Week 6:
Begin training the RL model on the Flappy Bird environment.
Monitor training progress and debug any issues.

Week 7-8: Testing and Evaluation","Checkpoint 1: Setting up pygame environment, successfully recreating the entire game.

Checkpoint 2: By week 4, successful integration of the chosen RL algorithm with the Flappy Bird environment with an appropriate state representation for the RL agent. The RL agent should be able to interact with the game environment based on the defined state representation.

Checkpoint 3: By end of week 6,  a reward structure that incentivizes the RL agent to learn how to play game would be implemented to start the training process of the RL model on the environment using the defined reward structure and state representation.

Checkpoint 4: By week 7, conduct thorough testing of the trained RL model on the Flappy Bird environment. Evaluate the performance of the RL model based on predefined metrics such as average score, survival time, and any other relevant criteria. 

Checkpoint 5: Conclude with the project, compile the results, display plots of various metrics, and derive conclusions, with suggestions to improve the model's performance.",ML
110,Prashabdhi  22b0363,The Pixel Playground: Exploring UI/UX Development,Divyadarshan Soni,UI/UX development ,"Dive into the world of UI/UX Development through this project which introduces you to all key concepts that one requires for their Design path. You will learn how to use Figma and related platform, their tools and how to efficiently use them. Also you will get to know about design theories and apply all of these on mini projects every week. Finally you will design your own Online Learning App Platform. This projects requires no prior knowledge but will require you to work regularly.
You can always go through the ANT Design Guidelines: (https://ant.design/docs/spec/introduce) or read an article about color theory
(https://99designs.com/blog/tips/color-meanings/)",10,,projects/default.png,https://drive.google.com/file/d/1x1sunVCgAYeOB_6vEC1gcPiSQKEyrx8A/view?usp=sharing,"Week 1 - 
1) Introduction to Design
2) Familiarisation with Figma and it's tools
3) Making of first Figma Design

Week 2 -
1) Understanding of Design Fundamentals
2) Introduction to Design theories.
3) Project - Designing a Instagram post

Week 3 -
1) Wireframing and it's concepts
2) Introduction to wireframing platforms
3) Project - Making of first Wireframe

Week 4 -
1) Introduction to Advanced Color Theory
2) Making mockups out of the wireframes
3) Project - Revamp a popular app

Week 5 - 
1) Introduction to Advanced tools like components.
2) Prototyping in Figma
3) Project - Prototyping of the previous project

Week 6 -
1) Understanding UX (user experience)
2) Animations and advanced prototyping
3) Project -  E- commerce website design

Week 7 -
1) Final Project  - Designing an Online  Learning app platform featuring courses, degrees, certificate programs, etc
2) Applying all the concepts to improve the project","Checkpoint 1) Introduction to Figma and it's tools
Checkpoint 2) Wireframing
Checkpoint 3) Making of low fidelity mockups.
Checkpoint 4) Understanding UX concepts 
Checkpoint 5) Final Project",Others
111,Pratyush Ranjan 22b0326,Improving robustness of CNN through Attention Mechanism,Aman Kumar Singh(22b0321),Deep Learning,"Convolutional Neural Networks (CNNs) remain one of the most successful and prevalent deep learning architectures used today for Computer Vision tasks. Despite impressive results achieved by classical CNN designs, there is always room for improvement when dealing with real-world challenges such as occlusion, noise, varying scales, and low contrast images. In order to address these limitations, we require you to propose solutions involving attention mechanisms integrated within established CNN structures.
https://medium.com/heuritech/attention-mechanism-5aba9a2d4727 
Above is an article for overview of what is to be done at last week.
Your task includes designing and implementing attention mechanisms, drawing inspiration from existing literature or developing original ones if desired.
",8,"The primary prerequisites is enthusiasm to learn. Good grasp on Linear Algebra. Basics of Python is appreciated(If not, 1st week will involve learning Python)",projects/default.png,https://drive.google.com/drive/folders/1S8aFug6AESoEvAt6kM0xhYQj6uavyVLJ?usp=sharing,"Project Timeline

Week 1 : Basics of Python

Week 2-3: Learning about basic ML algos like Linear/Logistic Regression and mathematics involved in it

Week 4-5 : Learning about Neural Networks and implementing CNN and Transfer Learning on Popular Datasets like CIFAR10, MNIST etc.

Week 6-7:Learning about some improvements in CNN by learning about Attention Mechanisms and implementing the mechanism on basic CNN architectures (like ResNet,MobileNet etc)

Week 8:Observing the effects on various metrics involved in judging the efficiency of CNN. Document the overall learnings either in form of written report or video presentation as required by WnCC.
","Checkpoint 1:Learning python basics
Checkpoint 2:Basic Maths involved in ML
Checkpoint 3: Learning simple algos in ML like Linear/Logistic Regression
Checkpoint 4: Knowledge of Attention Mechanism
Checkpoint 5: Encapsulating everything learnt
",ML
112,Praveen 22b3931,Generative AI: Unveiling Image Generation with Text Conditioning,Swaprabha dey (22b1841),Deep Learning,"Are you curious about the latest advancements in AI image generation?

In this project we'll unravel the mysteries behind cutting-edge technologies like DALL-E, MidJourney, ChatGPT, and Gemini, which can transform text into breathtaking images. In this project, we'll delve into the fascinating world of image generation with AI and discover why diffusion models are leading the charge in this field.

While traditional approaches like Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) have paved the way for image synthesis, the spotlight now shines on diffusion models.

Start by understanding the fundamentals of diffusion models we'll delve deeper into conditional image generation, where you'll learn to generate images based on specific attributes like class labels and spatial arrangements. Then, explore the realm of conditioning image generation using textual prompts describing facial features.

You can see a basic overview about diffusion models in below video.
https://youtu.be/yTAMrHVG1ew?si=C70L5ExyTE9LHk19
",8-10 mentees,"1. Good knowledge of Python Programming
2. And a lot of Enthusiasm :)",projects/praveen.png,https://drive.google.com/file/d/1hV0uHn5J0di4xsJ9FHEym-0a2YHzA2KN/view?usp=sharing,"1. Reading research papers on stable diffusion models and understanding the mathematics behind the model.
2. Getting familiar with tools like PyTorch, Google colab, Github or preparing, Captioning and understanding datasets.
3. Implementing an unconditioned stable diffusion model for the MNIST and CelebHQ datasets.
4. Implementing a class-conditioned diffusion model for both datasets.
5. Implementing a spatial arrangement-conditioned diffusion model for both datasets.
6. Implementing a text-conditioned diffusion model for both datasets.
7. Improving the outputs, checking precision, and optimizing the model.","Checkpoint-1: Familirization with mathematics behind the Diffusion
Checkpoint-2: Implementation of unconditional diffusion model
Checkpoint-3: Implementation of class conditioned diffusion model
Checkpoint-4: Implementation of spatial arrangement conditioned diffusion model
Checkpoint-5: Implementation of text-conditioned diffusion model ",ML
113,Praveen vijay 22b3975,Solving the rubicks cube using reinforcement learning.,none.,Deep Learning,"The rubicks cube is a very complex puzzle to solve for an average person without external help. Even though the rubicks cube has almost 4.3x10^19 possible states did  you know it has been proved that we can solve it within a max of 20 moves from any starting state
( which is called the god's number, really go search it up)? That was the inspiration for this idea.

Since the rubicks cube is a huge state space with sparse rewards, we use an algorithm called Autodidactic iteration (ADI) to train a joint value and policy network. The targets seek to estimate the optimal value function by performing a breadth-first search from each input state and use the current network to estimate the values of each of the leafs in the tree. updated values for the root nodes are obtained by recursively backing up the values of each node using a max operator. This algorithm is to train the model/ estimate the value function. We then use search algorithms like A* or MCTS to find the optimal path from the start state to the goal state. which will act as the solver. 

3x3x3 cube demonstration: https://deepcube.igb.uci.edu/.
research paper to implement: https://arxiv.org/pdf/1805.07470.pdf
project already implemented for 2x2 cube: https://github.com/Debdut/dl-rubiks-autodidactic-solver?tab=readme-ov-file",4 to 5,"To know the basics of reinforcement learning, and have prior experience with neural networks, BUT of course nothing can beat the prerequisite of interest and enthusiasm!",projects/ruckis cube poster.jpg,https://drive.google.com/file/d/1pDePigfrb0I_UT7lSoB3zXUfj3Wrg5jX/view?usp=sharing,"-2 weeks to study about value and policy function approximation.
-1 week to do any 1 project involving value/policy function approximations
-1 week to study about what are model based algorithms and planning.
-1 weeks to study about the various search algorithms
-1 weeks to implement the two search algorithms.
-2 weeks for the actual project","-one project to familiarize yourself with using networks and function approximation.
-one project of implementing the A*  search algorithm.
-one project of implementing the MCTS search algorithm.
-implementing the ADI algorithm and training the joint value function.
-putting all of them together and finishing the project.",ML
114,Prince Kumar 22b2448,https://docs.google.com/forms/d/1M-p2Wxb34W5pQx2AcXOIxpwU9hiv6ln49Jz-T4U9-Q8/viewform?edit_requested=true,Deepak Silaych,Machine Learning,"The photo gallery platform utilizes advanced machine learning techniques for face detection and recognition to organize images based on the individuals present in them. Initially, the system employs computer vision algorithms to detect faces within each image, identifying facial landmarks and features. Subsequently, a facial recognition model analyzes these features to recognize individuals based on their unique facial characteristics. Upon identification, the platform automatically creates separate folders for each recognized individual, serving as personalized collections for their respective photographs. Images are then categorized into these folders, ensuring that each photo is appropriately organized according to the faces present. ",8,Not any hard prerequisites But basic knowledge of Python/Web Dev or ML will be useful,projects/different-gallery-types.png,https://drive.google.com/file/d/1s12xvJKirOEh7t0AnIFXPKddfsXwPVJ5/view?usp=sharing,"Week 1: Learning basics of Python and ML
Python basics: Covering syntax, data structures, and basic libraries such as NumPy and Pandas.
TensorFlow and Keras: Introducing machine learning concepts using TensorFlow and Keras for model development.
OpenCV: Learning basics of computer vision with OpenCV for image processing tasks.

Week 2: Diving deep in ML model
TensorFlow and Keras: Delving deeper into TensorFlow and Keras for building and training complex machine learning models, especially CNNs for image recognition tasks.
OpenCV: Further exploration of OpenCV for advanced image processing techniques required for face detection and recognition.

Week 3: Learning whole workflow of platform + Learning basics of web dev
FastAPI: Understanding the workflow of building RESTful APIs using FastAPI for backend development.
React: Learning basics of React for building interactive user interfaces for the photo gallery platform.

Week 4: Model training and testing
TensorFlow and Keras: Training machine learning models for face detection and recognition using TensorFlow and Keras, and evaluating their performance.
OpenCV: Utilizing OpenCV for preprocessing image data and preparing datasets for model training.

Week 5: Building Backend architecture
FastAPI: Implementing the backend architecture of the photo gallery platform using FastAPI for creating APIs to interact with machine learning models.
TensorFlow Serving: Integrating TensorFlow models into FastAPI for serving predictions.

Week 6: Building Website and Integration
React: Building the front-end components of the photo gallery platform using React for creating user interfaces.
FastAPI: Integrating the frontend with the backend APIs developed using FastAPI for seamless interaction with machine learning models.

Week 7: Testing + Bug Fixing + Deployment
Testing: Conducting comprehensive testing of both backend APIs and frontend interfaces to ensure functionality and usability.
Bug fixing: Identifying and fixing any bugs or issues found during testing.
Deployment: Preparing the platform for deployment using suitable hosting services for both backend (FastAPI) and frontend (React), and deploying the platform to a production environment.","Checkpoint 1: Face Detection Model Implementation
Checkpoint 2: Face Recognition Model Implementation
Checkpoint 3: Backend API Development with FastAPI
Checkpoint 4: Frontend Development with React
Checkpoint 5: Testing, Debugging, and Deployment",ML
115,Priyanshu Ranjan 22B0420,Image Classification,,Machine Learning,"This is an image classification project in which you have to apply the machine learning or deep learning algorithms and come out with the best model for classifying images. You will learn and get to implement various machine learning algorithms such as SVM, Random Forest and also neural networks such as ANN and CNN. Also, there need to be done a lot of data cleaning for which you also have to apply the image processing concepts. You will be learning wavelet transform, haar cascade algorithm and various object detection tools and the ways to implement them. Towards the end, you will be building a basic website where you can deploy your model. I am giving my GitHub link which contains my work somewhat similar to this: https://github.com/priyanshu7466/Python/blob/main/Political_Person_Classification.ipynb
 ",8,"CS101 and basic coding in Python(writing functions and classes, etc.)",projects/default.png,https://drive.google.com/drive/folders/1ea1ExT89wOV4aIuCQkj6iokpE75tAvtx?usp=sharing,"Week1:  Python libraries such as numpy, pandas, matplotlib
Week2: Logistic Regression, Support Vector Machines, Random Forest
Week3: Tensorflow, Neural Networks, implementing fully connected ANN
Week4: CNN, implementing CNN on sample dataset
Week5: Wavelet Transform, Image Thresholding, smoothening, RGB, HSI and Gray scale images, co-occurrence matrix
Week6: OpenCV, Haarcascade, Object detection
Week7: Apply all the learnings and come out with best model for image classification
Week8: Develop a basic website to launch the model made","Checkpoint 1 : Implementing SVM and Random Forest Classifier on a sample dataset
Checkpoint 2 : Implementing CNN on a sample dataset
Checkpoint 3 : Implementing image processing on a sample image. Applying haar cascade algorithm
Checkpoint 4 : Apply all the learnings and come up with the best model
Checkpoint 5 : Build a basic website to launch the model
",ML
116,Priyanshu Sivamurthy Gangavati 22B2165,From Simple to Smart: Sentiment Analysis with Traditional ML and a Peek at Deep Learning,Varad Vikas Patil (22B2270),Machine Learning,"Sentiment analysis is like figuring out if people feel happy, sad, angry, or just okay when they write something. It's important because it helps us understand what people think and feel when they share their thoughts online. We use it in different areas like keeping an eye on how people see brands, helping customers when they have questions or complaints, and even in finance to see how people's feelings and choices affect the stock market.

During this project, we'll cover all the important stuff in machine learning. We'll provide you with articles/blogs, videos, and Jupyter/Colab notebooks each week to help you learn. You'll also have weekly assignments (theory + code) to make sure you're learning. Don't worry, though—the assignments will be easy if you've gone through all the resources for that week. You can find more details in the weekly schedule.",15,"(Soft requisite: not compulsory) Basic syntax of Python, 
(Bonus but not a hard pre-requisite) familiarity with sci-kit learn library of Python ",projects/Sentiment_analysis_banner2.png,https://drive.google.com/file/d/1-eAcsZTyMWgBdekA1QMkuUDdesTbEZpc/view?usp=sharing,"Week 1: Getting started (code + theory): Python basic syntax, important terminologies used in machine learning/data science, introduction to NumPy and Jupyter/Colab notebooks

Week 2: Data pre-processing with Pandas (code + theory): handling numerical and categorical (string) values, handling null values, one hot encoding, normalization of data and its importance

Week 3: Exploratory Data Analysis (code) and activation functions (theory): Plotting graphs using Matplotlib and Seaborne, activation functions such as sigmoid, relu, softmax, tanh, etc.

Week 4: Algorithms part 1: Logistic Regression (code), Linear Regression (code), Gradient Descent (code) and other optimization algorithms (theory)

Week 5: Algorithms part 2: Support Vector Machines (code), KNN (K-nearest neighbors) (code), Naïve Bayes and Decision Trees (theory)

Week 6: Natural Language Processing (code + theory): Basics of NLP including tokenization, stemming, lemmatization, removal of stop words, etc. Exploring libraries like NLTK (Natural Language Toolkit) and SpaCy for NLP tasks.

Week 7: Deep Learning: Introduction to RNN (Recurring Neural Networks) (theory) and LSTM (Long Short-Term Memory) (code + theory)

Week 8: Working on final project (Sentiment Analysis using all the ML models discussed above and comparing it with LSTM) (code + report)","Checkpoint 1: Hands-on experience in loading and pre-processing various datasets using Pandas

Checkpoint 2: Plotting various types of graphs on different datasets using Matplotlib

Checkpoint 3: Using all the mentioned ML algorithms for one classification/regression task

Checkpoint 4: Implementing all the NLP pre-processing techniques on various texts

Checkpoint 5: Final project with report or README.md
",ML
117,Rahul Agarwal 22B3961,2048: Dive into the realms of reinforcement learning ,Manav Agrawal(22B1253),Machine Learning,"- Explore cutting-edge techniques in game-solving algorithms through the implementation of N-Tuple Networks in Python.
- Dedicated project focused on optimizing reinforcement learning methodologies for mastery of the game 2048.
- Utilize sophisticated methodologies including Temporal Difference Learning to refine N-Tuple Networks.
- Aim to enhance performance and efficacy in solving the intricate gameplay dynamics of 2048.
- Inviting enthusiasts and scholars to delve into this research endeavor, offering insights into the evolving landscape of artificial intelligence.",10-12,Basic programming mindset and a lot of enthusiasm,projects/default.png,https://drive.google.com/drive/folders/1Q1Zgsd9TmCE1laIP6P_XB_da6L0iiTzc,"Week 1: Introduction to Reinforcement Learning

Learn about the basics of reinforcement learning (RL) and its applications.
Understand the Markov Decision Process (MDP) framework.
Study fundamental RL algorithms such as Q-Learning and Temporal Difference (TD) Learning.

Week 2: Deep Reinforcement Learning

Dive deeper into deep reinforcement learning (DRL) concepts.
Study Deep Q-Networks (DQN) and its variants.
Implement basic RL algorithms using Python libraries like OpenAI Gym.

Week 3: Introduction to Game 2048

Understand the rules and mechanics of the game 2048.
Review existing strategies and AI approaches for playing 2048.

Week 4: N-Tuple Networks

Learn about N-Tuple Networks and their application in game playing.
Study the papers by Rodgers & Levine (2014) and Szubert & Jaśkowski (2014) on using N-Tuple Networks for 2048.
Implement basic N-Tuple Networks in Python.

Week 5: Advanced RL Techniques

Study advanced RL techniques such as Policy Gradient methods (e.g., REINFORCE).
Understand how these techniques can be applied to complex games like 2048.

Week 6: Multistage Temporal Difference Learning

Dive into the paper by Yeh et al. (2016) on Multistage Temporal Difference Learning for 2048-like games.
Implement multistage TD learning algorithms in Python.

Week 7: Advanced Techniques in 2048 AI

Study the paper by Jaśkowski (2017) on mastering 2048 with advanced techniques.
Implement and experiment with techniques such as delayed temporal coherence learning and redundant encoding.

Week 8: Project Implementation

Design and implement the N-Tuple Network-based agent for playing 2048.
Experiment with different configurations and hyperparameters.
Debug and optimize the agent's performance.
Build a basic website or UI to showcase your project and deploy the agent.","Checkpoint 1 - 
Setting of python environment and able to run simple scripts through programming in the first week.

Checkpoint 2- 
Implementation of basic level reinforcement learning through a simple rod balancing game.

Checkpoint 3-
Getting a grasp of N-tuple networks which will be used for the implementation of the project.

Checkpoint 4-
Implementation of N-tuple networks with a reinforcement model and build a self learning and high scoring 2048 code.

Checkpoint 5-
Making a decent interface for better visualization of the task so far.",ML
118,Rana Das 22B0738,Conversational AI Meets Object Detection: Building Smart Chatbots,Piyush Soni ,Large language model (LLM) + Computer Vision + WebDev,"Description:
In this project, mentees will embark on an immersive journey at the intersection of conversational AI and object detection technology. Through a hands-on approach, mentees will delve into the intricacies of building intelligent chatbots capable of recognizing and interacting with objects in real-time.
The learning environment will revolve around a comprehensive curriculum covering various aspects of software development and AI integration. Mentees will start by gaining a solid understanding of Linux, WSL, Git, and GitHub to establish a robust development workflow. They will then delve into the fundamentals of RASA, a powerful open-source conversational AI framework, to lay the groundwork for creating sophisticated chatbots.
The highlight of the project lies in the integration of object detection capabilities using the YOLO (You Only Look Once) algorithm. Mentees will explore how to gather data, train computer vision models, and leverage NVIDIA CUDA and PyTorch for accelerated processing. By combining the power of RASA and YOLO, mentees will learn to develop chatbots capable of interacting intelligently with their surroundings, opening up exciting possibilities for real-world applications.
Throughout the project, mentees will engage in hands-on activities, including creating custom actions using RASA action servers and implementing conversational interfaces with the RAG (Retrieval-Augmented Generation) framework. They will collaborate closely with mentors to troubleshoot challenges, exchange ideas, and refine their skills.
By the end of the project, mentees will emerge with a comprehensive understanding of building intelligent chatbots with object detection capabilities. They will have the skills and knowledge to tackle complex AI projects, empowering them to contribute meaningfully to the future of AI-driven technologies.",7-8,"Python Programming, Object Orientated Programming Basics Preferable. A lot of Enthusiasm and Dedication.",projects/default.png,https://drive.google.com/drive/folders/1PugEP9fOnp3YfyKMByzfhcTNrvzTjTjN,"Week 1: Introduction to Tools and Frameworks
- Introduction to Linux, WSL, Git, and GitHub
- Setup development environment
- Familiarization with RASA and YOLO frameworks

Week 2: Fundamentals of Conversational AI
- Understanding the basics of conversational AI
- Exploring RASA architecture and components
- Setting up a simple chatbot with RASA

Week 3: Advanced RASA Concepts
- Customizing chatbot behavior with intents, entities, and actions
- Implementing slot filling and forms
- Introduction to RAG framework for conversational retrieval

Week 4: Introduction to Object Detection with YOLO
- Understanding the YOLO algorithm and its applications
- Setting up YOLO environment with NVIDIA CUDA and PyTorch
- Data gathering and preprocessing for object detection

Week 5: Training Object Detection Models
- Training YOLO models on custom datasets
- Fine-tuning models for specific object detection tasks
- Evaluation and performance tuning of object detection models

Week 6: Integrating Object Detection with Chatbots
- Incorporating YOLO object detection into RASA chatbots
- Handling object recognition responses in conversational interfaces
- Testing and debugging integrated chatbot with object detection capabilities

Week 7: Custom Actions and Advanced Features
- Implementing custom actions in RASA for enhanced functionality
- Exploring advanced features such as multi-turn conversations and context handling
- Fine-tuning chatbot behavior based on user feedback

Week 8: Project Completion and Showcase
- Finalizing the integrated conversational chatbot with object detection capabilities
- Preparation for project showcase and presentation
- Reflecting on the learning journey and planning for future AI projects","1. Environment Setup and Familiarization (Week 1):
   - Checkpoint: Ensure all mentees have successfully set up their development environments with Linux, WSL, Git, and GitHub.
   - Review mentees' understanding of the basics of RASA and YOLO frameworks.

2. Chatbot Development Progress (Week 4):
   - Checkpoint: Evaluate mentees' progress in building a basic chatbot using RASA, including intents, entities, and actions.
   - Assess mentees' ability to integrate RAG framework for conversational retrieval.

3. Object Detection Training (Week 6):
   - Checkpoint: Review mentees' proficiency in training YOLO models on custom datasets and fine-tuning them for specific object detection tasks.
   - Evaluate the performance of mentees' object detection models and provide feedback for improvement.

4. Integration and Testing (Week 7):
   - Checkpoint: Assess mentees' success in integrating object detection capabilities into RASA chatbots.
   - Test the functionality of chatbots with integrated object detection and provide guidance on debugging and optimization.

5. Project Showcase Preparation (Week 8):
   - Checkpoint: Review mentees' progress in finalizing their integrated conversational chatbots with object detection capabilities.
   - Provide guidance on preparing for the project showcase and presentation, including refining demonstrations and articulating key learnings.",Others
119,Reet Singh Solanki 21d070054,Unity game development(2-D),"Siddhant Chourasia (210070085), Prankul Yadav (21d070050), Abhishek Soni(21d070006)",Game Development,"In this project, we will be teaching all aspects, including basic C# programming for Unity, Unity game engine basics, crafting a Flappy Bird game, and fundamental 2D character movement. Mentees can delve into resources like Udemy's ""Complete C# Unity Game Developer 2D"" by Ben Tristem, Brackeys' YouTube tutorials, Unity's official documentation, and GitHub repositories such as ""Unity-2D-Character-Controller"" under my guidance.
Link to basic game prototype:-
https://drive.google.com/file/d/1zxsXvqvat7rtsjdc4w1FIeZox211nKjc/view?usp=drive_link
(Download the zip and then you can play it by double-clicking 'Flappy bird 2.0').",5 to 7,,projects/GameDevUnity.jpg,https://drive.google.com/file/d/1Pv3_qFQyTTRYWmQTwPyBXLa476FXptPp/view?usp=sharing,"Week 1:

Task 1: Unity software installation
Task 2: Orientation and familiarization with the Unity interface

Week 2:

Task 3: Basic C# programming concepts introduction
Task 4: Implementing basic 2D character movement in Unity

Week 3:

Task 5: Deep dive into C# scripting for game development
Task 6: Enhancing 2D character movement with advanced features (e.g., jumping, animations)

Week 4:

Task 7: Introduction to Flappy Bird game mechanics and design principles
Task 8: Planning and prototyping Flappy Bird game in Unity

Week 5:

Task 9: Completing Flappy bird.

Week 6-8:

Task 10: Make any 2-D platformer game of your choice.","1. Unity software installed successfully, basic understanding of the Unity interface achieved.
2. Basic 2D character movement implemented in Unity.
3. Graphics, audio, and user interface elements integrated into the game.
4. Final version of Flappy Bird game completed and polished.
5. Build a 2-D platformer game of your choice.",Development
120,Ripan Kamila 22b0456,Bitcoin Price Prediction using Machine Learning,,Machine Learning,"Data Collection: The first step is to gather historical data on Bitcoin prices. This data typically includes factors like opening and closing prices, trading volume, market sentiment indicators, and possibly external factors like economic news or regulatory changes.

Data Preprocessing: Once the data is collected, it needs to be cleaned and preprocessed. This involves handling missing values, normalizing or scaling the data, and possibly transforming it into a format suitable for machine learning algorithms.

Feature Selection/Engineering: In this phase, relevant features are selected or engineered from the data. For Bitcoin price prediction, features could include technical indicators (e.g., moving averages, relative strength index), sentiment analysis of news articles or social media, and macroeconomic indicators (e.g., inflation rates, stock market performance).

Model Selection: Various machine learning models can be used for price prediction, such as linear regression, decision trees, random forests, support vector machines, or deep learning models like recurrent neural networks (RNNs) or long short-term memory (LSTM) networks. The choice of model depends on factors like the complexity of the data and the desired accuracy.

Training and Testing: The selected model is trained on historical data, where it learns patterns and relationships between features and Bitcoin prices. The model's performance is then evaluated using testing data to assess its predictive accuracy.

Hyperparameter Tuning: Machine learning models often have hyperparameters that need to be tuned to optimize performance. Techniques like grid search or random search can be used to find the best combination of hyperparameters.

Reading material from : simplilearn.com and geeks for geeks website",9-10,Basic Python programming skills,projects/default.png,https://drive.google.com/file/d/1wSBrrMflydNfXOOej0ogxzhJj1V8F3Kd/view?usp=drive_link,"Week 1: 	Introduction to Python and Python libraries, and Google Colab
Week 2-3:	Introduction to machine learning concepts, such as supervised and 
                       unsupervised learning, and training vs. testing data
Week 4-5:	Intro to EDA (an approach to analyzing the data using visual techniques)
Week 6:	       Implementing machine learning algorithms to train some state-of-the-art machine learning models(Logistic Regression, Support Vector Machine, XGBClassifier)
Week 7-8:	Final Project Completion and Documentation","Checkpoint 1: Introduction to Python libraries and Google colab(Assignment 1)
Checkpoint 2: Data interpretation using functions and methods(Assignment 2)
Checkpoint 3: Plotting necessary graphs and trends and also noticing peaks, variations (Assignment 3)
Checkpoint 4: Introduction to Regression and other system models(Assignment 4)
Checkpoint 5: Final modelling, simulation and documentation with all datasets (Assignment 5)",ML
121,Rishi Daga 22b3003,Fashion RecommendationSystem,"Mahek Hinhoriya (22b3031), Aditya Sancheti (22b3004)",Deep Learning,"Have you ever wondered how Google Lens magically identifies objects in your photos or how Myntra suggests similar fashion items based on your uploaded images? 
Dive into the world of image processing and learn to make useful project that has wide scaled implementation

The Fashion Recommender System aims to provide product recommendations to users based on their uploaded images of garments or shoes. Leveraging deep learning  techniques, the system learns to associate visual features from the user’s input with relevant items in its dataset. 

Certainly! In addition to coding and model implementation, we’ll also focus on deploying the system. Our goal is to make it accessible and usable for real-world scenarios.",11,"Python Libraries  - Numpy, Pandas. 
Basic Understanding of Machine Learning and Deep Learning is a plus point.
and LOTS OF Enthusiasm !!!",projects/default.png,https://drive.google.com/file/d/1JnD3NanplEWNm-YWWU2RD5Dza4AQ7UT_/view?usp=sharing,"Week 1: Introduction to pandas, numpy, matplotlib, and classification algorithms.
Week 2: Exploring Image Processing.
Week 3-4: Delving into Deep Learning.
Week 5: Developing a Mini Project.
Week 6-7: Understanding Transfer Learning and deployment techniques.
Week 8-9: Creating a Final Project.","
Checkpoint 1: Mastery of pandas, numpy, matplotlib, and basic classification algorithms.
Checkpoint 2: Proficiency in fundamental image processing techniques using OpenCV or PIL.
Checkpoint 3 Successful implementation and evaluation of deep learning models for image-related tasks.
Checkpoint 4: Completion of a mini project demonstrating integration of learned concepts.
Checkpoint 5: Understanding and application of transfer learning techniques and deployment strategies for deep learning models.",ML
122,Rishu Kuamr 22b2130,Parseffect: ParseCraft: Intelligent Resume Parsing Engine,"Ayush Jadia(22b0407), Vidyanand(22b2171)",Natural Language Processing,"https://kgptalkie.com/resume-and-cv-summarization/
https://www.youtube.com/watch?v=nVvhkVLh60o&list=PLc2rvfiptPSR3iwFp1VHVJFK4yAMo0wuF, https://www.youtube.com/watch?v=nVvhkVLh60o&list=PLc2rvfiptPSR3iwFp1VHVJFK4yAMo0wuF,
https://github.com/laxmimerit/CV-Parsing-using-Spacy-3?tab=readme-ov-file,",6,only enthusiasm,projects/Designer.png,https://drive.google.com/file/d/1APlu0xPYgO6MFr7FRzrii5XWv0QB2DgD/view?usp=sharing,"Week 1: Introduction to Python and Basics of NLP
     Task: Intro to Python
               Introduction to Natural Language Processing (NLP).
               Understand the basic concepts of NLP, such as tokenization, named entity 
                recognition (NER), and text preprocessing.
        
Week 2: Setting Up Development Environment and Data Collection

    Task: Install necessary Python libraries like spaCy and PyMuPDF and master them.
              Collect sample resumes for training data.
Week 3: Data Preprocessing and Annotation

    Task: Understand the structure of the resume data.
              Preprocess the text data (e.g., remove unnecessary characters, normalize text).
              Annotate the training data for named entity recognition (NER) using spaCy.
Week 4: Building and Training the NER Model

    Task: Learn about spaCy's NER model and its components.
              Build a basic NER model using spaCy.
              Train the NER model on the annotated training data.
              Evaluate the trained model's performance.
Week 5: Model Optimization and Debugging

    Task: Optimize the NER model's hyperparameters (e.g., dropout rate, learning rate).
              Debug any issues encountered during training (e.g., handling exceptions, improving 
              model performance).
Week 6: Saving and Loading the Trained Model

    Task: Save the trained NER model to disk for future use.
              Learn how to load the saved model back into memory.
              Test the loaded model to ensure it performs as expected.
Week 7: Evaluation and Refinement

    Task: Evaluate model performance using a small set of diverse resumes or text samples.
              Identify errors and challenges by reviewing false positives and false negatives.
              Make minor adjustments to the model or data based on evaluation findings.
              Document evaluation results, refinements, and recommendations in a brief reports.
Week 8: Documentation and Finalization

    Task: Document the project, including its purpose, architecture, and usage instructions.
              Clean up the codebase and ensure it follows best practices.
              Finalize the project and prepare for deployment or further iterations.
    ","Checkpoint 1: Setting Up Development Environment and Data Collection
Checkpoint 2: Data Preprocessing and Annotation
Checkpoint 3: Building and Training the NER Model
Checkpoint 4: Model Optimization and Debugging. 
Checkpoint 5: Final report making, Saving, and Loading the Trained Model",ML
123,Rochan Prasad 22b2248,Finite Element Analysis for Simulations using Machine Learning ,,Machine Learning,"Computational cost of Finite Element Analysis(FEA) methods can become very high in certain cases, and using a ML or Deep Learning based regressor instead is a better approach. Understanding basic FEA and its implementation in simulation softwares, Python/MATLAB visualisation of meshes, as well as executing ML algorithms to replace FEA are some of the key learning features of the project, with a steep learning curve. Suggested reading: a) For FEA intro - https://www.simscale.com/docs/simwiki/fea-finite-element-analysis/what-is-fea-finite-element-analysis/ , b) Intro for ML in FEA-  https://www.mdpi.com/1424-8220/21/5/1654 c) Detailed thesis for FEA with ML - https://odr.chalmers.se/server/api/core/bitstreams/41315085-60ab-4e39-8ccc-6e1bc9040914/content",5,"Pre-requisites- Decent experience in ML, DS or Deep Learning; Good-to-have skills- Background in Mechanical Engg, Background in FEM, experience in simulation softwares such as ANSYS or COMSOL, comfortable with PDEs",projects/SOC.jpeg,https://drive.google.com/file/d/1oSF3nZb9ivK0ACrkjIJ7CjzV1D6uDeA0/view?usp=sharing,"Week 1-2: Learn about Finite Element Analysis, ML algorithms, Deep Learning, Week 3-4: Implement FEM in code in Python/Matlab, Week 5-6: Analyse simulation software mesh and plot it in Python/Matlab, Week 7-8: Propose and implement a suitable ML or Deep Learning Algorithm for FEM for a physical problem of your choice","Checkpoint 1- Report of concepts understood in FEA, Deep Learning; Checkpoint 2: FEA concepts implemented in Python/Matlab, Checkpoint 3: Plot of mesh in Python/Matlab, Checkpoint 4: Report of proposed ML algorithm and proposed physical problem to solve, Checkpoint 5: Final presentation with code of FEA using ML for physical problem",ML
124,Rohit Sinha 22b2417 ,Backtester Engine and Optimizer,Apoorva Ansh(22b2407),Machine Learning,"This project aims to develop a trading strategy analysis tool that backtests Moving Average Crossover and Dynamic Support-Resistance strategies. The focus will be particularly to create a ""Shrinking EMA difference with enlarging volume confluence"" strategy. It implements machine learning algorithms (KNN, SVM, Regression) for strategy optimization. Finally, it also aims to outperform indices and calculation of Sharpe ratio after implementation. 

Some resources:
https://www.investopedia.com/terms/c/crossover.asp 
https://www.ibm.com/topics/knn https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-completeguide-for-beginners/ https://www.investopedia.com/articles/07/sharpe_ratio.asp https://www.tradingview.com/pine-script-docs/en/v5/concepts/Libraries.html",7-8,Prerequisite: An interest in financial markets and a good grasp of ML,projects/default.png,https://drive.google.com/file/d/1O5RzklWIEm9PF7ZlzxqFMCADdjduHgxc/view?usp=drivesdk,"Week 1 Learning about trading indicators(MA, Volume, S&R)
Week 2 Working with Pine-Script Libraries
Week 3 Brushing up ML concepts
Week 4 Implementation of Strategy mentioned
Week 5 Optimization using ML models and backtesting on various TimeFrames
Week 6 Learning about Sharpe and Treynor ratios
Week 7 Calculation of Sharpe and tweakings to improvise Strategy
Week 8 Finalising the strategy with plotting PnL","Checkpoint-1 PineScript coding 
Checkpoint-2 Implementation of Strategy on TradingView 
Checkpoint-3 Optimization after fetching trades data(generated by signals) Checkpoint-4 Calculation of Sharpe Checkpoint-5 PnL plotting on various Time frames and Indices",ML
125,Rutvik Rathva 22B4509,MysticGPT,"Jaydip Damor (22b4221), Tanmay Mandaliya (22b1037), Rushi Chavda (20D100007)",Natural Language Processing,"Your primary benefit from this initiative is a verified summer internship with BAPS, an international organization (more info baps.org). For this organization, we are developing an end-to-end production-level conversational chatbot employing passages from Indian mythology (mythology knowledge is not required). We are trying to solve a significant issue for someone who is interested in mythological exploration, But for a novice, it might be challenging to navigate through mythical writings. Our chatbot is intended to serve as a bridge for the ideals of Indian civilization, encompassing aspects such as philosophy, spirituality, mythology, morals, character, values etc. for the younger generation. To create the chatbot, we will use open source English content that has been carefully selected. You should be very curious to learn and explore Web-scrapping, RAG, RAGAS, Langchain, LLM architectures, Fine-tuning LLMs, Evaluating LLMs, LLMOps etc.
",10-12,"Prerequisite: Basics of Python, Eagerness to learn is a must",projects/default.png,https://drive.google.com/file/d/1RzvsbSTUnlv0MvRb9B9qvJqA6upJowMU/view,"Week 1 - Reading material
Week 2 - Plan of action
Week 3,4 - Web scraping and data collection
Week 5,6,7 - End-to-end coding of chatbot
Week 8,9 - Integration with user Interface (UI)","Checkpoint-1: Specific Research and Learning
Checkpoint-2: Data Collection
Checkpoint-3: Backend Code Development
Checkpoint-4: UI Generation
Checkpoint-5: Frontend Backend Integration",ML
126,Sahiti Koya 210260028,Learn Data Structures and Algorithms,"Madhuri, Amruta deo, Srushti Kendre",DSA,Aim of this is to learn data structures and algorithms in a structured manner,10-15,Enthusiasm,projects/default.png,https://drive.google.com/file/d/1jChiWqV8rluyleXCP1ghbEmQrKpwiofz/view?usp=sharing,"Week 1: Arrays, two pointers, Sliding window
Week 2:Stack and Binary search
Week 3:Linked List
Week 4: Revision and Midterm submission of Excel sheet of names of all problems you solved and main logic used in each of them in one line
Week 5:Trees
Week 6:Heap/Priority Queue,Backtracking 
Week 7 and 8: Graphs and Advanced Graphs
Week 9 and 10: DP
Week 11: Greedy, Intervals
Week 12: Revision and Final submission of Excel sheet of names of all problems you solved and main logic used in each of them in one line","1: problems until and including linked list
2: problems until and including Trees
3: problems until and including Graphs
4: problems until and including DP
5: completing all the 150 problems",Others
127,Sai Charitha Janapati  22B0999 ,Memory Game using HTML.,Pavan Sekhar Naidu Routhu(22B1028),Web Development,"The Memory Game is an interactive web-based game designed to test and enhance players’ memory skills. The game board consists of an n x n grid (where n represents the number of rows and columns) filled with hidden emojis. Players can click on any two tiles to reveal the emojis underneath. If the revealed emojis match, they remain face-up; otherwise, they flip back down. The game features randomized emojis, responsive design, and a winning condition of matching all pairs within the fewest possible moves. The technologies used include HTML, CSS, and JavaScript. Players can customize the game by adding features like a timer, difficulty levels, and high scores. Whether you’re a beginner or an intermediate developer, building the Emoji Memory Game is a fun way to practice front-end web development skills and create an engaging user experience! Optional additional features include implementing a countdown timer for added challenge, providing options for players to choose between different grid sizes or emoji sets to adjust difficulty levels, incorporating a high score system to track players' achievements, and adding sound effects to enhance the gaming experience.",8 - 10,None,projects/default.png,https://drive.google.com/file/d/1j-761o5zwiH46QtR_vl21a77x8z2gVXH/view?usp=drivesdk,"Week 1-2: Learning Basic HTML/CSS 
- Introduction to HTML structure and elements
- Basic CSS styling and layout techniques
- Understanding of semantic HTML and CSS selectors

Week 3-4: Learning Basic JavaScript Syntax 
- Introduction to JavaScript variables, data types, and operators
- Control flow: conditional statements and loops
- Basic functions and event handling in JavaScript

Week 5-6: Project Setup with HTML/CSS 
- Implementing the frontend structure for the emoji memory game using HTML
- Styling the game interface using CSS to enhance user experience
- Responsive design principles to ensure compatibility across devices

Week 7-8: Backend Implementation and Logic 
- Introduction to backend development with JavaScript (Node.js)
- Setting up server-side logic for the memory game
- Incorporating extensions like multiplayer functionality or scoring system","Checkpoint 1: Assessing HTML/CSS Proficiency (Weeks 1-2) via creating a basic website (view only).
Checkpoint 2: Evaluating JavaScript Basics (Weeks 3-4) by developing a basic functional website.
Checkpoint 3: Verifying Memory Game Layout and Basic Functionality (Weeks 5-6) by assessing the implementation of the game interface and core features.
Checkpoint 4: Testing Backend Integration and Advanced Features (Week 7) through examining the incorporation of server-side logic and additional functionalities.
Checkpoint 5: Assessing User Experience and Accessibility (Week 8) by evaluating overall usability and inclusivity measures implemented in the game.",Development
128,Saksham Rathi 22B1003,Conquering Competitve Programming,"Anirudh Garg (22B1005), Utkarsh Pant(22B0914)",Competitive Programming,"If you're feeling unsure about where to start and how to enhance your skills in Competitive Programming, we're here to assist you! We provide a comprehensive guide to Competitive Programming concepts, Data Structures, and Algorithms, along with sharing our experiences, strategies, and shortcuts to help accelerate your progress. Competitive Programming bears resemblance to tackling challenging JEE questions, with the added pressure of time constraints. If you enjoyed grappling with tricky problems and devising novel solutions during your JEE preparation, this might be the perfect endeavor for you! This program will demand significant effort from your end as our objective is not as straightforward as it may appear and requires continuous self-improvement. Mastery in CP is achievable only through consistent practice. Quick problem-solving and implementation skills come after numerous attempts, so don't be discouraged if it takes time to find your rhythm. We plan to cover a wide range of topics with numerous questions on each, so it might be demanding. Best of luck!


Resources to be followed:
1. Introduction to Algorithms, third edition, Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, Clifford Stein
2.  J. Kleinberg and E. Tardos, Algorithm Design, Addison Wesley, 2005
3. Guide to Competitive Programming ~ Springer
4. Competitive Programmer’s Handbook by Antti Laaksonen
5. CSES Problem Set",10,"1. Basics of C++.
2. High Enthusiasm",projects/default.png,https://drive.google.com/file/d/1pSqyLGxsnx4Gl1Bz2pm1G9ehACKHMjBQ/view,"Week 1: C++ Review and CP Introduction. Practice solving basic programming exercises involving vectors and arrays. Overview of Big O notation and its role in representing time and space complexities.

Week 2: Exploring Various Data Structures like stacks, queues, sets, maps, unordered_sets, pairs, heaps, and their methods. Introduction and review of fundamental algorithms such as binary search, insertion sort, merge sort, quick sort, etc. Introduction to bit operations and their efficient application.

Week 3: Delving into Greedy and Dynamic Programming paradigms and learning how to recognize situations where they apply. Solving a range of basic and advanced problems based on these concepts.

Week 4: Introduction to Elementary Number Theory. Tackling problems related to exponentiation, divisors, primes, Fibonacci numbers, and probability.

Week 5: Introduction to Graph Theory. Covering fundamental concepts and techniques such as bfs and dfs graph traversal algorithms. Introduction to Trees and understanding how graph techniques can be applied to trees. Implementation of algorithms like Dijkstra, Bellman Ford, and others.

Week 6: Introduction to Directed Acyclic Graphs and Minimum Spanning Trees. Implementing algorithms like Kruskal's, Prim's, and Kosaraju's.

Week 7: Exploring string algorithms, trie structures, and suffix arrays. Implementing Z and KMP algorithms.

Week 8: Focus on problem-solving and reviewing previous concepts. Addressing mentees' weaknesses and encouraging them to explore editorials and examine others' code to enhance their skills.","Checkpoint-1: Learning all the important data structures mentioned.

Checkpoint-2: Greedy-DP

Checkpoint-3: Number Theory and Graph Theory

Checkpoint-4: Advanced Graph and String Agorithms

Checkpoint-5: Problem Solving and Revision of all concepts",CP
129,Sakshi Shinde 210110102,IntelliExtract: Dynamic PDF Table Parsing Using OCR and LLMs,Akash Banger: 210010007,Deep Learning,"IntelliExtract aims to revolutionize how we interact with unstructured data in PDF documents by leveraging Optical Character Recognition (OCR) technology, dynamic programming, and the capabilities of Large Language Models (LLMs) to accurately parse and convert table data into a structured CSV format. 

This project will involve:
Utilizing OCR to detect text and its spatial organization within a PDF.
Innovatively arranging detected text into a text grid that mirrors the table's layout.
Employing LLMs to interpret the grid, generate a CSV output, and correct any OCR-induced errors.
Crafting a robust pipeline that integrates these components into a workflow.

Learning and Reading Material:
OCR and EasyOCR: Familiarise with OCR technology and specifically EasyOCR documentation (https://pypi.org/project/easyocr/)
Dynamic Programming: Refresh knowledge on dynamic programming, focusing on applications in text and image processing (https://www.geeksforgeeks.org/dynamic-programming/)
LLMs for Data Structuring: Explore OpenAI's documentation on GPT models, focusing on text understanding and generation.(https://platform.openai.com/docs/introduction)",5,"Prerequisites:
Basic understanding of Python programming.
Familiarity with OCR technology and machine learning concepts.
No specific prior experience in dynamic programming or LLMs is required, but a willingness to learn is essential.

Expectations and Good-to-Have Skills
Strong analytical and problem-solving skills.
Experience with Python libraries like pandas, NumPy, and PyTorch or TensorFlow.
Basic knowledge of LaTeX or markdown formatting is a plus, for understanding text arrangement.",projects/default.png,https://drive.google.com/file/d/1jZjCs22e5mpwjMRchVcHRYxTn2wxE8mB/view,"Week 1-2: Foundation and Setup
Setup development environment.
Introduction to OCR with EasyOCR.
Initial trials of text extraction from PDFs.
Week 3-4: Text Grid Arrangement
Explore and implement dynamic programming techniques for arranging OCR text into a grid.
Develop algorithms for text alignment and spacing adjustments.
Week 5-6: Integration with LLM
Introduction to LLMs and prompt engineering.
Develop the interface between the text grid and LLM for CSV generation and error correction.
Week 7: Refinement and Testing
Optimize algorithms for efficiency.
Extensive testing with diverse PDF documents to refine the process.
Week 8: Final Integration and Documentation
Ensure the operation of the pipeline.
Document the project, code, and usage instructions.","Checkpoint 1: Successful extraction of text and bounding boxes from PDFs using OCR.
Checkpoint 2: Implementation of dynamic programming for accurate text grid arrangement.
Checkpoint 3: Initial integration with LLM for generating CSV from the text grid.
Checkpoint 4: Optimization and error correction enhancements.
Checkpoint 5: Complete system integration, testing, and documentation",ML
130,Samridhi Sahay 22B3935,VoxElectra: ML-Powered Speech Recognition for Electrical Control,"Virti R. Mehta, 22B3949",Machine Learning,"About the project:
""VoxElectra: ML-Powered Speech Recognition for Electrical Control"" is a project focused on making computers understand human speech better. We're teaching computers to recognize spoken words and turn them into text using advanced learning techniques and classify them into the desired action.
Vision/ Goal:
Harnessing the capabilities of machine learning, the project endeavors to create systems that can accurately interpret and transcribe spoken language into text format which would be used to give commands to electronic devices thus automating the household appliances.
Implementation:
Implementation:
1) Tensor flow, librosa libraries
2)Mel-frequency cepstral coefficients (MFCC)- speech recognition technique
3) CNN, RNN
4) Evaluation metrics and transfer learning.

https://www.researchgate.net/publication/358570577_speech_recognition_using_machine_lerning - (speech recognition, classification and accuracy improvement)
https://www.simplilearn.com/tutorials/python-tutorial/speech-recognition-in-python -(python methods)
https://github.com/pannous/tensorflow-speech-recognition?tab=readme-ov-file ",8,"python (soft-pre requisite)
enthu",projects/soc1.jpeg,https://drive.google.com/file/d/1sErQqcmlLRdRFoba2AVN0W61QLNlfiKM/view?usp=sharing,"Learning phase:
Week1-2: Classification and Neural Networks (CNN and RNN)
Week 3: Tensor flow library and applications. Getting started with librosa
Project Begins:
Week 4: Speech Data Preprocessing and Feature extraction
Week 5: Applying the neural network model on preprocessed data 
Week 6: Training and Testing of neural networks
Week 7: Evaluation metrics improvement and debugging
Week 8: Implementation for electrical control of appliances/devices ","Checkpoint-1: Assignment based on basic CNN and RNN application at the end of week 2
Checkpoint-2: Submission of outcomes of preprocessed speech data  at the end of week 4
Checkpoint-3: Submission of Neural networks implementation on preprocessed data at the end of week 5 
Checkpoint-4: Accuracy and precision of the model at the end of week 7
Checkpoint-5: Final implementation results of electrical control",ML
131,Sanskar Shaurya 22B0985,Competitive Programming (CP),"Jaladhi Joshi(22B0994), Arnav Garg(22B1021)",Competitive Programming,"The project will involve starting from the basics of CP which will first start by introducing the mentees to STL. We will follow the CSES handbook as a reference for the project, accompanied by the CSES problem set (https://cses.fi/problemset/list/), the leetcode 75 (https://leetcode.com/studyplan/leetcode-75/) and A2OJ ladders (https://earthshakira.github.io/a2oj-clientside/server/Ladders.html) which includes various codeforces problems sorted on the basis of difficulty. We will use the book ""Algorithm Design"" by Jon Kleinberg and Éva Tardos as a reading resource for some of the algorithms that we will cover in the project.",8,Basic grasp on any programming language ,projects/CP.png,https://drive.google.com/file/d/1TtCBj8jokUUKCPGKFy7gFrH_zWQj5EZN/view?usp=sharing,"Week 1 - Allow the mentees to get familiar with the C++ STL data structures and algorithms and help them in creating their own CP templates
Week 2 - Introduce Sorting and Searching problems with various ideas such as sliding window, two pointer method, meet in the middle, basic bit operations, etc. by the end of the week.
Week 3 - Introduce the concept of Divide-Conquer and Greedy Paradigms
Week 4 - Introduce the concept of Dynamic Programming
Week 5 - Introduce the idea of Graphs and touch upon basic graph concepts (dfs, bfs, graph representation) 
Week 6 - Move on to tougher problems in Graphs, implementation of Djikstra's Algorithm, Network-Flows
Week 7 - Introduce the idea of Segment Trees, Fenwick Trees","Checkpoint-1 : Introductory Problems in CSES
Checkpoint-2 : Sorting and Searching in CSES
Checkpoint-3 : Dynamic Programming in CSES
Checkpoint-4 : Tree and Graph Alogrithms in CSES
Checkpoint-5 : Some other Problems from CSES, Leetcode 75",CP
132,Santhosh Kumar M 23D0369,Price Prediction and Farm Health Analysis,,Machine Learning,"You would be involved in solving real-life challenges faced by farmers. As apart of this project, we are looking leveraging AI to make make farmers life better. You would understand how to predict the health of crops, look at seasonal impact and other aspects that influence ",2,"Basic understanding of prediction algorithm is good to have, python knowledge would be good to have.",projects/default.png,https://drive.google.com/file/d/1j_An0pu3p51-upxQi7H8Y_3MKG6cbX9a/view?usp=sharing,"week 1 & 2 - An API expecting sending payload as: type of asset,location and time frame as(1 day, 3 days, 1 week etc) and expect json output with the cost for that duration in future and suggestive forecast( for the next few days, weeks etc based on passed time frame)
week 3 & 4 - An API passing payload as : Asset Type, and duration, where expected response is json with cost comparision of similar types of assets
week 5 & 6 - An API with payload of asset type and it shall send back the response with the consumption units and its affect on cost in future
week 7 & 8 -An API suggesting alternative for similar type of assets at lower cost (Analogy with medicine, where same salt medicine of different is also used when a particular medicine is not available)","1- Price prediction of any assets(Vegetables, physical mobile assets e.g. Tractor, generators, water pumps etc) based on geography(district/tehsil as least granular level), any number of external factors(weather, geo political tension, import export duties etc)
2- Price prediction of above assets based on their geographical presence and their cost comparison of similar assets over a period time(next day to be the least granular level)
3- Prediction of resources consumption and their affect on cost in future
4- Alternative suggestions for similar type of assets to use for cheaper prices",ML
133,Santhosh Kumar M 23d0369,Safe and Secure Drone management system,None,App Development,"As part of this project, we would be enhancing ""MissionPlanner"" project (https://github.com/m-santh/MissionPlanner) to make it safe and secure.  As part of this, we would be using private and public key mechanism to secure drone firmware's so that only authroized ground control stations can be control the drone systems.
As part of this project, you will learn about drone ground control system and drone firmware.  You would develop embedded engineering skills as part of this project as you would start from installation of drone bootloader, drone firmware and you would develop a ground station control mobile application and windows desktop application to control drone actions.",2,It would be good if you know C# programming language. It would be good to have knowledge of development Windows desktop application. It would be good if you know how to develop windows application using Windows's forms. Some basic exposure to asymmetric encryption and decryption would be good to have.,projects/default.png,https://drive.google.com/file/d/1TsMW41Rco_E7YMtumnwZ9rEjIO_EEwMC/view?usp=sharing,"Week 1 - Basic understanding of Ardupilot project and drone systems
Week 2 - Understanding of Mission Planner project
Week 3 - Understanding of securing drone firmware and security keys (simple programs)
Week 4 & 5 - Modifications of Mission Planner application to make drone firmware secure
Week 6 - Modification of Ardupilot project to enable secure handshake with mission planner application
Week 7 & 8 - Integration and end-to-end system testing","1. Secure drone bootloader and firmware upgrade
2. Secure handshake between drone and ground station control
3. Drone identify verification and validation
4. Drone security reset and recover mechanism.
5. Drone activity management in secure mode.",Development
134,Santhosh Kumarm 23D0369,GPS denied Drone Navigation,,Embedded Programing,"Every Drone has magnetometer, altimeter, accelerometer sensor. In underground tunnels, it is difficult to get GPS signals, so the proposal is to use these sensor to convert coordinate systems from GPS coordinates to Drone reference coordinate systems.  The project would involve 3 major tasks. First is to get inputs from sensors and generate reference coordinate systems. Second is to convert GPS coordinate system to reference coordinate system, and third task is to convert reference coordinate system to GPS coordinate system. We would be testing our solution on Mobile device (Android) as most of these sensors are also available in mobile phones.

To start working on this project, you need to brush up your maths algorithms like Kalman filters or complementary filters so that you are able to combine sensor data and estimate the drone's position, velocity, and orientation accurately. Have a basic understanding of GPS navigation coordinate system. You can also learn KML file format which is used to store navigational paths. This is the formal used by your google maps application. Learn basic android programming (especially accessing sensor data).",2,"To work on this project, you should have strong mathematical background. You only need basic programming knowledge. Mobile (Android) application knowledge would be good to know.",projects/default.png,https://drive.google.com/file/d/1cR75b1pe_C1vy03lPCBVokvyQ-dHdho-/view?usp=sharing,"week 1 - Understanding GPS navigation system
week 2 - Understanding navigation systems
week 3 - Understanding and developing first Android mobile application and capture sensor data.
week 4 - Creating coordinate reference system from sensor data
week 5 - Plotting navigational path in reference coordinate system
week 6 - Developing an application to capture GPS coordinate path and translate KML files
week 7 - Developing an algorithm to convert GPS coordinate to reference coordinate and visa versa.
week 8 - Display of data in 3D plane and integrating the components into single application.","1. Reference coordinate path capture
2. GPS coordinate path capture and translation of KML files into GPS coordinate system.
3. Translation between GPS and reference coordinate system
4. Plotting GPS and reference coordinate navigation path in 3D plane
5. Improving accuracy of reference coordinate paths.",Others
135,Sarthak Niranjan 22B3923,RegalRooms.com: Build Your Own MERN-Powered Hotel Booking Website from SCRATCH,No co-mentor.,Web Development,"We will be building a fully functional full-stack hotel booking website using the MERN stack. 
This will include features like date selection, location filtering, location previews, and also robust backend logic that will make sure no two parties can ever book the same room. 
We will understand the process of password generation, storage of user credentials, and security features like password-hashing, error handling, and fundamental React concepts like states, virtual DOM, component tree, props, and of course, responsiveness across all devices.
The project will expose the mentees to the latest technologies used in the industry as well as provide them with hands-on experience on how a real-life product is ideated, refined, built, and put into action.
If you're targeting software roles, or just want to get your hands dirty with code, hop on!
A GitHub repo of an existing similar project: https://github.com/safak/youtube2022/tree/mern-booking",5,"Basics of HTML, CSS, JS are a must. Any experience with MERN stack or any other equivalent would be a bonus!",projects/original-e88119446c2dfaa205e754887a9c53e7.png,https://drive.google.com/file/d/1-FjxWR58iC7H5h40Hw3MKBrHGtq8Lazl/view?usp=sharing,"Week1: Understanding what we're building and going through the basics of HTML, CSS and JS
Week2: Learning React by doing a mini project.
Week3: Begin work on the frontend
Week4: Finish frontend 
Week5: Understanding the backend tech and database
Week6: Writing the backend APIs, testing them and adding security features
Week7: Frontend and Backend integration
Week8: Deploying project on Vercel, and fixing any bugs that remain","1. Understanding React and Building the Front-end
2. Understanding Node.js + Express and Building the APIs
3. Understanding MongoDB and connecting it with the backend
4. Frontend and Backend integration and bug testing
5. Deployment of the project on the internet.",Development
136,Sarvesh Kumar 22b0736,WebCraft: From Basics to Mastery,Shrikant Dighole(22b2244),Web Development,"Embark on a journey of web development mastery with ""WebCraft."" This comprehensive project-based mentoring program is designed to take aspiring developers from the fundamental building blocks of HTML, CSS, and JavaScript to the dynamic world of React.

Throughout the program, participants will engage in hands-on learning experiences, guided by experienced mentors, as they progress through weekly checkpoints tailored to each subject area. In the first week, students will dive into the structure and semantics of HTML, followed by a deep dive into the styling prowess of CSS in the second week. The third and fourth weeks will be dedicated to mastering the powerful functionalities of JavaScript, enabling students to create interactive and dynamic web applications.

The final phase of ""WebCraft"" will focus on React, a cutting-edge JavaScript library for building user interfaces. Over two weeks, participants will delve into the core concepts of React, including components, state management, and routing, culminating in the development of a fully-functional project.

As the culmination of their journey, students will apply their newfound skills in a one-week final project, where they will have the opportunity to showcase their creativity and technical proficiency by building a real-world web application using React.",6-8,,projects/default.png,https://drive.google.com/drive/folders/1ldFg9XOGQP-soJYbgkcLqBaL71TentJZ?usp=sharing,"Week 1: HTML Basics
- Learn HTML structure and elements
- Create a simple webpage using HTML

Week 2: CSS Fundamentals
- Explore CSS styling and selectors
- Style the HTML webpage using CSS

Week 3: JavaScript Essentials
- Understand JavaScript fundamentals
- Add interactive elements to the webpage

Week 4: Advanced JavaScript
- Dive into DOM manipulation and events
- Implement complex interactions on the webpage

Week 5-6: React Fundamentals
- Learn React components, props, and state
- Build a basic React application

Week 7-8: Advanced React Development
- Explore React Hooks and context API
- Enhance the React application with advanced features

Week 9: Final Project Week
- Apply all concepts to develop a complete web application
- Prepare and present the final project","Checkpoint-1: HTML Mastery
Checkpoint-2: CSS Styling
Checkpoint-3: Javascript Interactivity
Checkpoint-4: React Application Development
Checkpoint-5: Final Project",Development
137,Sathwik Shetty 22b2209,When 'LLM' meets 'Web-Dev'!,"Ashwani Dubey(22b3024), Amit Tiwari(22b3006)",Natural Language Processing,"Customizing GPT with Different LLMs: Diving deep into understanding the architecture and capabilities of different LLMs such as GPT, BERT, and RoBERTa. It's fascinating to explore how these models are trained, their strengths and weaknesses, and how they can be fine-tuned for specific tasks or domains.

Integrating NLP Techniques: Beyond just leveraging pre-trained LLMs, incorporating additional NLP techniques like Named Entity Recognition (NER), sentiment analysis, and summarization. Understanding how these techniques work and how they can augment the capabilities of our model is crucial for our project's success.

Deployment with React Frontend: Once our customized model is ready, the focus will shift to deploying it in a user-friendly manner. Integrating it with a React frontend will offer users a seamless way to interact with the model through a web interface, enhancing accessibility and usability.

Learning Resources:

Tutorials and Documentation: The documentation provided by Hugging Face's Transformers library invaluable for leveraging pre-trained language models and fine-tuning them for our specific needs. Additionally, I refer to TensorFlow and PyTorch official documentation for implementing NLP techniques and building models from scratch.

Research Papers: Keep up with the latest advancements in NLP by reading papers from conferences like ACL, NeurIPS, and EMNLP. These papers offer valuable insights into cutting-edge techniques and approaches in the field.",11,"Python skills
Basic web development skills
A general understanding of machine learning will be appreciated.
And most important a lot of enthusiasm to learn ",projects/default.png,https://drive.google.com/file/d/1CTwRbOjmOkzUgo-QF42WMSjPiXhzXB6d/view?usp=sharing,"Week 1-2 (May 6th - May 19th):

Python basics: Variables, data types, control structures, and functions.
ML basics: Supervised and unsupervised learning, regression, and classification.
Deep learning basics: Neural networks, activation functions, and basic architectures.

Week 3-4 (May 20th - June 2nd):

NLP fundamentals: Word embeddings, sequence modeling, and language models.
LLMs exploration: GPT, BERT, and RoBERTa architecture and applications.
Initial planning for the final project.

Week 5-6 (June 3rd - June 16th):

Advanced NLP techniques: Named Entity Recognition (NER), sentiment analysis, and text summarization.
Fine-tuning LLMs: Customization for specific tasks or domains.
Designing the integration of NLP techniques with LLMs.

Week 7-8 (June 17th - June 30th):

Implementation of integrated system.
Testing, validation, and optimization.
Documentation preparation and final project submission.

Week 9-10 (July 1st - July 10th):

Finalizing React.js frontend.
Conducting extensive testing and debugging.
Submitting the final project by July 15th deadline.","Checkpoint-1: Research and Selection of Language Models

Explore different LLMs such as GPT, BERT, RoBERTa, etc. Evaluate their architectures, strengths, and weaknesses. Select the most suitable LLMs for the project based on requirements.

Checkpoint-2: Fine-tuning and Customization of LLMs

Fine-tune the selected LLMs for specific tasks or domains. Experiment with different hyperparameters and training techniques. Validate the performance of customized LLMs through thorough evaluation.

Checkpoint-3: Integration of NLP Techniques

Incorporate additional NLP techniques such as Named Entity Recognition (NER), sentiment analysis, summarization, etc. Implement these techniques in conjunction with the customized LLMs. Ensure seamless integration and compatibility between different NLP components.

Checkpoint-4: Development of React Frontend

Design and develop a user-friendly React frontend for interacting with the customized language models. Implement features for inputting text, displaying model predictions, and handling user interactions. Ensure responsiveness, accessibility, and aesthetic appeal of the frontend interface.

Checkpoint-5: Deployment and Testing

Deploy the entire system, including customized LLMs and React frontend, to a production environment. Conduct extensive testing to ensure the functionality, performance, and reliability of the deployed system. Gather feedback from users and stakeholders, and iterate on the system based on their input.
",ML
138,Satvik Jain 22b0635 ,Image captioning,,Machine Learning,"The project seeks to replicate the functionality of the human brain in recognizing images and generating corresponding captions. We will be employing pretrained CNN models along with Long Short-Term Memory (LSTM) and Natural Language Processing (NLP) techniques.
We will be exploiting famous datasets like MNIST, CIFAR 10 etc.",5,Python Basics. Familiarity with ML is a bonus.,projects/SOC Project.png,https://drive.google.com/file/d/1Xnr-FvIDl6HaOep52f_pBqdtdFTyt3Oq/view?usp=sharing,"Week 1	        Python and Jupyter Basics
Week 2-3	Basics of ML and Learning Numpy, Pandas, Data Visualization, Sklearn
Week 4	        Learning fundamentals of ANN and CNN
Week 4-5	Diving into Pytorch and torchvision
Week 6-8  	Going through LTSM and Diving into Model Development","Checkpoint-1: Getting to know about important libraries required for ML
Checkpoint-2: Knowing about basic ML algorithms like Linear and Logistic Regression
Checkpoint-3: Diving into Neural and Conv Nets
Checkpoint-4: Learning Pytorch for Deep Learning
Checkpoint-5: Model Submission",ML
139,Satvik Jain 22b0635,Scrapping Stock Prices Using Python,,Web Development,The project will involve the development of custom web scraping scripts using Python libraries like BeautifulSoup. Mentees will learn how to navigate through web pages and extract structured data. Final Project will include scrapping stock prices from NSE website.,10,"No prerequisites required
Difficulty level: Easy",projects/web scraping.png,https://drive.google.com/file/d/1dCnR2LVJO003pYwwdRpi8y92CJthPk9O/view?usp=sharing,"Week 1: Introduction to Python
Week 2: HTML Basics
Week 3: Introduction to web scraping, understanding HTML structure, and basic data extraction using BeautifulSoup.
Week 4: Learning File Handling in Python to organize scrapped data into csv
Week 5: Assignment on extracting Data from several websites including SOC webpage
Week 6-8: Heading towards the final project by scrapping stock prices from NSE and also learning about dynamic scraping using Selenium","Checkpoint 1 : Learning Python and HTML Basics
Checkpoint 2 : Getting to know about BeautifulSoup library for scrapping
Checkpoint 3 : Learning File Handling 
Checkpoint 4 : Assignment on Scrapping SOC Webpage
Checkpoint 5 : Final Project + Learning about Dynamic Web scrapping for Live scrapping ",Development
140,Satyankar Chandra 22B0967,Algorithms for Competitive Programming,"Gourish Garg (22B0914), Mrinal Garg (22B0930)",Competitive Programming,"Our aim is to study a variety of data structures and algorithms which are well-known for their application in competitive programming. The idea is to not focus on a specific paradigm itself, but to develop an intuitive thinking process for hard problems.

This project will be highly collaborative, with mentees being strongly advised to participate in numerous group discussions with both the mentors and other mentees. Getting to a solution is not as important here as the path to reach it is.

This is an intermediate level project, with the target range of problem solving being at the level of CodeForces Div2D problems (rated nearly 2000). Mentees with prior experience in math or informatics olympiads will find a ton of enjoyment in this project, and so will others with strong problem-solving skills and great motivation.

Sample material for this project includes the Algorithms book by Jeff Erikson (https://jeffe.cs.illinois.edu/teaching/algorithms/) and the USACO guide (https://usaco.guide/gold).",10-12,"Basic programming experience in any language (pref. Python/C++)
Idea of basic algorithms and their implementation (eg. binary search, sorting, graph storage and traversal, recursive algos, basic DP etc)
Comfortable in solving CF div2AB and some C (it's fine if not participated in live contest)
Mostly topics from the Bronze and Silver sections here (https://usaco.guide/)",projects/Competitive-Programming-1.jpg,https://drive.google.com/file/d/1y82xYGml_2BeEu4589bhQUNTtfffNqn2/view?usp=sharing,"We aim to complete a set of targeted topics every week. For each topic, we will have a small number (4-5) of compulsory (harder) problems to be solved. We will also have an additional amount (5-10) optional (easier) problems which mentees can solve, implement and submit in online judges.

Week 1: Warm-Up
Getting to know each other and discussing a few basic concepts from Bronze and Silver sections of USACO guide and solving some easier problems from the CSES problem set.

Week 2: Greedy Algorithms
Understanding some common greedy patterns in problems and proving their optimality. Mostly covering the Greedy chapter from Jeff Erikson. Introduction to matroids.

Week 3: Recursion and DP - 1
Discussing classical problems in Dynamic Programming and solving some hard DP problems from past contests.

Week 4: Recursion and DP - 2
DP on trees, subarray queries using segment trees and PBDS, subtree queries using Euler Tour Technique, subset DP.

Week 5: Graphs - 1
Basic graph algorithms, connected components, shortest path algorithms, disjoint set data structure, minimum spanning trees.

Week 6: Graphs - 2
Network flows, graph matching, topological sorting, eulerian tours.

Week 7: Range Queries
Segment trees revisited, sparse segment trees, lazy propagation, range update range query, 2D range queries, Square Root Decomposition.

Week 8: Wrap-Up
Mixed bunch of problems from linear programming, game theory and data structures like treaps.

Resources Covered:
https://jeffe.cs.illinois.edu/teaching/algorithms/
https://usaco.guide/
https://cp-algorithms.com/
https://cses.fi/problemset/","1. Greedy Algorithms
2. Dynamic Programming
3. Trees and Graphs
4. Range queries
5. Implementation of all data structures",CP
141,Shanttanu Oberoi 22b1823,FSociety Security Breachers,"Karthick Narayanan (22b1849), Bhaskar Biswas(22b1834)",Network and Cyber Security,"The project aims to develop a comprehensive web security training covering fundamental principles, common attacks, countermeasures, and emerging threats in web security. Mentees will be tasked with learning materials, participating in hands-on exercises and CTF events, and engaging in real-world security challenges to deepen their understanding of web security concepts.",10,"Bash Scripting, Any Programming Language, Basic Computer Networks knowledge",projects/WhatsApp Image 2024-04-08 at 23.34.37_50946140.jpg,https://drive.google.com/file/d/1NLI9wpF9seInRxtcCGpKgk0u8mcAbOos/view?usp=sharing,"Week 1-2- Introduction to Web Security Fundamentals

Study materials- ""Web Application Security: A Beginner's Guide"" by Bryan Sullivan.
Resources: OWASP Top Ten Project, Web Security Academy by PortSwigger and Stanford
CS 253 Web Security Course
Task: Mentees to create a brief presentation summarizing key concepts 

Week 3-4- Understanding Common Web Attacks

Study materials: OWASP Cheat Sheet Series, ""Real-World Bug Hunting"" by Peter Yaworski.
Resources: Capture The Flag (CTF) challenges focusing on common attacks like SQL injection, XSS, and CSRF.
Task: Complete CTF challenges related to common web attacks and document findings.

Week 5-6- Cryptography Basics for Web Security

Study materials: Online courses or tutorials on cryptography basics.
Resources: Cryptography challenges focusing on encryption, hashing, and digital signatures.
Task: Complete lightweight cryptography challenges and provide brief analysis .

Week 7-8: Understanding Emerging Threats and Defense Mechanisms

Study materials: Web Security blogs, articles on emerging threats.
Resources: Discussions on recent web security incidents, case studies.
Task: Research and discuss emerging threats and propose defense mechanisms
.
Week 9-10: Project Presentation Preparation and Reflection

Task: Prepare a brief presentation summarizing the course learnings and personal reflections. Mentees can also discuss their understanding of web security concepts and their application and Mentees will be encouraged to participate in HackMIT pre hackathon CTF challenge.
","Five Major Checkpoints:

Checkpoint 1: Understanding Web Security Fundamentals

Task: Submit brief presentation summarizing key concepts.
Checkpoint 2: Hands-on Experience with Common Web Attacks

Task: Complete guided exercises on common attacks and document findings.
Checkpoint 3: Cryptography Basics for Web Security

Task: Complete lightweight cryptography challenges and provide brief analysis.
Checkpoint 4: Understanding Emerging Threats and Defense Mechanisms

Task: Research and discuss emerging threats and propose defense mechanisms.
Checkpoint 5: Project Presentation Preparation and Reflection

Task: Prepare and deliver a brief presentation summarizing course learnings and reflections.",Others
142,Shreya Tiwari 210050146,Multi-player game,"Sankalan Baidya(210050141), Harsh Chaurasia(20B030019)",Game Development,"In the project, the student will have to create a multi-player game using Unity. The game will be later incorporated in a program by an independent body, Sampurna to teach people how they can teach themselves technology in an ever-growing and fast-paced scenario.
Resources to gain context:-
1.https://www.youtube.com/watch?v=7glCsF9fv3s&list=PLzDRvYVwl53sSmEcIgZyDzrc0Smpq_9fN
2.https://www.youtube.com/watch?v=KFVdHDMcepw",6-7,"Only great enthusiasm in learning game development is required, although it would be good to have a prior knowledge of Unity.",projects/80aa0ce5-c6ab-40ee-87d3-25fc45792261.JPG,https://drive.google.com/file/d/1jRDavAQqpoGwieqd_T7Cc91dRm09n80A/view?usp=sharing,"Week 1: Introduction to Unity and Setup
Week 2: Player Movement and Interaction
Week 3: Refine player controls and interactions based on feedback
Week 4: Networking Setup and Synchronization
Week 5: Design and create game levels with appropriate challenges and objectives
Week 6: Bug Fixing and Optimization
Week 7: Finalization and Deployment","Checkpoint 1: Understand the basics of Unity interface, game objects, components, and scripting
Checkpoint 2: Implement basic player movement and interaction mechanics.
Checkpoint 3: Establish multiplayer functionality and synchronization.
Checkpoint 4: Introduce core game mechanics and start polishing the game.
Checkpoint 5: Develop game levels",Development
143,Shreyas Katdare 22B0636,Sentiment Analysis and Text Generation using Many-to-One LSTMs,Dion Reji (22B0029),Natural Language Processing,"Hey there, future AI enthusiasts! Are you ready to embark on an exciting journey into the world of Natural Language Processing (NLP)? Buckle up, because we're diving deep into sentiment analysis and text generation using the power of Long Short-Term Memory (LSTM) neural networks. Imagine being able to predict the sentiment of reviews with just a glance, or even better, to generate whimsical text with just a tap of your keyboard. Sounds like magic? It's actually the magic of AI and LSTMs!

📝 Sentiment Analysis: Dive into real-world sentiments and use LSTMs to predict whether a review is positive or negative. Clean up messy text, convert it into numerical data, and unleash the power of LSTMs to become a sentiment-savvy AI wizard!

🔍 Text Generation: Immerse yourself in the fantastical realm of LSTMs to generate text that's as whimsical as the original. Explore techniques like entropy scaling and softmax temperature to add a dash of randomness and creativity to your AI-authored tales!

📈 Learning and Resources: Don't worry if you're new to AI or NLP – we've got you covered! We'll provide reading materials, resources, and step-by-step guidance to help you grasp the concepts and unleash your creativity.",10-12,"Basic Python knowledge (libraries like numpy, pandas) is appreciated but not necessary",projects/default.png,https://drive.google.com/drive/folders/1iYcFjydK3JCvDiFB2c1x2pBLdCofDWCW?usp=sharing,"Week 1 :
Set up development environments and install necessary libraries and packages.
Learning basic Python syntax and basic libraries like pandas, numpy.
Week 2 :
Review project requirements and dataset specifications.
Learning overall architecture, mathematics and approach for sentiment analysis and text generation using LSTM.
Week 3 :
Introduce the concept of LSTM neural networks and the many-to-one architecture.
Part 1 of the project begins
Implement a many-to-one LSTM model for sentiment analysis using Keras and TensorFlow.
Train the LSTM model using the preprocessed dataset and evaluate its performance.
Week 4 :
Split the dataset into training and testing sets.
Train the LSTM model on the training set and evaluate its performance on the testing set.
Analyze model metrics such as accuracy, precision, recall, and F1 score.
Discuss potential improvements and optimizations for the sentiment analysis model.
Week 5 :
Part 2 of the project begins
Perform data preprocessing tasks such as text cleaning, tokenization, and sequence creation.
Prepare the text data for training the LSTM model for text generation.
Week 6 :
Implement a many-to-one LSTM model for text generation using Keras and TensorFlow.
Train the LSTM model using the prepared text dataset.
Explore techniques such as entropy scaling and softmax temperature for enhancing text generation quality.
Week 7 :
Evaluate the trained LSTM model for text generation using qualitative assessment.
Generate sample text sequences and analyze the coherence and relevance of generated text.
Fine-tune the LSTM model parameters and hyperparameters based on feedback and observations.
Week 8 :
Present final results and outcomes of sentiment analysis and text generation tasks.","Checkpoint-1 : Learning basics of Python and necessary libraries
Checkpoint-2 : Sentiment Analysis (Part 1) Model Development
Checkpoint-3 : Sentiment Analysis Model Evaluation and Optimization
Checkpoint-4 : Text Generation (Part 2) Model Development
Checkpoint-5 : Text Generation Model Evaluation and Fine-Tuning",ML
144,Shreyas Kulkarni 22B1510,A Quantum Approach to Credit Risk Analysis,Nishlesh Goel (22B0017),Quantum computing/Quantum machine learning,"Risk management plays a central role in the financial system. Risk management encompasses the identification, evaluation, and mitigation of potential threats to an institution's financial security. The problem of risk analysis has been solved extensively using traditional methods. In this project, we'll delve into a revolutionary (and certainly more exciting) way to approach credit risk analysis - Using quantum computing! Quantum computing has proven its efficacy in a variety of different fields, throughout this project the mentees will be able to learn one of the applications of quantum computing. The content covered in this project is just the tip of an iceberg and can have potential applications in wide variety of domains. Sign up for a summer full of venturing into the unexplored waters of quantum computing in the realm of finance.",7-10,Basic-python would be a pre-requisite,projects/SOCprojectbannerSAK.png,https://drive.google.com/file/d/1TZciTcY95xOM2hLCiNsl5gH_x5vYARTw/view?usp=sharing,"Week 1 & 2 - We will delve into the basics of probability & portfolio theory
Week 2 - We analyze credit-default risk using standard methods
Week 3 & 4 - We go on to learn more quantum circuitry and the basics of the qiskit library
Week 5 - We'll create the uncertainty model using these libraries
Week 6 & 7 - The mentees finally perform credit-default risk analysis, make the final report and we have a team treat (maybe)","1 - In-depth learning of probability & portfolio theory
2 - Credit risk analysis via jupyter notebook
3 - Learn to analyze quantum circuits
4 - Create the uncertainity model on python using qiskit
5 - Credit risk analysis using qiskit and final report making",Others
145,Shruti Ghoniya 22B1288,Cyber Sentry: Network Traffic Classification ,"Lakshya Gadhwal, 22b0995",Machine Learning,"https://github.com/cstub/ml-ids/blob/master/notebooks/07_binary_classifier_comparison/binary-classifier-comparison.ipynb

The notebook presents a comparison of binary classifiers for distinguishing benign from malicious network traffic. Three approaches are explored: Random Forest Classifier, Gradient Boosted Tree Classifier using the CatBoost library, and a Deep Neural Network using Keras and Tensorflow 2. The models are trained and evaluated on the CIC-IDS-2018 dataset.",5-7,should have knowledge of simple neural networks and very basic machine learning. We expect lot of enthusiasm owing to the fact that the project is niche and requires time to be put in,projects/WhatsApp Image 2024-04-09 at 22.15.40_712d5ab6.jpg,https://drive.google.com/file/d/1Jw5tQD-LG1jSuUNPP6fWoEJr1RL08zm2/view?usp=sharing,"Week 1)Overview and prep (we can pull this one more week if need be)
Week 2)data loading and hyperparameter optimization for algo 1
Week 3)data loading and hyperparameter optimization for algo 2
Week 4)data loading and hyperparameter optimization for algo 3
Week 5)model selection, training
Week 6)Precision-Recall Decision Boundary Analysis","1)Hyperparameter op
2)data loading and hyperparameter optimization for each algo
3)model selection, training
4)Precision-Recall Decision Boundary Analysis
5)finalization",ML
146,Shubham Ingale 210260022,Introduction to Machine Learning,Omkar Kalugade (210110056),Machine Learning,"In this 8-week capstone project, you’ll have the opportunity to choose a project based on your interests. We'll cover everything from basics starting from learning Python. Whether you’re passionate about finance, healthcare, or any other domain, you can tailor the project to align with your preferences. The capstone project will culminate in a practical application of machine learning techniques.",5-10,,projects/soc_2024.png,https://drive.google.com/file/d/1OM7bug3ZsqIkP2quInEWmREGMdMdXGTS/view?usp=sharing,"Week 1: Introduction to Python
Week 2-3: Basic Machine Learning
Week 4: Neural Networks
Week 5-8: Project","1. Python proficiency
2. Basic ML algorithms application
3. Neural Network application
4. Model selection and training
5. Project completion",ML
147,Shubham Raj 22B0665,Introduction to Deep Learning,Himanshu (22B2131),Deep Learning,"In this project, we aim to delve into the realm of Deep Neural Networks, Convolutional Neural Networks (CNNs) and tackle a multi-class classification problem. CNNs have revolutionized various fields, particularly in computer vision tasks, due to their ability to automatically learn hierarchical features from input data.
The primary objective of this project is to develop a robust multi-class classification model capable of accurately identifying and categorizing input images into multiple predefined classes or categories. This involves understanding the fundamentals of CNNs, including their architecture, layers, and parameters, as well as implementing them using frameworks like TensorFlow.

At the end of this project, you'll have 2 mini-projects and a Final Project, here are some details
Weekly assignments (after covering theory)
2 Mini-Project (Cat/non-Cat Classifier and Digit Classifier) with Neural Network
Final Project: Image classification with CNN (in TensorFlow)",8-10,Basic Python and lots and lots of enthusiasm,projects/SOC Project Banner,https://drive.google.com/file/d/1FyDVJkNITX0QhC8OFeeFLEYBtoAPYbn0/view?usp=sharing,"Week 1: Introduction to Neurons, Basic ML, Logistic & Linear Regression

Week 2: Neural Networks, Gradient Descent, Backpropagation (Assignment 1)

Week 3: Deep Neural Networks (Assignment 2)

Week 4: Multi-Class Classification (Mini-Project: Digit Classification)

Week 5: Introduction to CNNs (theory & practical)

Week 6: Introduction to TensorFlow (Assignment 3)

Week 7-8: Final Project: Multi-class CNN-based Classification Project","Checkpoint-1: Cat/non-Cat classifier Assignment 1 (Week 2)
Checkpoint-2: Improving Cat/non-Cat classifier Assignment 2 (Week 3)
Checkpoint-3: Digit Classification Mini Project (Week 4)
Checkpoint-4: Basic TensorFlow Assignment (Week 6)
Checkpoint-5: Final Project (Week 8)",ML
148,Siddhant Gada 22b4223,Online Trading with Pine Script,Pinak Mahapatra(22b0447),Finance,"We will guide participants through the TradingView platform and the Pine Script language, essential for online trading. Attendees will acquire skills in backtesting existing strategies and crafting new ones, leveraging both technical and fundamental financial insights to enhance their trading proficiency.",15,,projects/default.png,https://drive.google.com/file/d/1S1kwwOGjUgY_uI4G9Juj3M4tB0Ji7flg/view?usp=share_link,"Creating an 8-week plan to teach trading using the TradingView platform and Pine Script involves a blend of theoretical knowledge and practical application. Here's a structured approach to ensure comprehensive coverage:

Week 1: Introduction to Online Trading and Tools
Objective: Understand the basics of online trading, overview of the TradingView platform, and the significance of Pine Script.
Activities:
Interactive sessions on the history and evolution of online trading.
Introduction to TradingView platform: navigation, tools, and resources.
Overview of Pine Script: purpose and potential.

Week 2: Deep Dive into TradingView
Objective: Gain in-depth knowledge of TradingView’s functionalities, including chart analysis and indicators.
Activities:
Hands-on training on using charts, indicators, and drawing tools on TradingView.
Begin basic analysis of financial markets using TradingView tools.

Week 3: Fundamentals of Market Analysis
Objective: Understand the importance of technical and fundamental analysis in trading.
Activities:
Theoretical sessions on the principles of market analysis.
Practical exercises on identifying trends, support, and resistance levels.

Week 4: Introduction to Pine Script
Objective: Learn the basics of Pine Script for creating custom indicators and strategies.
Activities:
Writing simple scripts to customize indicators.
Analyzing script structure and basic commands in Pine Script.

Week 5: Advanced Pine Script Strategies
Objective: Develop complex trading strategies using Pine Script.
Activities:
Coding custom trading strategies in Pine Script.
Debugging and refining scripts for accuracy and efficiency.

Week 6: Backtesting Strategies
Objective: Master the skill of backtesting trading strategies using Pine Script and TradingView.
Activities:
Theoretical overview of backtesting importance and methodologies.
Practical sessions on backtesting pre-existing and newly created strategies.

Week 7: Risk Management and Optimization
Objective: Learn risk management principles and strategy optimization to enhance trading performance.
Activities:
Sessions on risk management techniques and their implementation.
Optimizing trading strategies for better performance and reduced risk.

Week 8: Final Project and Review
Objective: Apply learned skills to create and present a comprehensive trading strategy.
Activities:
Developing a complete trading strategy incorporating technical and fundamental analysis.
Presentations of strategies with a review session for feedback and improvement suggestions.

Throughout the 8 weeks, encourage active participation, provide real-world examples, and foster a collaborative learning environment. Weekly assignments and quizzes can help reinforce learning and assess progress.","Deep Dive into TradingView
ntroduction to Pine Script
Backtesting Strategies
Risk Management and Optimization
Final Project and Review",Others
149,Siddhant Midha 200070078,Exploring quantum convolutional neural networks,--,Machine Learning,"In this work, we will aim to study quantum convolutional neural networks. Starting from the basics, we will implement the model, study its training, and study applications to quantum error correction, phase diagram classification etc. Finally, we will aim to explore what makes this a ""good"" model: does it generalize? how well does it train? what is the parameter space of optimization? anything else?

See [1] https://arxiv.org/pdf/1810.03787.pdf, [2] https://arxiv.org/pdf/2306.13461.pdf
 ",1-2,"Basics of ML, Basics of Quantum Physics",projects/Screenshot 2024-04-09 at 00.48.18.png,https://drive.google.com/file/d/1cTE6VuMosqj4SD-eb128FvLhwBhTYR_S/view?usp=sharing,"basics of qc/ml, implement basic models, implement the paper, start implementing new modifications, write report and wrapup","basics of qc/ml, implement basic models, implement the paper, start implementing new modifications, write report and wrapup",ML
150,Siddhant Midha 200070078,The physics of machine learning,--,Machine Learning,"We will study ML models from a ""physics"" perspective: rather than being in the race of getting better accuracy and better models, we will study the basics of how optimization in ML can show very interesting phenomenon. Some examples are (i) fractality in hyperparameter spaces [3], (ii) phase transitions in optimization procedures [1], and (iii) grokking [2]. Thus, the idea is to study classical ML models, and ""see"" how they ""learn"".

[1]https://proceedings.neurips.cc/paper_files/paper/2023/hash/a23598416361c7a9860164155e6ddd0b-Abstract-Conference.html
[2] https://arxiv.org/pdf/2201.02177.pdf
[3] https://sohl-dickstein.github.io/2024/02/12/fractal.html",2-3,"basics ML, coding/python skills",projects/0_HwFeAB4nHLpqgw-7.png,https://drive.google.com/file/d/1Es14p4k9uLo_Lqg0Nzl3zBaZnySAWUl1/view?usp=sharing,"basic ml recap, studying the papers, setting up codebase for study training dynamics, writing up results","basic ml recap, studying the papers, setting up codebase for study training dynamics, writing up results",ML
151,Siddharth Kumar 210020134,AI Powered PDF Chatbot,Samyak Bagdiya( 210020115),Natural Language Processing,Creating a chatbot using Langchain and openAI. This chatbot will answer all the questions regarding the pdf (or whatever the dataset is concerned about).,10,"python
basics of nlp and ml
",projects/default.png,https://drive.google.com/file/d/1dMRPC-eSg4SpKEByaZavxybNzzLpiWQ-/view?usp=sharing,"week 1: Python
Week 2 and 3: Basics of NLP
week 4 : Langchain
week 5 and 6 : working with the main project
week 7: Interface for chatbot
week 8: report making
","1:python
2:Hands-on in NLP
3:A basic langchain based assignment
4: Main project
5:Streamlit Interface",ML
152,Siddharth Verma 22b2153,"""The Art of ShadowOps: Steganographic Warfare and Cloud-Sentinel Deployment ""","Abhisekh Kumar (22B2210)   , Danish Siddiqui (22B2104)",Cybersecurity + Machine Learning,"Welcome to ""The Art of ShadowOps: Steganographic Warfare and Cloud-Sentinel Deployment,"" where Python serves as our base programming language, and you will embark on an enriching journey encompassing the realms of steganography, deep learning, and cloud computing. 

In this project, you'll delve deep into the intricacies of Python, honing your skills to wield it as a powerful tool in the domain of digital secrecy and defense. Through hands-on exercises and immersive tutorials, you'll master the language's capabilities, leveraging its versatility to implement cutting-edge techniques in steganography, machine learning, and cloud deployment.

As you navigate through the shadows of ShadowOps, you'll gain invaluable insights into the art of steganography, learning to conceal messages within digital images with precision and finesse. Guided by experts in the field, you'll unravel the secrets of embedding encrypted information in plain sight, equipping yourself with a formidable arsenal for clandestine communication.

But that's just the beginning. With a firm grasp of steganography, you'll venture into the realm of deep learning, exploring advanced concepts and methodologies to enhance your understanding of Machine Learning and its applications in cybersecurity. Through practical projects and real-world scenarios, you 'll develop the skills to construct intelligent Cloud-Sentinels, guardians of the digital frontier, capable of detecting and thwarting hidden threats with unparalleled efficiency.

Moreover, ""The Art of ShadowOps"" isn't just about acquiring technical expertise – it's about cultivating a mindset of curiosity and inquiry. Through an introduction to reading research papers, you'll learn to navigate the vast landscape of academic literature, extracting valuable insights and staying abreast of the latest developments in cybersecurity and beyond.

Join us on this transformative journey into the heart of ShadowOps, where Python prowess meets the art of secrecy, and innovation reigns supreme. Are you ready to unlock the mysteries of the shadows and emerge as a true master of the art?

",30-40,"No Coding or Programming Prerequisites for Mentees ,Although Mentees must mention about their Motivation and What really brings them here . Hard Work should be there as I would be personally guiding them through and moreover plenty of learning is there.

One more thing , be ready for a lot of Assignments and Compulsory Meets & Guided Tutorials.  

Finally Don't use LLM like ChatGPT or Gemini or Quiltbot for writing proposal , You will be caught  immediately  ;) 

Happy Learning!",projects/1_dQyfOpFWmSxrmdOcQgW6OQ.jpg,https://drive.google.com/file/d/1gA4Q4BWCx8jAfosZYMEQ33JsQKCPrczf/view?usp=sharing,"Week 1 : Introduction to Cryptography & Programming in Python
Week 2 : Intro to Python Libraries 
Week 3:  Introduction to Steganography  & Machine Learning
Week 4:  Neural Network & Image Classification
Week 5:  Socket Programming Basics & Protocol
Week 6:  Practicing Python Script & Reading Research Paper
Week 7: Discussion and Code Dedicated to Final Project & Documentation
Week 8: Final Review","Checkpoint 1:  Coding Caesar Cipher & Hangman Game as Mini Project
Checkpoint 2: Creating a Basic Machine Learning as Mini Project 
Checkpoint 3: Image Classification using Neural Network
Checkpoint 4: Documentation & Submission of Working ML Model
Checkpoint 5: Setting up ML-Sentinel on Docker",ML
153,Soham Dahane 22b0941,Hands on Reinforcement Learning,Shreyas Katdare(22b0636),Machine Learning,"Hands on Reinforcement Learning
Reading material-Sutton & Barto,Grokking Deep Reinforcement Learning
We will be following Grookings as a reference for the theory, and read chapters from it while implementing the strategies described in it in Python. 
Some resources we may use are the slides on RL by David Silver (https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver) and the slides from the course CS 747: Foundations of Intelligent and Learning Agents (https://www.cse.iitb.ac.in/~shivaram/teaching/old/cs747-a2022/index.html)

I have done both wids and soc myself under same topic whose repo is below-
https://github.com/theashwinabraham/WiDS-Training-AI-to-play-games-using-Reinforcement-Learning",10-15,"1. Should know basic python libraries like numpy, sklearn
2.Should know basic RL( can read first 2-3 chapters from Sutton & Barto)",projects/default.png,https://drive.google.com/drive/folders/1CjP4BcX35w3T1mUf1sB2vioujvQdyhBt?usp=sharing,"Week 1-Implementations of common Machine Learning Algorithms
Using the standard implementations of some famous algorithms using Scikit-Learn.

Week 2-MAB,MDPs,Implement a game of Snake
Learning objectives for this week are:
1. N-armed bandits: Perhaps the simplest RL challenge. You are provided with n arms, and you can pull one of them at a time. Each arm gives a reward from a probability distribution, independent of which arms you pulled beforehand (However it may depend on the time step you pull). Your task is to maximize the sum of these rewards, that is essentially find the arm which gives the maximum expected reward. We will be studying few algorithms to solve this problem.
2. Formalism of Reinforcement Learning in terms of Markov Decision Process: Way to generalise and represent a given problem as a Reinforcement Learning problem.
3. Dynamic Programming: The most basic set of algorithms to deal with prediction and control problems, that is, finding an optimal policy given the complete Markov Decision Process

Week 3-Monte Carlo Methods,Temporal Difference Learning
Part I is on implementing the Monte Carlo ES algorithm for a given MDP. I've provided the MDP as a Linux executable. If it doesn't run on your device please let me know, and I will share another executable. 

Part II is on solving the game of Tic Tac Toe. Tic Tac Toe can be solved exactly via the minimax algorithm, and in Part I you will have to implement this algorithm. However, you will see that this algorithm is extremely computationally expensive. Therefore we will use an on policy RL algorithm (we will use an algorithm based on ε-soft policies).

Week 4-DDQN
Reading chapters grookings and implementing

Week 5 and 6- Implementing a paper to create a Chess Engine based on Deep RL
Implement the paper.","Checkpoint 1-Implementations of common Machine Learning Algorithms
Checkpoint 2-MAB,MDPs,Implement a game of Snake
Checkpoint 3-Monte Carlo Methods,Temporal Difference Learning
Checkpoint 4-DDQN
Checkpoint 5 and 6- Implementing a paper to create a Chess Engine based on Deep RL",ML
154,Soham Joshi 22b2495,Image Captioning Using Attention Mechanism,"Co-Mentors: Parth Rasal (22B2236), Abhishek Kumar (22B2210)",Image Processing,"The project is based on image captioning using CNN encoder and LSTM decoder. This project was done by my co-mentor in WiDS. Unfortunately, the output predicted in that project was not quite good. Hence, we have decided to incorporate the attention mechanism in the encoder and decoders.
Shared below is the WiDS project link that I have completed:
https://github.com/Soham-joshi04/Image-Captioning/blob/main/Image_Captioning.ipynb ",10,Python and Basic Familiarity with Machine Learning,projects/default.png,https://drive.google.com/file/d/1Y4l6FbXu53EHVoyEsKiYyygL27rWX2Ha/view?usp=sharing ,"Week 1: Learning Neural Networks 
Week 2: Exploring Convolutional Neural Networks 
Week 3: Exploring Sequential Models (RNN, LSTM)
Week 4: Learning Basics of Natural Language Processing
Week 5: Understanding Attention Mechanism & Encoder-Decoder Architecture
Week 6 & Week 7: Building Model","Checkpoint-1: Basic Classification Task using Neural Networks
Checkpoint-2: Classification of Images using CNN
Checkpoint-3: Stock Prediction using Sequential Models (Hands on with Sequential Model)
Checkpoint-4: Sentiment Analysis using NLP
Checkpoint-5: Final Model",ML
155,Soutrik Sarangi 20B090014,RL for Combinatorial Optimization,Samyak Jha (samyakj@iitb.ac.in),Machine Learning,"Using RL-based methods for NP-hard Combinatorial Optimization has been popularised in recent days with the advent of the celebrated PPO algorithm by OpenAI, which is intractable to solve otherwise. Examples include the Travelling Salesman Problem, Maximal Independent Set in graphs, Dominating Set problem, etc.  Learning to solve combinatorial optimisation is very suited for RL-based techniques owing to formulating a CO-based problem as a decision problem. However, we have a non-Markovian decision problem at hand. Monte Carlo Tree Search comes into play to combat this issue. We will explore this domain and look to obtain improved baselines and come up with better algorithms(and implement them, obviously!) by combining MCTS and policy gradient-based methods. One can look into recent works on these and their corresponding Github repos: https://openreview.net/forum?id=0Hm6VYaAiRP, https://arxiv.org/pdf/2206.01011.pdf, https://www.ijcai.org/proceedings/2019/0432.pdf, https://arxiv.org/pdf/2006.10643.pdf",4-6,"Basic familiarity with DL frameworks like PyTorch/Jax and RL libraries(Gym). Basic familiarity with MDPs and RL algorithms(can be picked up soon if not very familiar), basic familiarity with combinatorial algorithms for graphs and approximation algorithms. Enthusiasm and perseverance
 to go through research papers, codebases and adapt/come with new ideas is a must!",projects/default.png,https://drive.google.com/file/d/10mwwg3ymNOE2CFsg41D3LIVUJbNyjlfW/view?usp=share_link,8 weeks,"Checkpoint-1: Gaining familiarity with Jax, PyTorch, Gym and RL algorithms.
Checkpoint-2: Literature review on the topics
Checkpoint-3: Building baselines by running codebases from existing papers on various datasets
Checkpoint-4: Optimizing existing code and designing new algorithms.
Checkpoint-5: Writing tensorized code for the algorithms designed and comparing to already created baselines.",ML
156,Sravan K Suresh  22B3936,Quantum Computing and Quantum Information,"Nivesh Aggarwal (22B0912), Harsh Anand (22B1249)",Quantum Computing and Quantum Information,"Learn the magic of quantum computing through hands-on activities, starting from basics to designing mind-bending quantum circuits and mastering cutting-edge algorithms like Grover's and Shor's. Here's your chance to dive into the exciting world of quantum error correction to conquer the challenges of tomorrow's computing.

Introductory reading:
https://www.ibm.com/topics/quantum-computing#:~:text=Quantum%20computing%20uses%20specialized%20technology,can't%20solve%20quickly%20enough.
https://cds.cern.ch/record/383367/files/p165.pdf

References for the complete project:
Introduction to Quantum Computing and Information, Nielsen & Chuang [Chapters 1-10]

Get ready to experience the coding fun and join the quantum revolution!",7,Proficiency in linear algebra ,projects/banner.jpg,https://drive.google.com/file/d/1_dSdyu_0azZ_OO3hyB7oHTnTCDGlg3JL/view?usp=sharing,"Week-1: Linear Algebra for Quantum computing 
Week-2: Introduction of Qiskit library
Week-3: Basic Quantum Circuitry
Week-4: Quantum Algorithms- part 1
Week-5: Quantum Algorithms- part 2
Week-6: QEC- Part 1
Week-7: QEC- Part 2","1) Basic linear algebra and introduction to Qiskit
2) Deutsch and Deutsch-Jozsa algorithms
3) Algorithms based on Fast Fourier Transform like Shor
4) Algorithms on Quantum search like Grover
5) Quantum Error Correction",Others
157,Sumanth 22b3915,Institute Course Interaction Platform (ICIP),shivam panwar(22b3965),Web Development,"The Institute Course Interaction Platform (ICIP) is a comprehensive web-based system designed to streamline the academic experience for students, professors, and teaching assistants (TAs) at IIT Bombay.

ICIP leverages individual institute IDs and passwords to grant students access to their registered courses for the semester. Upon logging in, students are presented with a personalized dashboard displaying all the courses they are enrolled in.

Each course is represented by a dedicated virtual room within the website, providing a centralized hub for course-related interactions. Within these rooms, students can engage in discussions, ask questions, submit assignments, and access course materials. Professors and TAs are assigned to monitor and facilitate these interactions, fostering a collaborative learning environment.

Moreover, ICIP is seamlessly integrated with other IIT Bombay websites, providing direct access to additional resources and services offered by the institute. Whether it's accessing library databases, checking academic calendars, or exploring extracurricular opportunities, ICIP serves as a gateway to the rich ecosystem of IIT Bombay's online platforms.

Overall, ICIP aims to enhance the educational experience by promoting active engagement, facilitating communication, and centralizing access to academic resources within the IIT Bombay community.",4,,projects/default.png,https://drive.google.com/drive/folders/1xSoO3785zx0uHQ--PVZYKKjhDx2-UOdG,"Week 1:
Checkpoint 1: Backend Infrastructure Setup

Setup development environment (Node.js, MongoDB).
Design database schema for storing course information and user data.
Implement basic user authentication system.

Week 2:
Checkpoint 1 (continued):

Develop backend APIs for user authentication and course management.
Test APIs using Postman or similar tools.
Begin documentation of API endpoints and functionality.

Week 3:
Checkpoint 2: Frontend Development with React

Setup React.js environment.
Design wireframes and user interfaces for student dashboard and course rooms.
Begin development of frontend components for authentication and course listing.

Week 4:
Checkpoint 2 (continued):

Implement responsive layouts and navigation.
Integrate frontend with backend APIs for user authentication.
Develop UI components for displaying course information and basic interactions.

Week 5:
Checkpoint 3: Course Room Functionality

Develop backend APIs for creating and managing course rooms.
Implement frontend components for accessing and joining course rooms.
Begin development of discussion forums and basic chat functionalities within course rooms.

Week 6:
Checkpoint 3 (continued):

Complete implementation of discussion forums and chat functionalities.
Test course room functionalities for basic interactions.
Integrate notifications and alerts for course updates.

Week 7:
Checkpoint 4: Integration with Other IITB Websites

Research and identify APIs for integration with external IIT Bombay websites.
Develop backend endpoints for accessing external resources.
Integrate frontend components with external APIs for seamless navigation.

Week 8:
Checkpoint 4 (continued):

Test integration with external websites and resources.
Fine-tune user experience for accessing external resources.
Complete documentation of integration process.

Week 9:
Checkpoint 5: Testing and Deployment

Conduct comprehensive testing of frontend and backend functionalities.
Gather feedback from users and make necessary adjustments.
Prepare deployment scripts and configurations for production environment.

Week 10:
Checkpoint 5 (continued):

Deploy the platform to production environment.
Monitor performance and address any issues.
","Checkpoint 1: Backend Infrastructure Setup

i]Develop backend APIs using Node.js, Express.js, and MongoDB.
ii]Set up user authentication and authorization using institute IDs and passwords.
iii]Implement database schema to store course information, user data, and interactions.

Checkpoint 2: Frontend Development with React

i] Design user interfaces for student dashboards, course rooms, and other features using React.js.
ii]Implement responsive layouts and intuitive navigation to enhance user experience.
iii]Integrate frontend components with backend APIs to fetch and display relevant data.

Checkpoint 3: Course Room Functionality

i] Create individual virtual rooms for each course, accessible to enrolled students and assigned professors/TAs.
ii]Implement features such as discussion forums, chat functionalities, file uploads, and assignment submission within course rooms.
iii]Enable notifications and alerts for important updates or announcements from professors/TAs.

Checkpoint 4: Integration with Other IITB Websites

i]Establish seamless integration with other IIT Bombay websites and resources.
ii]Develop APIs or utilize existing APIs to link to library databases, academic calendars, event portals, and extracurricular platforms.
iii]Ensure smooth navigation and data exchange between ICIP and external websites.

Checkpoint 5: Testing and Deployment

i]Conduct thorough testing of both frontend and backend functionalities, including user authentication, data retrieval, and real-time interactions.
ii]Perform usability testing to gather feedback from users and identify areas for improvement.
iii]Prepare for deployment to production environment, ensuring scalability, security, and reliability of the platform.",Development
158,Sumanto Kar 22m1526, , N/A,Deep Learning, ,2, ,projects/default.png, , , ,ML
159,Sumit Prakash 22b3306,Future Forecasting using Time Series Analysis,"Parth Pai (22b3305), Nandan Paralikar (22b3326)",Machine Learning,"Embark on a journey to the forefront of predictive analytics with 'Future Forecasting using Time Series Analysis,' a 8-week intensive project tailored for beginners. This project offers a deep dive into the fascinating world of data science through the lens of time series analysis, empowering you to forecast the future with precision and confidence. Perfect for those with a curiosity for patterns and predictions, you'll master the art of Python programming, statistical modelling, and the latest in machine learning techniques. With a special focus on real-world application, you'll not only learn the theory behind forecasting but also apply your knowledge to a major project that simulates actual industry challenges. You'll uncover the secrets hidden in time-based data and learn to predict trends, seasonalities, and future events with accuracy. It's your first step towards becoming a visionary in data science. Join us to unlock the predictive power of data and shape the future with your insights.

Checkout this video to get a taste of how fascinating time series modelling looks like!
https://www.youtube.com/watch?v=YQH-gKRuwsk

PS: don't fear looking at the math behind it. it's gonna be fun :)",7-8,Basic programming knowledge (preferably python) and a high enthusiasm :),projects/default.png,https://drive.google.com/file/d/1rNIlPd3BuW6xcCOtIoG_VwEI7jmXhnCg/view?usp=sharing,"Week 1 - Introduction to Data Science and Python Programming
Week 2 - Exploratory Data Analysis and Visualization
Week 3-4 - Statistical Foundations
Week 5 - Machine Learning Basics
Week 6 - Different Machine Learning models like SVM, Decision Trees etc.
Week 7 - Intro to Time Series Analysis and applications (Intro to Deep Learning - Optional)
Week 8 - Final Project on Future Forecasting using Time Series ","Checkpoint 1 : Getting comfortable with tools used for Data Science
Checkpoint 2 : Understanding Statistical foundation and implementing in examples
Checkpoint 3 : Get hands on different ML models 
Checkpoint 4 : Building foundations of Future Forecasting and Time series data
Checkpoint 5 : Final project",ML
160,Takshit Aggarwal 22B1236,SeeDeep: Into the Depths of Computer Vision,Harsh Kumar (22B0973),Deep Learning,"In this project, we embark on a journey to unlock the power of deep learning for advanced image analysis.  Our goal is to develop a comprehensive system that can not only categorize images based on predefined classes (classification), but also identify objects within an image with pinpoint accuracy (segmentation). This project will delve into the fascinating realm of deep learning architectures, empowering us to train a model that can effectively ""see"" and understand the intricate details within images. By leveraging this cutting-edge technology, we aim to realize the various real-world applications of computer vision.",9 - 11,N/A (basic knowledge of python is a bonus but everything will be taught from scratch),projects/SOC.png,https://drive.google.com/file/d/18f6Zcj0CknxSUFOMwKSP1IvRB1lgvNdB/view?usp=sharing,"Week 0: Project Kick-off & Foundations
Week 1: Data Wrangling & Preparation
Week 2: Model Selection for Image Classification
Week 3: Model Implementation & Initial Training (for grayscale images)
Week 4: Model Evaluation & Optimization
Week 5: Model Adjustment for Deployment on other types of datasets
Week 6: Introduction to the Concepts of Segmentation
Week 7: Understanding various Architectures (such as U-Net) {Optional}","Checkpoint-1: Review of essential python libraries alongside explanation about the working of Neural Networks for Image Classification.
Checkpoint-2: Image Classification of Grayscale Images
Checkpoint-3: Image Classification for Coloured Images
Checkpoint-4: Deployment and Optimization of Models
Checkpoint-5: Introduction to Image Segmentation",ML
161,Tanay Bhat 22B3303,Retro-Learning: Exploring Reinforcement Learning through Retro Games,"Devavrat Patni, 22B3969",Machine Learning,"Reinforcement Learning isn't just a dry concept - it's a gateway to a world of endless exploration! We shall use the power of RL algorithms to create agents that can tackle  games like Super Mario and Tetris. Explore the underlying mathematics behind RL  and use them to create strategies to conquer these retro classics.

https://github.com/Tanay-Bhat/SOC-2024-Retro-Learning-/tree/b1801dd41655cc27fb1c49c230d8533f70c89bb0

(All files will be uploaded here)",6-8,"Basic knowledge about probability, Familiarity with python",projects/default.png,https://drive.google.com/file/d/1r5GzsatSYS7xL4T0HL7bVvSDbKSEhGET/view?usp=sharing,"Week 1: Understanding the foundational mathematics behind RL
Week 2 - 3: Using RL to play simple single player games
Week 4: Understanding some advanced mathematical concepts related to RL\
Week 5 - 7: Using RL to play Super Mario","Checkpoint 1: Summarize Basic RL principles in Latex
Checkpoint 2: Implement RL on snake/tic-tac-toe (or similar simple game)
Checkpoint 3: Implement RL on tetris/2048 (or any similar intermediate game)
Checkpoint 4: Summarize understanding of advanced topics in Latex
Checkpoint 5: Implement RL on Super Mario ",ML
162,Tec Narayan Brahmachari 22b0982,Transformer Based Model for Image Captioning,NA ,Machine Learning,"https://jmlr.org/papers/volume3/bengio03a/bengio03a.pdf

https://arxiv.org/abs/1411.4555

https://www.researchgate.net/publication/315666581_Where_to_put_the_Image_in_an_Image_Caption_Generator

https://arxiv.org/pdf/2203.15350.pdf

https://github.com/tecnarayan/Image_Captioning",12,Python ,projects/default.png, Numpy ,https://drive.google.com/file/d/17mgta1i02Xz4aTSPehVD6vBbW9U5coxb/view?usp=drivesdk,22b0982@iitb.ac.in,ML
163,Tejas G. Shende 22B3318,Graphs' Empire,"Geet Singhi (22b1035), Devavrat Patni (22b3969)",Graph Optimisation Algorithms,"We will cover basic graph theory, following which the focus will be on implementation of graph traversal algorithms, alongside solving network flow problems. Primary references for the course will be Algorithm Design by Kleinberg Tardos and Introduction to Graph Theory by Douglas West. The detailed topic-list can be found in the week-wise description.
In addition we will provide mentees with video learning resources (from youtube/coursera) and regularly provide problem statements for them to practise, honing both their knowledge of theoretical CS and ability to actually implement the learnt algorithms.",10-12,"Experience with C++/python (CS101 is good enough) but more importantly, lots of enthusiasm :)",projects/default.png,https://iitbacin-my.sharepoint.com/:i:/g/personal/22b3318_iitb_ac_in/EcQGWuwawAdOn2ejVdecOTABFPTGNxv2fImWMGJmZ5xTyg?e=GRhSAT,"Week 1: Introduction to graph theory and traversal
Week 2: BFS, DFS - theory and implementation
Week 3: Dijkstra's algorithm, Kruskal's algorithm
Week 4: Network Flow and Ford Fulkerson algo with implementation 
Week 5: Buffer week to catch up and complete remaining parts 
Weeks 6 and 7: Using graphs for topics such as image segmentation, and application for network flow
Week 8: Review, buffer, and more problems in case time permits","Checkpoint 1: Understood and implemented BFS/DFS
Checkpoint 2: Implemented Djikstra and Kruskal
Checkpoint 3: Understood network flow and implemented Ford Fulkerson
Checkpoint 4: Completed theory and begun implementation for image segmentation
Checkpoint 5: Finished image segmentation code",Others
164,Tirth Gada 22B3005,Image Colorizer,"Tirth Gada ( 22b3005 ) , Mohit Yadav (22b0442 )",Image Processing,"Excited about the transformative potential of computer vision? Dive into a cutting-edge project implementing Pix2Pix GAN for grayscale image colorization! Learn to harness deep learning and GANs to produce stunning full-color images. With hands-on experience using Pix2Pix, a leading GAN architecture, explore its applications for enhancing image realism. This project offers invaluable insights into GAN fundamentals and image colorization, empowering you to develop your own Pix2Pix models. Unleash the power of Pix2Pix GAN to revolutionize graphic design and photo editing. Don't miss this chance to explore the endless possibilities. Check out the Pix2Pix GAN paper: https://arxiv.org/pdf/1611.07004.pdf",6-8,"Basic Proficiency in Python , Basics of Machine learning / Deep learning",projects/colorizer.png,https://drive.google.com/file/d/1JEqMdi-cwPRPQ_L3iKddt48ZMWFQzK2X/view?usp=sharing,"Week 1 : Brush up basics of Python & basics of neural networks

Week 2 - 3 : Learn convolutional neural networks ( CNN's ) & implement them in short project using PyTorch - Tensorflow 

Week 4 - 5 : Learn about generative adversarial networks ( GAN's ) 

Week 6 - 7 : Implement the project idea of colorization using Pix2Pix GAN

Week 8 : Deploy & Implement some additional features ","1 ) Learning Python and neaural networks 

2 ) Implementing CNN using PyTorch / TensorFlow

3 ) Implement and learn generative adversarial networks ( GAN's ) 

4 ) Apply Pix2Pix GAN

5 ) Deploy ",ML
165,Utsav Jha 22B0303,ResoRevive: Breathing Life into Low-Resolution images,Aditya Kumar(22B0431),Deep Learning,"Embark on an exciting adventure where you'll first explore the basics of machine learning before diving into the fascinating world of deep learning. In first two weeks, build a strong foundation in classical deep learning concepts like perceptrons and neural networks. to the cutting-edge technology of Generative Adversarial Networks (GANs).

Picture yourself discovering the incredible potential of GANs as you learn to create stunning projects that were once only in your imagination. From generating lifelike images to transforming one type of image into another, and even swapping faces seamlessly - the possibilities are endless and bound only by your creativity.

But that's not the end of your adventure. Picture yourself equipped with the skills to train your very own ESRGAN. With this newfound knowledge, you'll have the power to enhance low-resolution images, transforming them into vivid, detailed masterpieces.

Join us on this exhilarating expedition where creativity knows no bounds, and each stride forward brings you closer to turning your aspirations into reality. Are you prepared to delve into the realm of deep learning and uncover the keys to crafting extraordinary projects? Your journey of discovery awaits!",8-10,"1. Basics knowledge of python libraries like numpy, matplotlib and classical ML algorithms like linear, logistic regression Will be more than enough.",projects/default.png,https://drive.google.com/drive/folders/1z1MvuqAtbCZdQ5lp0aMnXkmpTFkDGVwm?usp=sharing,"Week 1 - Review of python programming,OOPS in python
Week 2 - Multi Layer Perceptrons (MLP), Basics of Neural Networks
Week 3 - Introduction to Pytorch, learn how to use Autograd and train a simple MNIST /Fashion MNIST classifier 
Week 4 - Introduction to CNNs and transfer learning 
Week 5 - Use of transfer learning to train an image classifier 
Week 6 - Learn about GANs, read the original 2014 GAN paper 
Week 7 - Learn about ESRGANs from the ESRGAN paper, Start implementing the paper on pytorch.
Week 8 - Final model preparation.
","Checkpoint 1 - Understanding the architecture of a basic neural network
Checkpoint 2 - Built the MNIST classifier with deep understanding of pytorch autograd and OOPS
Checkpoint 3 - Used transfer learning on pretrained datasets to make a CNN image classifier.
Checkpoint 4 - Reading and understanding the original GAN paper. appreciating Adversarial networks over traditional
Checkpoint 5 - Implementation of the ESRGAN paper to produce high resolution images",ML
166,Varun Ram Narayanan 22B0347,Build your own powerful GPT using Open Source LLMs with Langchain and Llama Index,"Varun Ram Narayanan(22B0347), Samkit Palrecha(22B0328), Raj Singh Yadav(22B0341)",Natural Language Processing,"Resources also include Kaggle Tutorials which are available for free online. GeeksforGeeks Websites also has some interesting NLP and ML Tutorials. Course Era Courses by DeepLearningAI has theory required for the project.Youtube tutorials are also available for the code implementation. Youtube tutorials will be sent for the LangChain and LlamaIndex Sections as well. Resources also include Kaggle Tutorials which are available for free online. GeeksforGeeks Websites also has some interesting NLP and ML Tutorials.
https://www.coursera.org/learn/nlp-sequence-models?specialization=deep-learning",8-10,"Basic Coding Experience in Python libraries like numpy, pandas, and Machine Learning is a must. Some familiarity with basic linear algebra, particularly in the context of matrix operations at a level akin to MA106 is required. 
Familiarity in how to implement a neural network is a bonus. However, this can be covered up in the first week.",projects/default.png,https://drive.google.com/drive/u/1/folders/1BGNkG2p64EuLH8wmwgklk1O8o9n5mesB,"Week 1: RNN and LSTM + assignment

Start by understanding the basics of Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks.
Implement a simple RNN and LSTM from scratch using a deep learning framework like TensorFlow or PyTorch.
Assignments involve training these networks on simple sequential data like time series or text prediction tasks.

Week 2: NLP basics (tokenization, word embedding, etc.) + assignment

Dive into Natural Language Processing fundamentals such as tokenization, word embeddings (Word2Vec, GloVe), and maybe even basics of text preprocessing.
Implement tokenization and word embedding techniques on a corpus of text.
Assignments involve tasks like sentiment analysis or text classification using these techniques.

 Week 3-4: Encoder-decoder architectures, Transformer models, and basic concepts of RAG

Study encoder-decoder architectures, focusing on sequence-to-sequence models.
Understand the Transformer architecture and its components, including self-attention mechanisms.
Learn about concepts like positional encoding and multi-head attention.
Explore the basics of Retrieve and Generate (RAG) models for information retrieval and generation tasks.
Assignments involve building and training sequence-to-sequence models for translation tasks or summarization.

Week 5: Langchain and LLama index

Study Langchain and Llama index  Research any available resources or papers on this topic.
 Explore these resources to understand their relevance in NLP tasks.
Assignments could involve exploring language datasets and understanding how blockchain can be applied in the context of language data.

Week 6: Choose a project topic and start creating your own ChatBot.

Select A specific topic and begin collecting data for the same.
Define the scope of your project and set clear objectives.

Few Examples would be taking the UGAC Rulebook, or a Company's Annual Report to create your very own Chatbot

 Week 7-8: Project development, optimization, and UI

Work on developing your chosen project, keeping in mind good coding practices and optimization techniques.
Optimizing the RAG model using SOM/graph of concepts or other strategies. Design and implement a user interface using libraries like Gradio to make your project accessible and user-friendly.
Test your project thoroughly and iterate on improvements based on feedback.","CheckPoint 1 : Comfortable Implementing Basic ANN's, RNNs,  and LSTMS.
CheckPoint 2 : Comfortable with basic NLP tasks like Tokenization,Stemming, Lemmatization, Word embedding, etc. Familiarity with Attention Models and transformers, Assignment will reflect on clarity
Checkpoint 3 :Familiarity with LANGCHAIN and llama index
Checkpoint 4 : Implement the code to run the open source LLMs
Checkpoint 5 : RAG implementation and optimization and show user interface with Gradio.",ML
167,Varun Sawant 22B2502,Financial Modelling,"Akshat Thakur(22b2110) , Aditya Vema Reddy Kesari (22b3985)",Financial Modeling,"Mentees will be learning Financial Modelling using mathematics and statistics. They will learn pricing models for Futures, Forwards and Options and bond valuations. These models can then be coded into python and used for forecasting. Explore market trends and forecast using these financial models , find out arbitrage opportunities in the markets and capitalize on them. 

Its a great way to explore Quantitative Finance Domain.",9,,projects/default.png,https://drive.google.com/drive/folders/16Ubb12sUGxM1loYJ3Gu4Y0KhoBwpeQe5?usp=drive_link,https://docs.google.com/document/d/1NYQ8F7swRuVGc9g1YDD1mmaOaPAgYhX3j4lF9sLZRc4/edit?usp=drive_link,https://docs.google.com/document/d/1UoJYHgD3y0BZ-x6zX8K_ME10KdVsE0teDYoRAbnQ02o/edit?usp=drive_link,Others
168,Vatsal Melwani 22B0396,SnakeRL,Husayn Bootwala,Reinforcement learning,"The project will involve reinforcement learning on the classic snake game. This will first involve replicating the game using pygame, and then applying RL to it. Here is a link https://github.com/eidenyoshida/Snake-Reinforcement-Learning",6,"Basic coding knowledge in python. Most importantly, applicant should be enthusiastic about learning.",projects/default.png,https://drive.google.com/file/d/1ak-83eqsW2S6lUK4Nvj-kVQfuPwfZhAG/view?usp=drive_link,"1) week 1- Brushing up the basics
2) week 2- Markov Chains and basics
3) week 3, 4 and 5- Learning RL and maze solver
4) week 6- Learning PyGame and replicating snake game
5) week 7 and 8- Implementing the final project and training the agent
Extra: If someone completes early, they can also try on the flappy bird game.","checkpoint 1: Basics and Markov Chains
checkpoint 2: Learning RL and maze solver questions
checkpoint 3: Replicating the snake game
checkpoint 4: RL algorithms like monte carlo, TD learning, etc.
checkpoint 5: Traing the RL + final demo",Others
169,Ved Parulekar 22b2429,Machine Learning & Game Theory for Real-World Application,Vishrut Nikunj Mittal (22b2427),Machine Learning,"Description: This project dives deep into data science and machine learning. It builds a strong foundation in linear algebra (NumPy) and data manipulation (Pandas) before tackling machine learning algorithms (Scikit-Learn) and addressing overfitting through regularization techniques.  The exploration continues into deep learning with feedforward neural networks and convolutional neural networks, then expands to game theory, including both sequential and simultaneous games, applied to real-world examples like Poker and Chess. Overall, this project provides a comprehensive understanding of essential tools and techniques across various data science and machine learning domains.

References:  ""Game Theory"", Michael Maschler, Eilon Solan, Shmuel Zamir, Cambridge University Press. 

Link to CS6001(GameTheory):https://www.cse.iitb.ac.in/~swaprava/cs6001_07_2023.html

Learning from Data: A Short Course , Book by Yaser Abu-Mostafa

An Introduction to Statistical Learning
By  Gareth M. James, Daniela Witten, Trevor Hastie, Robert Tibshirani",Around 15-20,,projects/default.png,https://drive.google.com/file/d/1FHkGnz0Cu7vcKH_7NCvhxKWyX71NHYM-/view?usp=sharing,"Week 1:
Implementation of Basic Linear Algebra using numpy arrays.
Understand input of data using pandas.
Go through Scikit-Learn

Week 1-2.5 :
Basic ML Algorithms 
Regression- Linear and Multivariate:
K Means Clustering, KNN, Naive Bayes.

Week 2.5-4.5:
 Noise and its Various  Types
Noise Identification and Cleansing 
Overfitting and Regularization
Midterm Project

Week 4.5 -5.5:
FNN to understand Neural Networks.
Image Processing using CNN.
For grammar Prediction (RNN)

Week 5.5 -7:
Game Theory
Sequential games
Simultaneous games
Poker and Chess, X and O

Week 7-8: Time for doing the final project based on code implementation and optimization of a few simple Game Theory algorithms.","Project Machine Learning:
Checkpoint 1: 
Implement basic matrix operations with NumPy and data input methods using Pandas.
These Ffnctions will be used in your checkpoint 3 ,

Checkpoint 2:
Build linear and multilinear regression models from scratch. Additionally, craft algorithms for K-Nearest Neighbors (greedy approach), K-Means clustering, and Naive Bayes classification – all without relying on external libraries.
These functions will be used in your checkpoint 3

Checkpoint 3:
Implementation of the following problems statement:
Chemical Plant CSI: Can you be a data detective? Use machine learning to clean noisy sensor data and optimize plant operations.

Checkpoint 4:
Create neural networks from scratch, develop an RNN for autocomplete, and construct a CNN for image processing.

Project Game Theory:
Checkpoint 5: 
Code sequential games such as Tic Tac Toe and Chess with optimizations like alpha-beta pruning, and implement algorithms for simultaneous game theory such as Randomized Greedy Algorithm.",ML
170,Vidyanand kumar 22B2171,"1) Predictive Maintenance, 2) Fraud detection","Rishu kuamr (22B2130), Ayush Jadia (22B0407)",Machine Learning,"Build a model that predicts when machinery or equipment is likely to fail so that maintenance can be performed proactively. This could be applied to various industries such as manufacturing, aviation, or healthcare.
Learning :- 1) Understanding of Domain Knowledge,
2) Data Collection and Preprocessing, 
3) Feature Selection and Engineering
4) Model Selection and Evaluation
5) Handling Imbalanced Data
Deployment and Integration

Datasets :- Kaggle
Online courses and tutorials :- Youtube, Coursera and Udemy
GIthub link:- https://github.com/ayoubouaja/Predictive-Maintenance-Project-MLOPS
",6,,projects/Predictive Maintenance.jpeg,https://drive.google.com/file/d/1IQPJshG2bQlN9dvz9FBEC6iJZuHfKHnQ/view?usp=sharing,"Week-wise timeline for completing a predictive maintenance project over a span of 7-8 weeks:

Week 1: Project Planning and Data Collection
 Day 1-2: Define project scope, objectives, and deliverables.
 Day 3-4: Identify relevant datasets and sources for predictive maintenance.
 Day 5-7: Collect and download the selected datasets. Begin exploratory data analysis (EDA) to understand the data structure and quality.

Week 2: Data Preprocessing and Feature Engineering
 Day 1-3: Clean and preprocess the collected data (handling missing values, outliers, etc.).
 Day 4-5: Perform feature engineering to create new features or extract meaningful 
 information from raw data.
 Day 6-7: Conduct further EDA to visualize relationships between features and target variables.

Week 3: Model Selection and Training
 Day 1-3: Choose appropriate machine learning algorithms for predictive maintenance tasks (e.g., regression, classification, time series forecasting).
 Day 4-5: Split the dataset into training and testing sets. Train initial models on the training data.
 Day 6-7: Evaluate model performance using appropriate metrics and iterate on model selection and hyperparameter tuning.

Week 4: Model Evaluation and Validation
 Day 1-3: Validate model performance using cross-validation techniques to ensure generalizability.
 Day 4-5: Fine-tune models based on validation results and analyze errors or discrepancies.
 Day 6-7: Document findings, strengths, and limitations of the selected models.

Week 5: Deployment Preparation
 Day 1-3: Prepare for model deployment by finalizing preprocessing steps, feature scaling, and model serialization.
 Day 4-5: Develop a plan for integrating the predictive maintenance model into existing systems or workflows.
 Day 6-7: Create documentation and instructions for deploying and using the model.

Week 6: Model Deployment and Testing
 Day 1-3: Deploy the predictive maintenance model in a test environment or on a small-scale dataset.
 Day 4-5: Conduct thorough testing to ensure the model functions correctly and produces reliable predictions.
 Day 6-7: Address any issues or bugs encountered during deployment and testing.

Week 7: Performance Monitoring and Optimization
 Day 1-3: Implement monitoring mechanisms to track model performance and detect deviations from expected behavior.
 Day 4-5: Analyze model performance over time and identify opportunities for optimization or refinement.
 Day 6-7: Optimize model parameters, feature selection, or data preprocessing steps based on monitoring results.

Week 8: Finalization and Presentation
 Day 1-3: Finalize project documentation, including code, models, reports, and presentations.
 Day 4-5: Practice delivering a presentation summarizing the project objectives, 
 methodology, results, and conclusions.
 Day 6-7: Present the completed predictive maintenance project to peers, instructors, or stakeholders and gather feedback.","Checkpoint 1: Data Preparation and Exploration
Checkpoint 2: Feature Engineering and Model Selection
Checkpoint 3: Model Optimization and Validation
Checkpoint 4: Deployment Preparation and Testing
Checkpoint 5: Performance Monitoring and Presentation",ML
171,Vijay Balsubramaniam 21D180043,Demon Slayer AI: Mastering Doom with Reinforcement Learning,",",Deep Learning,"If you're not sure where to begin your journey in Machine Learning, Reinforcement Learning is a great place to start! Reinforcement Learning teaches AI agents to perform better based on feedback from their past performance - a technique that has given birth to superhuman intelligence in chess and has mastered self-driving vehicles. Safe to say, it's all the buzz in today's AI landscape! In this project, we will aim to apply RL methods to train an AI to play Doom [1993 GBA], which will hopefully illustrate the sheer robotic power vested in the laptop in your bag.


If you want a flavour of RL, I recommend you watch the video lecture 1 in the link below.
 

Takeaways from this project:
- Understanding RL algorithms and the sound mathematical basis they are grounded in
- Setting up scalable ML projects, moving them around and building on top of Open-Source projects (you might underestimate the value of this point, but this will make you a pro!)
- Being able to code your own neural networks
- You create an AI agent that kills demons >:)
- A look at the current work in RL and where you could go from here


As a wise programmer once said, ""ML is 2% coding and 98% debugging"". You'll learn to handle frustrating errors and you'll master the art of deftly tuning hyperparameters to extract maximum benefits from your AI agent. All while actually learning something that's meaningful and widely in demand. You'll gain the most if you're a beginner in Reinforcement Learning or have no knowledge of this domain.


For theory, we will follow the following sources:
Textbook: https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf
Video Lectures: https://youtu.be/2pWv7GOvuf0?si=gzh3qQVcJt8OIHVT


Coding tasks will be based on the theory covered during the week.
There are 7 theory goals, one each week and 5 coding skill checkpoints.",16,"Bare minimum pre-requisites:
- Basic knowledge of python (if you have no idea about python, look at a tutorial right now, it's quickly learnable; we'll revisit important python concepts in week 1)
- Enthu (important)
- Interest in understanding the math that governs algorithms and neural nets (it can get a bit overwhelming, but it isn't too hard)
- Enthu (iske bina nahi chalega)
- Patience to debug code that throws 420.69 errors per minute
- Enthu (non-negotiable)


Any other skills you bring to the table are nice but are not hard pre-requisites. Please mention these in your SoP.


What your SoP should have:
- Why you want to choose this specific project
- Your current skill level
",projects/default.png,https://drive.google.com/drive/folders/1uE25w_lLxa_8AdUnY8uyahTMkYpehdzY?usp=sharing,"Week 1:  Catching up with Python and Probability Theory
Week 2:  Multi Armed Bandits - The first step to RL
Week 3:  Markov Decision Processes and Bellman's Equations 
Week 4:  Model Free Prediction and Control
Week 5:  Introduction to Neural Networks and Deep Learning
Week 6:  Policy Gradient Methods, Playing Doom 
Week 7:  Review of State-of-the-Art methods in RL and applying to Doom.
","Checkpoint-1: Implementation of Algorithms to play Multi Armed Bandits
Checkpoint-2: Implementing Markov Decision Processes in Python
Checkpoint-3: Coding Q-Learning and simple RL methods
Checkpoint-4: Writing your own Neural Networks for Deep Q-Learning
Checkpoint-5: Training a model to play Doom",ML
172,Vijay Kulhari 22B3001,Competitive Programming Bootcamp,Neeraj Bajiya (22B3026),Competitive Programming,"Organize a structured bootcamp program where you cover different topics in competitive programming over a period of several weeks. Include lectures, problem-solving sessions, practice contests, and individualized feedback sessions.",10,Basics Of Python,projects/images.jpeg,https://drive.google.com/file/d/1ZCfGv1rZXU1StvftY0LnKI4FlU5Y3JAp/view?usp=sharing,"1. Pre-Bootcamp Preparation- 1 week
2. Lectures and Workshops- 2 week
3. Problem-Solving Sessions- 1 week
4. Practice Contests- 2 week
5. Individualized Feedback and Progress Tracking- 1 week","1. Pre-Bootcamp Preparation
2. Lectures and Workshops
3. Problem-Solving Sessions
4. Practice Contests
5. Individualized Feedback and Progress Tracking",CP
173,Vikash Chahar  22B3034,Recommender System ,Sahil Choudhary (22B3034),Machine Learning,"Recommendation systems track user preferences and behavior to predict and recommend items or services. This project covers the essentials of recommendation systems.It includes data preprocessing ,vectorization and streamlit. Recommendation system are of two type  content based and collaborative based. If you want to explore more about this you can use 
( https://www.nvidia.com/en-us/glossary/recommendation-system/#:~:text=A%20recommendation%20system%20is%20an,demographic%20information%2C%20and%20other%20factors. ) for more information.",8-10,No prerequisites but basic knowledge of python will be good ,projects/recommender_system.jpg,https://drive.google.com/file/d/1JKBj0prndPtxwau0cIMZLjtXAp7sjJTd/view?usp=sharing,"Week 1: introduction of recommendation system and installation of Jupiter notebook
Week 2-3: data preprocessing
Week 4: Vectorization
Week 5: define main function which recommend
Week 6: understanding of streamlit
Week 7-8 : deployment ","Checkpoint-1: understanding of recommendation system
Checkpoint-2: Data preprocessing
Checkpoint-3: Vectorization and define main function 
Checkpoint-4: understanding frontend/streamlit
Checkpoint-5 : deployment",ML
174,Yash Bhake 22B2148,MusGen- Generate music using Deep Learning,Karrthik Radhakrishnan (22B2237),Deep Learning,"Constantly listening to music? enthusiastic about music and ml?? We have the perfect intersection of music and deep learning- music generation using Deep Learning.

We intend to create a Music Generation model trained on a music database, using deep learning, specifically RNNs and LSTMs, developing a suitable architecture to implement these models and amending the code in a way, such that the generated music is coherent with some major music theory concepts, such as key, time signature and basic resolution. 

Initially, the project involves a lot of data preprocessing, as we first have to gather appropriate music training data and pre-process it in a form (transposing to one key, maintaining one level of note, and rhythm complexity, maintaining a max time duration etc.) which can be fed to the LSTM. Once a melody is generated, we will analyse it and make alterations to increase the coherency and aesthetics of the music generated.

Once we have a decent melody, if time permits, we will use mir (music information retrieval) techniques to track tempo and beat onsets. A fun application would be to make an Instagram reel with your original generated music and images matching the rhythm of the piece (any song for that matter). I hope it would be a fun experience to 

Check out the following article for the gist of the project-

https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5 - Article on generating music using LSTM model

https://github.com/jordan-bird/Keras-LSTM-Music-Generator - repo implementing this paper.

https://www.youtube.com/playlist?list=PLTzZ8gHUBuyp5BeqUTBp29dZHMXuclyFW - YouTube playlist, we will be updating for resources.

Other links and documents would be maintained on Notion and Google Docs and coordinated with the mentees.
",5-7,"Basic to intermediate Python, (also the ability to efficiently use LLMs to get your code working), Basic Machine learning knowledge and basic music theory would make it much smoother.",projects/image_fx_a_programmer_writing_code_and_lyrics_of_a_son.jpg,https://drive.google.com/file/d/1vIRlqfv1fZK0BM6U7p3NKhSE0Z4H6USk/view?usp=sharing,"Week 1- Introduce the project and the process pipeline. basic ML and music theory

Week 2&3 - Provide resources to learn LSTMs and RNNs and an assignment based on them to be submitted at the end of week 3.

week 4 - understand the implementation of LSTMs and RNNs in music, and musical data encoding, with an assignment on training an LSTM model on simple time series data (can be any time series)

week 5 - Data collection and preprocessing, everyone will be engaged in collecting music data suitable to our use, and then pre-processing it to bring it in a form that is feedable to the models. 

week 6 & 7 - Formulate and implement an architecture of LSTMs and RNNs on the processed music training data. Then analyse the generated music. tweak parameters and amend the program such that it is coherent with basic music theory concepts such as time signature and key. Programming will be done along with the mentees

week 8 - tempo and beat tracking of the musical piece, using mir (music information retrieval) techniques (This will be done once we are fairly satisfied with the music generated if time permits) with an assignment on tempo tracking, and let the mentees try to make a reel using their generated music and add images in rhythm.","Checkpoint-1: Data collection and formulation of a music database with appropriate data and processing on broad parameters like duration

Checkpoint-2: Data pre-processing on finer parameters like note, rhythm complexity, scale, and vectorisation to make it feedable to the LSTM

Checkpoint-3: Implementing a developed RNN and LSTM architecture and other processing to train on the training set, and generate music

Checkpoint-4: Tweak parameters and amend the code to make the generated music more coherent with music theory topics

Checkpoint-5: Implement tempo and beat tracking on the generated pieces.",ML
175,Yash Gupta 22B1813,Quantum Symphony: Orchestrating Machine Learning in the Quantum Realm,"Saarthak Krishan (22B3959), Aditya Singh (22B1844)",Quantum Machine Learning,"You must have heard the word Quantum and also about Machine Learning. We present to you Quantum Machine Learning. In this project you would be introduced to concepts of Quantum Information and Computing, traversing from introduction to qubits to quantum circuits and finally to quantum algorithms with the primary reference being online IBM-Qiskit Textbook and QCQI by Michael A.Nielsen and Issac L.Chuang. The progress of the mentee will be checked by weekly assignments using qiskit library in python.
Then we will move on to Introduction to Machine Learning, with various lectures and notes chosen with experience as the reference. There will be a mid-term assignment which will test your understanding till now and also prepare you for the upcoming weeks which are relatively challenging.
Subsequently the mentee can choose from either Quantum Deep Learning or Quantum Reinforcement Learning. Finally the project ends with the application of the knowledge gained by implementing one of the research papers given by us.
More in-depth resources will be provided as the project goes on.",8-10,"Does not have a fear of QM and Linear Algebra from the first year courses, Comfortable with using Python. Knowledge of basics of machine learning is appreciated but not necessary.",projects/default.png,https://drive.google.com/file/d/1HEeTuZKEDvp9McM1KAOM8ztjloYAMQeN/view?usp=share_link,"Week 1: Basics of Quantum Mechanics and Linear Algebra (Not your 1st year MA and PH courses), Introduction to Qubits and Qiskit
Week 2: Quantum Gates and Circuits, Phase Kickback, QFT
Week 3: Quantum Algorithms - DJ,  BV,  Simon's, Grover's and Shor's
Week 4: Introduction to Machine Learning - Regression, Classification, SVMs
Week 5: Machine Learning continued: Neural Networks / Reinforcement Learning
Week 6: Introduction to QML, Mid-term Assignment
Week 7: Advanced topics in QNNs / QRL
Week 8/9: Implementing the Research paper of your choice","Checkpoint 1: Understanding and implementing Quantum Algorithms in python
Checkpoint 2: Implementing basic ML algorithms in python
Checkpoint 3: Mid-term assignment 
Checkpoint 4: Getting comfortable with concepts of QML
Checkpoint 5: Completion of the project by implementing the research paper",ML
176,Yash Jonjale 22b0990,Computational Biology for Beginners,None,Computational Biology,"Computational biology is an interdisciplinary field that applies computer science techniques to understand and model complex biological systems. It involves the analysis of biological data and the development of algorithms to predict or simulate biological processes. 

This is a beginner-level project, majorly for freshies. We will be focusing on only two aspects - systems biology and genomics. No worries if you don’t know Python. We will be covering that, too. In systems biology, we will do Flux balance analysis and Population modelling, and in Genomics, we will focus on Sequence Alignment.

Videos for reference: 
https://youtu.be/fuVVCvDKcKg?feature=shared
https://youtu.be/MvuYATh7Y74?feature=shared
https://youtu.be/AhsIF-cmoQQ?feature=shared


For queries, contact: Yash Jonjale (9137088561) 
",10-12,Basic programming skills and tons of enthusiasm,projects/1_8XSOdpRkyV4BC7E3yKqXZA.jpg,https://drive.google.com/file/d/1DFF09CfY-2GCJnvSU5Pf5yRwsTDeQzXB/view?usp=sharing,"Week 1: Basic Microbiology, 
Week 2-3: Python, Biopython, BLAST
Week 4: Metabolic Flux Analysis, Reading basic papers, Cobrapy
Week 5: Reading Advanced Papers on FBA and their implementation
Week 6-7: Sequencing Algorithms
Week 8-9: Population Modelling","Checkpoint 1: Microbiology Basics
Checkpoint 2: Python Programming and relevant libraries
Checkpoint 3: Flux Balance Analysis 
Checkpoint 4: Sequencing Algorithms
Checkpoint 5: Basic population modelling",Others
177,Yash Santosh Jonjale 22b0990,Semantic Segmentation using Vision Transformers,Tanmay Gejapati (22b0969),Machine Learning,"Semantic segmentation is a computer vision task where the goal is to classify each pixel in an image into a specific class/category, effectively dividing the image into segments or regions based on the semantic meaning of the objects present. Semantic segmentation is crucial in various applications, including autonomous driving, medical image analysis, satellite image analysis, and more. 

Our project will revolve around Brain Image Segmentation or Microscope Image Segmentation depending on the interests of the mentees. This will be a intermediate+ level project. We expect decent programming skills and familiarity with implementing basic machine learning models like Neural Networks. We will discuss the projects in slack. 

Videos on Transformers (3b1b 🙂): https://youtu.be/wjZofJX0v4M?feature=shared
https://youtu.be/eMlx5fFNoYc?feature=shared

Semantic Segmentation: https://youtu.be/aNAZxV8yQHM?feature=shared

For queries contact: Yash Jonjale (9137088561) 
Tanmay Gejapati (9632672825)
",10,"Programming, Python, Libraries like Numpy, etc., Machine Learning including Neural Networks and Backpropagation, Familiarity of Implementing Basic Neural networks in any framework(Pytorch/Tensorflow/Numpy)",projects/BeFunky-collage.jpg,https://drive.google.com/file/d/11rUFO2xZO2aVnDbnT2rHc7O-gUZCdInM/view?usp=sharing,"Week 1, 2 : Machine Learning Refresher ( NNs, CNNs, RNNs, LSTMs, Clustering, Backpropagation, Pytorch )
Week 2, 3 : Understanding and Implementing Transformers
Week 4, 5 : Understanding and Implementing Vision Transformers
Week 6: Reading Papers
Week 7: Conceptualising and implementation of models
Week 8: Implementation and Training of Models
Week 9: Further Tuning the model","Checkpoint 1: Deep Learning Review
Checkpoint 2: Transformers
Checkpoint 3: Vision Transformers
Checkpoint 4: Reading Papers
Checkpoint 5: Implementing and Training the Model
",ML
178,Yash Toshniwal 22b0307,Grader Bot,none,Natural Language Processing,"The project will be a collaborative one which focuses on the development of an innovative grader bot designed to evaluate subjective answers. This tool integrates Generative AI (Gen AI) with advanced Machine Learning (ML) models, particularly in Natural Language Processing (NLP), to assess and grade written responses. Unlike conventional grading systems that rely on keywords or predefined patterns, our approach aims to understand the context, creativity, and depth of student answers, making the grading process more nuanced and reflective of human evaluation.

The primary objective is to create a prototype of a grader bot that mimics human grading capabilities for subjective answers. This involves understanding the semantics of the text, evaluating the quality of content, and providing fair, unbiased grades. The final aim is to produce a working prototype that leverages insights and methodologies from existing research papers in this domain, ensuring the solution is both innovative and grounded in proven scientific principles.",5,"Machine Learning & NLP Foundations: Participants are expected to have a foundational understanding of machine learning and natural language processing. This includes a basic familiarity with concepts such as neural networks and language models (e.g., GPT-3), as well as introductory knowledge of sentiment analysis and other NLP techniques.

Programming Proficiency: A good grasp of programming languages, particularly Python, is necessary. This includes working knowledge of essential libraries and frameworks that are commonly used in AI and ML projects, such as TensorFlow or PyTorch, and basic NLP libraries like NLTK or spaCy.

Research Skills: The ability to engage with and understand research materials in the fields of AI, ML, and NLP is important. Participants should be comfortable translating theoretical concepts from research papers into practical applications, even if on a more fundamental level.",projects/DALL�E 2024-04-08 20.53.05 - Craft a banner i ... evaluating subjective answers. This ima.webp,https://drive.google.com/file/d/1ZFVQP2NmUqDc9956FRyQapZsqGPXkmOX/view?usp=sharing,"Week 1-2: Foundation and Research
Objective: Build foundational knowledge in NLP and generative AI. Review and analyze relevant research papers.
Sub-tasks:
Week 1:
Introduction to basic concepts in NLP and generative AI.
Begin exploring online courses and tutorials.
Select a list of pivotal research papers to review.
Week 2:
Deep dive into selected research papers.
Weekly discussion to share insights and key learnings.
Start drafting reports on each paper, focusing on methodology, findings, and potential applications to our project.
Week 3-4: Model Design and Data Analysis
Objective: Initiate the development of the model's architecture and analyze existing data while seeking additional datasets.
Sub-tasks:
Week 3:
Sketch the initial workflow and architecture of the model.
Begin analysis of the provided dataset to understand its structure and content.
Research and identify potential sources for additional data.
Week 4:
Finalize the model workflow and detailed architecture.
Complete data analysis and begin data preprocessing.
If new data sources are found, start the acquisition and integration process.
Week 5-6: Development and Assembly
Objective: Commence coding the model components and integrate them into a working prototype.
Sub-tasks:
Week 5:
Start coding individual components of the model based on the defined architecture.
Regular coding sessions and reviews to ensure alignment and progress.
Begin integrating components into the initial prototype.
Week 6:
Continue coding and integration efforts.
Complete the assembly of the model into a functional prototype.
Perform initial testing to identify major issues.
Week 7-8: Testing, Tuning, and Evaluation
Objective: Conduct comprehensive testing, fine-tune the model, and evaluate its performance against benchmarks.
Sub-tasks:
Week 7:
Begin exhaustive testing of the model for various scenarios.
Identify areas for improvement and start fine-tuning the model.
Start documenting the testing process and initial results.
Week 8:
Continue fine-tuning the model based on test feedback.
Finalize performance evaluation, comparing results with those mentioned in relevant research papers.
Prepare a comprehensive report detailing the development process, testing methodologies, results, and areas for future research.","Checkpoint 1: Completion of Foundational Learning and Research Review
Timing: End of Week 2
Criteria:
All team members have completed foundational learning in NLP and generative AI.
Research papers have been thoroughly reviewed, with reports summarizing methodologies, findings, and applicability to our project completed.
Initial brainstorming on how research findings can influence our project approach has been conducted.
Checkpoint 2: Model Architecture and Data Analysis Completion
Timing: End of Week 4
Criteria:
The initial model workflow and architecture have been fully defined and documented.
Comprehensive analysis of the provided dataset is completed, with data preprocessing underway.
Additional data sources have been identified and integrated into the project (if applicable).
Checkpoint 3: Prototype Development and Integration
Timing: End of Week 6
Criteria:
Coding of individual model components is finished, with initial integration testing begun to ensure they work together as expected.
A working prototype that incorporates the core functionalities of the grader bot is developed.
Early stage testing to identify and rectify major integration or functionality issues has been initiated.
Checkpoint 4: Initial Testing and Fine-Tuning
Timing: Mid Week 7
Criteria:
The prototype has undergone initial rounds of testing, with data on performance and any issues documented.
Fine-tuning of the model based on initial testing feedback is in progress.
Adjustments to improve accuracy, efficiency, and user experience are being implemented.
Checkpoint 5: Final Evaluation and Documentation
Timing: End of Week 8
Criteria:
Comprehensive testing is completed, with the model fine-tuned for optimal performance.
The model's performance has been evaluated against benchmarks and findings from research papers, with results ready for presentation.
A final report detailing the development process, testing methodologies, performance evaluation, and recommendations for future improvements is prepared and ready for dissemination.
These checkpoints serve as critical markers of progress, enabling the team to systematically approach the project, assess outcomes, and make necessary adjustments to meet the final project objectives efficiently.",ML
179,Yuvraj Khandelwal 22B0725,Game Automation of Chrome Dino,Daksh Soni (22B2150),Machine Learning,"Ever wished you could conquer the Chrome Dino game without lifting a finger? We're working on just that! Our project combines cutting-edge tech like Convolutional Neural Networks (CNN) and Deep Reinforcement Learning (RL) to teach an AI how to play the game like a pro. Picture this: a virtual dino that learns from its mistakes, jumping over cacti and ducking under obstacles with finesse. We're collecting tons of gameplay data, training our AI to make split-second decisions just like a human player would. But it's not all about the tech – it's about pushing the boundaries of what's possible, creating something that's not only fun but showcases the power of artificial intelligence. Join us on this adventure as we revolutionize gaming and AI, one Chrome Dino jump at a time. ",6,Interest in Machine Learning and Enthusiasm.,projects/Reinforcement Learning.jpg,https://drive.google.com/file/d/1O1d7UrF1BMaJG21JdFroKPxBd_xJk9TS/view?usp=sharing,"Week 1 : Learning basics of python for ML
Week 2-3 : Learning basics of ML & RL
Week 4 : Learning Pytorch 
Week 5 : Learning CNN and implementing it with Pytorch.
Week 6-7 : Implementation and training of Model for automation of Chrome Dino","1. Learning implementation of ML and RL models.
2. Model Architecture design.
3. Training pipeline implementation.
4. Environment Integration and Action Space Definition.
5. Evaluation and Fine-Tuning.",ML
180,Ashwin Goyal  210050024,Simulating Natural Selection and Decision Making,Aditya Nemiwal (210050024),Simulations,"

We plan to introduce the mentees to simulation using Python, following with applying it to the various number of theoretical scenarios related to natural selection and evolution of species. The major focus would be on developing a framework to code realistic scenarios (like competition, prey-predator, natural selection due to random mutations etc.) and then verify the results with theoretical models (where available). The last few weeks will go forward to develop a GUI or create a toy setup to observe actual events.

Links to something similar that we will use as a reference are as follows:

https://youtube.com/playlist?list=PLKortajF2dPBWMIS6KF4RLtQiG6KQrTdB&feature=shared",4-8,"Applicants should be willing to put in some hard work, particularly if their current background with coding is not strong. Other than that basic python skills are helpful but not necessary.",projects/Screenshot 2024-04-11 at 3.24.56 PM.png,https://drive.google.com/file/d/1x0kuUKHiuLLaO9YEO7l5ynf4_dbQ6MJO/view?usp=sharing,"1.
Introduction to Python (Krittika notebooks 1-4. JS notebooks 1-4)

2.
Game Theory simulations according with different scenarios (dominant strategies, nash equilibrium, percent of players playing with certain strategy (deterministic)) (Primer Video)

3.
Initial simulation of a chemostat, with random sampling for the next generation. Observation of genetic drift, mutation rates, wave model etc. (Content from CL717 course)

4.
Making the model concrete, creating beings with simple traits like size, speed etc and food particles. Viewing overall changes in traits ( refer primer video - simulating natural selection)

5.
Multiple species, simulating competition. Prey-predator behaviors. cooperation strategies and decision making( Reference - primer videos ) 

6.
Buffer period for catching up, creative ideas to be discussed on where the project should go as a final goal. 

7,8
Move according to what was discussed in week 6. Possible places to go - stability of ecosystems, implementing research papers on the topic, animating the simulations to make them more engaging, any other online simulation ideas they get in this framework
","1. Completion of python notebooks and game theoretic background.

2. Simulations of chemostat from cl717 course

3. Basic simulations with specific traits

4. Advanced simulations with multiple species

5. Final goal as decided in week 6.",Others
181,Priyanshu Gupta 210070064,Basics of Competitive Programming,"Divyansh Singhal (210050045), Atharva Tambat (210070014)",Competitive Programming,"Our program will guide you through the basics and foundational aspects of competitive programming algorithms, making it a great starting point for those who want to get into CP and aim to reach intermediate levels.",10-12,"Basic Programming skills, Basic C++ (CS 101 is enough)",projects/default.png,https://drive.google.com/file/d/159eMGwyJYa741bnhTR7lCHaikL7H96mm/view?usp=share_link,"Week 1	C++ STL Basics + basic math algorithms
Week 2	Sorting and Searching + brute force
Week 3	Graph Algorithms - bfs + dfs + recursion
Week 4	Dynamic Programming + Divide-Conquer and Greedy Paradigms
Week 5	Buffer to catch up + practice contest 1 across all mentees
Week 6	Graph Algorithms - shortest path algos + tree algos
Week 7	Range Queries
Week 8	Attempt codeforces virtual contests + practice contest 2 across all mentees + discussion","Checkpoint-1: C++ IDE Setup and basic STL Reading
Checkpoint-2: Week 2 
Checkpoint-3: Practice Contest 1
Checkpoint-4: Week 6
Checkpoint-5: Practice Contest 2",CP
182,Ayush Agarwal 210050029,Python Interpreter in C++,"Abhijit Amrendra Kumar (210050002), Sankalan Baidya (210050141), Kartik Nair (210050083)",Compiler Design,"Unlock the secrets of Python's inner workings with our immersive journey into the Python interpreter written in C. Dive deep into lexing tools like Flex and parsing tools such as Bison as we bridge the gap between high-level Python code and low-level assembly language. From exploring primitive data types to mastering container data structures like lists, dictionaries, and tuples, our project offers a comprehensive understanding of Python's internal mechanisms. Join us as we unravel the mysteries of Python and elevate coding to new heights, all while discovering the art of compiler optimization. Are you ready to decode Python's magic?",8,"Familiarity with C++ abstractions, classes and inheritance and pointers is a must. Some knowledge of data structures is preferred.",projects/interpreter.png,https://drive.google.com/file/d/1wpO8y8gCbG-aeBo0jZlh2KTcYJsIaa9S/view?usp=sharing,"1 - Introduction to Compilers and Lexical Analysis
2 - Lexical Analysis and Introduction to CFGs
3 - Basics of Parsing
4 - Abstract Syntax Trees (AST)
5 - Semantic Analysis
6 - Bytecode Generation
7 - Execution and Interpreter Development
8 - Compiler Optimizations (optional)","- Foundations of Compilers and Lexical Analysis (1.5 weeks)
- Lexical Analysis and Parsing (1.5 weeks)
- Abstract Syntax Trees (AST) and Semantic Analysis (2 weeks)
- Bytecode Generation and Execution (1.5 weeks)
- Interpreter Development and Optimization (1 week)",Others
183,Mugdha Bilotia 22b1009,Vision Venture: Exploring the world of computer vision,Anushka Bhoir (22b0937),Computer Vision and Image Processing,"From facial recognition for phone unlocking to enabling autonomous vehicles, Computer Vision (CV) is everywhere. This project aims to provide you with the essential tools to begin exploring the world of CV.

The project is divided into two phases. The first month will focus on Image processing. Initially, we will cover the basics of Fourier transformation and gradually advance towards understanding spatial-temporal filters, hybridization of images and multi-scale pyramids. 
The second phase encompasses digital video processing. We'll explore and implement Motion Magnification—a technique that enhances subtle motions in video sequences, making them more visible to the human eye.

All programming will be done in Python using libraries like NumPy, Matplotlib, OpenCV (cv2), and SciPy. (don't worry if you are hearing these names for the first time, we will provide you tutorial for every library :) ). You'll have access to ample resources and sufficient time to complete the assignments, ensuring a thorough learning experience.",8-10,"All you need is a dash of curiosity and enthusiasm, along with the basic linear algebra knowledge from your first year :)",projects/default.png,https://drive.google.com/drive/folders/1UUDKVVxv3KsbdN3t6hO--vES7zPogz7Y?usp=drive_link,"Week 1: Brush up on Python and its libraries NumPy and Matplotlib
Week 2: Introduction to Signal Processing: Fourier Transformation (DFT), Convolution, Inverse Fourier Transforms, Correlation
Week 3: Introduction to Image Processing Methods and Their Python-based Implementation: Per-pixel Transformation, 2D Correlation, (Optional) Seam Carving (No libraries will be used for this part to grasp the underlying essence)
Week 4: Continuation of Week 3 Assignments and Using NumPy to Create Desired Images by Altering the Fourier Domain
Week 5: Spatial Linear Filters, OpenCV Tutorial, Using Spatial Filters to Hybridize and Dehybridize given Images
Week 6: Temporal Linear Filters and Multiscale Pyramids, Implementation of Motion Magnification on Videos Using Two Techniques.
Weeks 7-8: Final Assignment Wrap-up and Documentation.","Checkpoint 1: Brush up on Python and introduction to signal processing
Checkpoint 2: Implementation of image processing methods from scratch
Checkpoint 3: Implementation of image processing methods using python libraries
Checkpoint 4: Implementation of hybridization and dehybridization of images
Checkpoint 5: Final assignment of implementation of motion magnification with two techniques",ML
184,Sreekar Reddy  22B1274 ,Graph Neural Network models for network analysis and generation ,"Hardik Gohil (22B1293), Madhava Sriram (22B1233), Banoth Preetam (22B1254)",Deep Learning,"This project aims to explore the application of Graph Neural Networks (GNNs) in network analysis tasks, including node classification, link prediction, and graph generation. Over the course of two months, the project will cover foundational concepts in graph theory and GNNs, implementation of GNN models for node classification and link prediction, and exploration of GNN-based graph generation techniques. By the end of the project, the goal is to develop a deep understanding of GNNs and their potential applications in analyzing and extracting insights from complex networks such as social networks, citation networks, and biological networks.",5-6,Basic Python (unless you are Harry Potter),projects/1000148866 (738�415),https://drive.google.com/file/d/1jS2mYPUZpO0emv4-LKuCNVKZKjdRgiYh/view?usp=sharing,"Week 1:
Objective: Gain a solid understanding of graph theory fundamentals, including concepts like nodes, edges, and graph representations.
Tasks:
    Study introductory materials on graph theory, including textbooks, online courses, or lecture notes.
    Familiarize yourself with common graph representations, such as adjacency matrices and edge lists.
    Research the basics of neural networks and how they can be applied to graph data.

Week 2:
 Objective: Understand the basics of Graph Neural Networks (GNNs) and their architectures.
 Tasks:
     Study foundational papers and tutorials on GNNs, such as the Graph Convolutional Network (GCN) paper by Kipf and Welling.
     Implement basic GNN models (e.g., GCN) using PyTorch on simple datasets.
     Validate the implementations by reproducing results from existing research papers.

Week 3:
 Objective: Implement GNN models for node classification tasks on real-world datasets.
 Tasks:
     Obtain and preprocess graph datasets suitable for node classification, such as social networks (e.g., Facebook, Twitter) or citation networks (e.g., Cora, Citeseer).
     Implement GNN models (e.g., GCN, GraphSAGE) for node classification using the chosen datasets.
     Train and evaluate the models using standard evaluation metrics like accuracy, precision, and recall.
 
 Week 4:
 Objective: Fine-tune and optimize GNN models for node classification tasks.
 Tasks:
     Experiment with different GNN architectures, hyperparameters, and optimization techniques (e.g., learning rate schedules, regularization methods).
     Conduct cross-validation experiments to tune model parameters and assess generalization performance.
     Document and analyze the results, identifying insights and areas for improvement.

Week 5:
 Objective: Extend GNN models for link prediction tasks on graph data.
 Tasks:
     Research link prediction techniques and datasets suitable for evaluating GNN models.
     Preprocess the graph data to create positive and negative examples for link prediction.
     Implement GNN-based link prediction models and train them on the prepared datasets.

Week 6:
Objective: Evaluate and refine GNN models for link prediction.
Tasks:
     Evaluate the link prediction models using appropriate evaluation metrics such as AUC-ROC or precision-recall curves.
     Experiment with different strategies for negative sampling and feature engineering to improve link prediction performance.
     Conduct ablation studies to analyze the contribution of different components of the GNN models to link prediction accuracy.

 Week 7:
  Objective: Explore the generation of synthetic graphs using GNN models.
  Tasks:
     Research graph generation techniques based on GNNs, such as GraphVAE or GraphGAN.
     Obtain or generate datasets of real-world graphs suitable for training and evaluating graph generation models.
     Implement GNN-based graph generation models and train them on the prepared datasets.

Week 8:
 Objective: Evaluate and refine GNN models for graph generation tasks.
 Tasks:
    Assess the quality and diversity of the generated graphs using appropriate evaluation metrics and visual inspection.
    Experiment with different latent space representations, training objectives, and regularization techniques to improve graph generation performance.
    Analyze the properties of the generated graphs and compare them to those of real-world graphs in the dataset.

Throughout the project, maintain regular communication with advisors, mentors, or teammates for feedback, guidance, and collaboration. Adjust the timeline and tasks as needed based on project progress and unforeseen challenges.","Checkpoint-1: Understanding of Graph Theory, Networks and GNNs

Checkpoint-2: Fluency with the PyTorch library and implementation of GNNs

Checkpoint-3: Node classification using various models 

Checkpoint-4: Evaluate and develop link prediction models

Checkpoint-5: Generation of Synthetic Graphs ",ML
185,Siddharth Kaushik 210070086,Competitive Programming,Ishaan Manhar (210070033),Competitive Programming,This course would be a beginners guide to getting started with and mastering the skills required to ace CP. The course would start from simple logic based questions and would proceed to cover and touch all the major topics in CP. We would be giving selected problems each week that you are expected to solve as well as plenty of practice on your own too from Leetcode and Codeforces. ,12,Basics of CPP (CS101 level) is recommended but not a must,projects/default.png,https://drive.google.com/file/d/1WeeVhANAZomp06_4WeFYKYRv3K7i_ghN/view?usp=sharing,"Week 1- DSA course by Naveen Garg, Math and logic problems
Week 2- Datastructure based easy questions and get accustomed to the member functions of the data structure in std libs (Array, Stack, Heap, Queues, Set)
Week 3- Sorting and Searching
Week 4 - Greedy problems
Week 5- Dynamic problems
Start to do contests
Week 6,7 - Graphs including Linked list, trees, DG	
Week 8 - Miscellaneous","Checkpoint 1 - Getting accustomed to member functions of std lib datastructure
Checkpoint 2 - Mastering all Sorting and Searching Algorithms
Checkpoint 3 - Getting used to Greedy Problems and DP and knowing when to use each
Checkpoint 4 - Understanding and solving graph based questions
Checkpoint 5 - Mastering CP and knowing when to use what tecnique to solve various types of questions",CP
